{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "755a39c06618441f844ca4decdc82346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2795fb792fe84943a828255d770c6b70",
              "IPY_MODEL_192984e73e6f4f6fa3d9594decd226c3",
              "IPY_MODEL_ae101cf8354f4d9795f1cc83cc709426"
            ],
            "layout": "IPY_MODEL_3ee6316899cf4f6d9bf1ccf01d791bd6"
          }
        },
        "2795fb792fe84943a828255d770c6b70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9169e8c4f2a4c8bbb04628b591d0b97",
            "placeholder": "​",
            "style": "IPY_MODEL_f3326022b01c41018cf4a60770f943c7",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "192984e73e6f4f6fa3d9594decd226c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a225e07733b4c2390bd29de1aa2a76c",
            "max": 2324,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_578128809b944fe7b3355c834e68bbd4",
            "value": 2324
          }
        },
        "ae101cf8354f4d9795f1cc83cc709426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cacde5749c074e319b9c2d29404f7b36",
            "placeholder": "​",
            "style": "IPY_MODEL_67f16c27a6ea4c56999f796c1256cbb0",
            "value": " 2.32k/2.32k [00:00&lt;00:00, 97.2kB/s]"
          }
        },
        "3ee6316899cf4f6d9bf1ccf01d791bd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9169e8c4f2a4c8bbb04628b591d0b97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3326022b01c41018cf4a60770f943c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a225e07733b4c2390bd29de1aa2a76c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "578128809b944fe7b3355c834e68bbd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cacde5749c074e319b9c2d29404f7b36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67f16c27a6ea4c56999f796c1256cbb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc2ab00a30aa4148bfbf6b98b23ed0a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_911633f11da64b3d9f93d61cc9956311",
              "IPY_MODEL_7a526eafda2d492d8c710ccfeccca9f5",
              "IPY_MODEL_1fdb4570c493468595542dd76165e47a"
            ],
            "layout": "IPY_MODEL_7e9994ca19d94793af1519f97cef7d9a"
          }
        },
        "911633f11da64b3d9f93d61cc9956311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1a9ea127dc840238c619897ae4f3e3b",
            "placeholder": "​",
            "style": "IPY_MODEL_192534a1703e480d9a7120a120b7a8d0",
            "value": "spiece.model: 100%"
          }
        },
        "7a526eafda2d492d8c710ccfeccca9f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21d79282437b44c9a6e647fae7fc29ca",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_749c99d3311b4527a92e393364305a96",
            "value": 791656
          }
        },
        "1fdb4570c493468595542dd76165e47a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43d7713867c94ec7b6c12b9754a87ad7",
            "placeholder": "​",
            "style": "IPY_MODEL_57557cc242584945b303a270f27a336f",
            "value": " 792k/792k [00:00&lt;00:00, 3.34MB/s]"
          }
        },
        "7e9994ca19d94793af1519f97cef7d9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1a9ea127dc840238c619897ae4f3e3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "192534a1703e480d9a7120a120b7a8d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21d79282437b44c9a6e647fae7fc29ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "749c99d3311b4527a92e393364305a96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43d7713867c94ec7b6c12b9754a87ad7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57557cc242584945b303a270f27a336f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a13ab2387ee4b2aae7a0dba68831cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88cafda85e9244bbb81b168660ee951f",
              "IPY_MODEL_d1f56a90e0f14b918557dac8bd67788a",
              "IPY_MODEL_4045766d76c84bd0830bfcdd7e5b8be1"
            ],
            "layout": "IPY_MODEL_ed70ba4833d743a8bf52f788646c8bbe"
          }
        },
        "88cafda85e9244bbb81b168660ee951f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a67901b86764506ba97e162983695a2",
            "placeholder": "​",
            "style": "IPY_MODEL_3ab1e83ca99c44159753ac140882d2f4",
            "value": "tokenizer.json: 100%"
          }
        },
        "d1f56a90e0f14b918557dac8bd67788a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ca8eeda44fe4b47ad29ef83091fa74b",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b558aba2725d4b199efc286a29b1496f",
            "value": 1389353
          }
        },
        "4045766d76c84bd0830bfcdd7e5b8be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f1f69bc866c458c9ad4fff8990f7cb1",
            "placeholder": "​",
            "style": "IPY_MODEL_d15209cbb2a849e9a31a64c2203466ca",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 4.51MB/s]"
          }
        },
        "ed70ba4833d743a8bf52f788646c8bbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a67901b86764506ba97e162983695a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ab1e83ca99c44159753ac140882d2f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ca8eeda44fe4b47ad29ef83091fa74b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b558aba2725d4b199efc286a29b1496f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f1f69bc866c458c9ad4fff8990f7cb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d15209cbb2a849e9a31a64c2203466ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3ddc5e96c82494586bb9f9b09c63d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89fc16b702c24e41a8f59abaf2d7a103",
              "IPY_MODEL_e4df57152cf24e76816111582b62f5ef",
              "IPY_MODEL_cd9c675f6cf747479329eb08627e22e6"
            ],
            "layout": "IPY_MODEL_15c2390a48cb45c38bb58a300a19dce0"
          }
        },
        "89fc16b702c24e41a8f59abaf2d7a103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0202fb2dc800464daaa6df723bcc5479",
            "placeholder": "​",
            "style": "IPY_MODEL_acec00a370ea47e58b134cb1da1f0d1e",
            "value": "Map: 100%"
          }
        },
        "e4df57152cf24e76816111582b62f5ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c06d9807de5421cad715cb74f400022",
            "max": 1600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_addd835b00954ab8b47815bf7c794115",
            "value": 1600
          }
        },
        "cd9c675f6cf747479329eb08627e22e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e675b07c0224468f800dce536f21deb8",
            "placeholder": "​",
            "style": "IPY_MODEL_36be6c3dd1374b36895e678a14381240",
            "value": " 1600/1600 [00:03&lt;00:00, 427.22 examples/s]"
          }
        },
        "15c2390a48cb45c38bb58a300a19dce0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0202fb2dc800464daaa6df723bcc5479": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acec00a370ea47e58b134cb1da1f0d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c06d9807de5421cad715cb74f400022": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "addd835b00954ab8b47815bf7c794115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e675b07c0224468f800dce536f21deb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36be6c3dd1374b36895e678a14381240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "735e9631d29e4791be84e1d145b396a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c87cae25d57041468a46eea12a5969d4",
              "IPY_MODEL_1324679d2ea941248085071dbd3d1079",
              "IPY_MODEL_f721e1ace3c54f3699d78fa1125392ff"
            ],
            "layout": "IPY_MODEL_a836efb195434b36af1262af990e30ac"
          }
        },
        "c87cae25d57041468a46eea12a5969d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_484a475cbc4f4cdd9ff1f02c538975c7",
            "placeholder": "​",
            "style": "IPY_MODEL_c85cbecd98004c53b8e742b5e3377a93",
            "value": "Map: 100%"
          }
        },
        "1324679d2ea941248085071dbd3d1079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d379f79289d4cdc920178ccf7c0ac15",
            "max": 400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa3a82573bc04aac82c4aa41a4c03c14",
            "value": 400
          }
        },
        "f721e1ace3c54f3699d78fa1125392ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f2dcc0e649f4e81baa5f0ce9f50317f",
            "placeholder": "​",
            "style": "IPY_MODEL_97ded8d6e9cd40139dd10177ef1fcc73",
            "value": " 400/400 [00:00&lt;00:00, 506.23 examples/s]"
          }
        },
        "a836efb195434b36af1262af990e30ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "484a475cbc4f4cdd9ff1f02c538975c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c85cbecd98004c53b8e742b5e3377a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d379f79289d4cdc920178ccf7c0ac15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa3a82573bc04aac82c4aa41a4c03c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f2dcc0e649f4e81baa5f0ce9f50317f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97ded8d6e9cd40139dd10177ef1fcc73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Install necessary packages**"
      ],
      "metadata": {
        "id": "VLQEGluyWtnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install -U transformers datasets evaluate rouge_score accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_q6o6OiQXCqX",
        "outputId": "0478b76b-1a7f-41f2-bb33-68fc5c28896b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.1)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=69e6c1099dcaec1a5d9495db53ead2ede1d55602fe6a509b0ba5823b16244e6c\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: xxhash, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, rouge_score, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, transformers, datasets, evaluate, accelerate\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.41.1\n",
            "    Uninstalling transformers-4.41.1:\n",
            "      Successfully uninstalled transformers-4.41.1\n",
            "Successfully installed accelerate-0.30.1 datasets-2.19.1 dill-0.3.8 evaluate-0.4.2 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 rouge_score-0.1.2 transformers-4.41.2 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mRc2bj8auhp",
        "outputId": "648b579a-f215-4592-a6d2-d8cc65424ba4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.30.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.5.40)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Upload and Prepare Dataset**"
      ],
      "metadata": {
        "id": "EvCasKbhxoaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the dataset file from local drive\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Import json module for handling JSON files\n",
        "import json\n",
        "\n",
        "# Read the uploaded JSON file into a Pandas DataFrame\n",
        "import pandas as pd\n",
        "with open(\"medical_dataset.json\") as f:\n",
        "    data = json.load(f)\n",
        "dataframe = pd.DataFrame(data)\n",
        "\n",
        "# Convert the DataFrame into a Hugging Face dataset format\n",
        "from datasets import Dataset\n",
        "med_ds = Dataset.from_pandas(dataframe)\n",
        "\n",
        "# Print the size of the dataset\n",
        "print(\"Total dataset size:\", len(med_ds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "LQm3xc18xVHu",
        "outputId": "613f4659-4a6c-47db-a3e2-bd1ae11df0a7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ad1b22ca-26b1-4d8a-84b1-dd447646533e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ad1b22ca-26b1-4d8a-84b1-dd447646533e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving medical_dataset.json to medical_dataset.json\n",
            "Total dataset size: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split Dataset**"
      ],
      "metadata": {
        "id": "7mZpvD3Ax7FZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "med_ds = med_ds.train_test_split(test_size=0.2)"
      ],
      "metadata": {
        "id": "y6ZWIqH-xVL9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Print Dataset Structure**"
      ],
      "metadata": {
        "id": "2anoNdLjaWhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(med_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_1gSgknxVPm",
        "outputId": "430357b0-9e65-40c9-9e14-a71bfe9a24c8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['output', 'input', 'instruction'],\n",
            "        num_rows: 1600\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['output', 'input', 'instruction'],\n",
            "        num_rows: 400\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inspect an Example**"
      ],
      "metadata": {
        "id": "Fj4bHveIabN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = med_ds[\"train\"][0]"
      ],
      "metadata": {
        "id": "UYAQkVTsxVSk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in example:\n",
        "    print(\"A key of the example: \\\"{}\\\"\".format(key))\n",
        "    print(\"The value corresponding to the key-\\\"{}\\\"\\n \\\"{}\\\"\".format(key, example[key]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ2wJYc0xVVn",
        "outputId": "bb512599-d30f-42c8-aae3-2f61a2a292d9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A key of the example: \"output\"\n",
            "The value corresponding to the key-\"output\"\n",
            " \"Emergency Medicine Physicians' Approaches to Coping with Stress in COVID-19 Pandemic\"\n",
            "A key of the example: \"input\"\n",
            "The value corresponding to the key-\"input\"\n",
            " \"Aim: This study aimed to investigate the stress experienced by emergency medicine physicians working in emergency departments during the coronavirus disease-2019 (COVID-19) pandemic, the factors they stated to be effective against stress, and their coping approaches to stressful situations. Materials and Methods: The study was designed in a general screening model, and 200 emergency medicine physicians participated via e-mail who work in emergency departments in Turkey. The sources of stress related to the pandemic, the factors that they find effective in combating stress, and their strategies to cope with stress were investigated with relation to their gender, marital status, after-shift accommodation, manner of working in a shift, smoking behavior, having a chronic disease, having children, and spouse's job as a healthcare professional. Results: While the primary source of stress of emergency medicine physicians during the pandemic was the risk of transmitting the virus to their families, the most influential factor in combating stress was leisure activities. Emergency physicians' approaches to coping with stress were significantly predicted by the variables of using full personal protective equipment while working, having an adequate sleep and resting opportunities, obtaining additional economic income, and not knowing the pandemic's end date. Conclusion: Emergency medicine physicians used active problem-oriented approaches, and among these, they used the social support seeking approach the most during the pandemic. It is necessary to provide social support, take precautions to care for healthcare workers' families and arrange emergency physicians' shifts to allocate their time to their leisure activities appropriately to reduce stress.\"\n",
            "A key of the example: \"instruction\"\n",
            "The value corresponding to the key-\"instruction\"\n",
            " \"Please summerize the given abstract to a title\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Preprocessing the data**"
      ],
      "metadata": {
        "id": "9skrZXp46wGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ey0iP1MKZqkk",
        "outputId": "d19bd9fb-bb56-472e-e64a-6995b69ca16c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jun  1 15:24:10 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   74C    P0              33W /  70W |   8249MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Tokenizer**"
      ],
      "metadata": {
        "id": "b6QttPKTagD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "755a39c06618441f844ca4decdc82346",
            "2795fb792fe84943a828255d770c6b70",
            "192984e73e6f4f6fa3d9594decd226c3",
            "ae101cf8354f4d9795f1cc83cc709426",
            "3ee6316899cf4f6d9bf1ccf01d791bd6",
            "b9169e8c4f2a4c8bbb04628b591d0b97",
            "f3326022b01c41018cf4a60770f943c7",
            "5a225e07733b4c2390bd29de1aa2a76c",
            "578128809b944fe7b3355c834e68bbd4",
            "cacde5749c074e319b9c2d29404f7b36",
            "67f16c27a6ea4c56999f796c1256cbb0",
            "cc2ab00a30aa4148bfbf6b98b23ed0a9",
            "911633f11da64b3d9f93d61cc9956311",
            "7a526eafda2d492d8c710ccfeccca9f5",
            "1fdb4570c493468595542dd76165e47a",
            "7e9994ca19d94793af1519f97cef7d9a",
            "e1a9ea127dc840238c619897ae4f3e3b",
            "192534a1703e480d9a7120a120b7a8d0",
            "21d79282437b44c9a6e647fae7fc29ca",
            "749c99d3311b4527a92e393364305a96",
            "43d7713867c94ec7b6c12b9754a87ad7",
            "57557cc242584945b303a270f27a336f",
            "5a13ab2387ee4b2aae7a0dba68831cd6",
            "88cafda85e9244bbb81b168660ee951f",
            "d1f56a90e0f14b918557dac8bd67788a",
            "4045766d76c84bd0830bfcdd7e5b8be1",
            "ed70ba4833d743a8bf52f788646c8bbe",
            "2a67901b86764506ba97e162983695a2",
            "3ab1e83ca99c44159753ac140882d2f4",
            "0ca8eeda44fe4b47ad29ef83091fa74b",
            "b558aba2725d4b199efc286a29b1496f",
            "8f1f69bc866c458c9ad4fff8990f7cb1",
            "d15209cbb2a849e9a31a64c2203466ca"
          ]
        },
        "id": "or49iEnYxVY1",
        "outputId": "9ad118d6-1b10-4163-cdce-76a886202d34"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "755a39c06618441f844ca4decdc82346"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc2ab00a30aa4148bfbf6b98b23ed0a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a13ab2387ee4b2aae7a0dba68831cd6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenize Dataset Examples**"
      ],
      "metadata": {
        "id": "XUtUT8wmalOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through each example in the training set\n",
        "for example in med_ds[\"train\"]:\n",
        "    # Tokenize the input text in each example\n",
        "    tokenized_input = tokenizer(example['input'], return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    # Print the keys and corresponding tokenized values for input\n",
        "    for key, value in tokenized_input.items():\n",
        "        print(f\"A key of the input example: \\\"{key}\\\"\")\n",
        "        print(f\"The value corresponding to the key-\\\"{key}\\\"\")\n",
        "        print(value)\n",
        "\n",
        "    # Tokenize the output text in each example\n",
        "    tokenized_output = tokenizer(example['output'], return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    # Print the keys and corresponding tokenized values for output\n",
        "    for key, value in tokenized_output.items():\n",
        "        print(f\"A key of the output example: \\\"{key}\\\"\")\n",
        "        print(f\"The value corresponding to the key-\\\"{key}\\\"\")\n",
        "        print(value)\n",
        "\n",
        "    # Tokenize the instruction text in each example\n",
        "    tokenized_instruction = tokenizer(example['instruction'], return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    # Print the keys and corresponding tokenized values for output\n",
        "    for key, value in tokenized_instruction.items():\n",
        "        print(f\"A key of the output example: \\\"{key}\\\"\")\n",
        "        print(f\"The value corresponding to the key-\\\"{key}\\\"\")\n",
        "        print(value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azLV9SCrxVcI",
        "outputId": "cee18754-0c65-4283-ad22-05cafa17e392"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "          5406,   201,  4816,   120, 14087,   326,   227,  8088,  1945, 24306,\n",
            "         14319,   263,    95,   167,    13,     8, 24306, 14319,    41,  2128,\n",
            "            13,  6687,     6,  2861,     5,  5170,   137,  1541,  1230,     6,\n",
            "         24306, 14319,    28,  8530,  4148,  1553,    12,  3098,    41,  2445,\n",
            "            13,  1640,     6,     3,  3539,     5,  6170,   201,   167,    28,\n",
            "           119,   576,    53,   222,  2366,     5,  8530,  4148,  6145,     7,\n",
            "            41,  8172,    29,     6,  1243,     3,     2,  9579,    61,   344,\n",
            "             3, 10207,  9440,    41, 23838,     6,     3, 10593,     3,     2,\n",
            "           314,  2394,     3,  1725,    87,    51,   434,    61,    11, 24306,\n",
            "            41, 11434,     6,   431,  2079,     3,     2,   850,  1755,     3,\n",
            "          1725,    87,    51,   434,    61, 14319,   130,  1126,     5,  8530,\n",
            "          4148,  6145,     7,   130, 15712,    16,  2069,  1717,     3,  2172,\n",
            "            12, 22586,  1717,    45,    73, 10304,  1488,     5,  8530,  4148,\n",
            "            47, 14619,    16,     3,     9,  1196,    13,    20, 30818,     7,\n",
            "           383,     8,   192,  4160,     6,    28,     3,  5325,  1021,  1589,\n",
            "          5069,  4740, 11159,  9699,     3, 10207,  9440,  8926,    16,     8,\n",
            "           166,  5112,    11,     3,  5325,  1021,  1945,  5069, 24306,  4251,\n",
            "            26, 13534,  8926,    16,     8,   511,  5112,     5,   100,   810,\n",
            "             3, 21275,    24,  8530,  4148,    19,   150,  1200,     3, 24092,\n",
            "            12,     3,     9,  1088,  1898,     6,    68,    54,    92,    36,\n",
            "           435,    16,   315, 11881,    18, 13599, 10133,     9,     6,   379,\n",
            "           165,  6028,    28,  9674,     3, 10207,  1294,    26,   138, 14319,\n",
            "             5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 2759,   374,  6615,     7,    13, 16208,  2427,     7,    63,    10,\n",
            "          4804,    89,  1222, 10007, 16587, 11145,     7,    16,   374, 30818,\n",
            "             7,   338,  8530,  4148,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[23023,    10,    37,  4388,  2131,   221,  3113,  2847,  7765,   308,\n",
            "          4481,    65,  2546,     3,     9,  5987,    13,   585,    72,  7313,\n",
            "           227,     8, 22494,     5,    86,   131,     3,     9,  1158,    13,\n",
            "           767,     6,   132,    19,     3,     9,  3098,    16,   633,  2116,\n",
            "            30, 28045, 18095,     6,  2651,    95,    12,     8,     3, 26892,\n",
            "          6678,     5,  7717,    10,    37,   750,   810,  9048,    12, 16021,\n",
            "            35,   235,  7959,  8341,   182,  1100,  6678,    30, 28045, 18095,\n",
            "            15,     7,   131,   274,    11,   227,     8, 22494,     5,     3,\n",
            "          8500,     6,     8,  5997,    13,    48,  9740,    47,    12,  6570,\n",
            "             8,  1252,   585,  2188,    30, 28045, 18095,    16,  1100,   648,\n",
            "             5,    37,   750,   585,    19,    46, 18355, 25444,   810,   338,\n",
            "         16021,    35,   235,  7959,     7,     5,    37,   810,  3106,   963,\n",
            "           585,  5778,    81,     8, 28045, 18095,     3, 30564,    16,  1620,\n",
            "            13,  2854,    41,   518,    32,   134,    61,  3501,    45,  1762,\n",
            "          1914,  1360,    12,   932, 11363,  6503,     5,    37,  3187,    28,\n",
            "          2859,   960,    41,    77, 21418,     7, 11029,     6, 20114,     6,\n",
            "         24685,     7,    11, 24685,     7,  2477,    61,   105,  5715,   106,\n",
            "             9, 18095,   153,   130, 21527,     5,   506,   331,   130,     3,\n",
            "         16466,    57,  5266,  9506,    11,     8, 21744,     7,   130,   990,\n",
            "           338,  4398,   402,     3, 20119,    10,    37,   772,  3217,    24,\n",
            "           944,  5553,  4290,  6678,    81,     8, 28045, 18095,    47,     3,\n",
            "         30564,    16,  3488,   134,     5,    71, 10710,   381,    13,   175,\n",
            "          2984,   130,  1790,    16, 18178,   224,    38,     8,  3559,    13,\n",
            "          3721,     3, 21031,  1863,     6,     3, 27837,    15,     7,     6,\n",
            "          7913,     6,    11, 22207,    17,     5, 10236,     7,    45,  1473,\n",
            "             6,  2312,    11,  5308,   130,     8,   167, 27701,  5921,     5,\n",
            "          4504,   314, 15731,  4704,  2984,  1204,   792,    13,     3, 18959,\n",
            "          2469,     3, 13903,     7,    28,    46,  1348,    13,   668,     3,\n",
            "         13903,     7,     6,    84,  9379,    24,  2111,   985,  2984,   130,\n",
            "             3, 11675,    16,   430,  5707,     5,    37,  2030,    11,  7402,\n",
            "             3, 13903,     7,    21,   175,  2984,   130,     3, 27931,    11,\n",
            "          1914,  6898,     5, 29197,    10,   506,   772,   504,     3,     9,\n",
            "           306,  1080,    13,   585,    30, 28045, 18095,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[16021,    35,   235,  7959,     7,  1693,    13,  1100,  5001,    16,\n",
            "          3699, 28045,  6722,  2200,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[23023, 16525,   138,    46, 11658,   788,    12,  3575,    20,  4638,\n",
            "            23,  4392,    19,     8,   167,  1017,  1137,    13,    46, 11658,\n",
            "            16,  1547,     5,    37,  1348,  3178,    16,  1547,    19,   731,\n",
            "            16,  3575,    11,  3323,    13, 12065,  5233,     5,   100,    54,\n",
            "            36,  3798,    57,  3094,  4349,    13,  4371,    17,  2999,     7,\n",
            "            24,    33,  2354,    16,  3575,    11,     3,  5833,    70,  5576,\n",
            "             5, 27919,    37,  5997,    13,     8,   810,    47,    12,  6570,\n",
            "             8,   463,    13,   251,   347,    30,  3575,    18,  3723,  4371,\n",
            "            11,    12,  6570,    70,   999,    11,  5962,    16,  1547,     5,\n",
            "          7717,     7,   100,    47,     3,     9,  1132,    13,  1017, 19533,\n",
            "             7,    21,  1035,     6,  8205,     6,    11,   234,  2056,   481,\n",
            "           117,  1341,  1291,    11,   478,  2691,   117,    11,   789, 10142,\n",
            "            30,   999,    11,  5962,    13,   796,  4371,    17,  2999,     7,\n",
            "            16,  1547,     5, 12772,  9487,    13,   806,  4371,    24,    33,\n",
            "          2354,    16,  3575,    43,    59,   118,   937,     5,  3910,     6,\n",
            "           542,  1637,   224,    38, 13468,     7,     6, 17360,     7,     6,\n",
            "         11446,     6,    11,  1442,  8384,    63,  6205,    41, 13011,   553,\n",
            "             7,    61,    43,   118,  2799,    24,    33,   207,  2836,    13,\n",
            "           529,    18,  6015,    15,  3575,     5,   100,    19,    16, 17912,\n",
            "            13,     8,   685,    24,    66,     8,  4371,    17,  2999,     7,\n",
            "            16,   175,  1637,    33,    59,  7117,   120,  3575,  2354,     5,\n",
            "             3,  7264, 17360,     7,    11, 13468,     7,     6,  6605,    11,\n",
            "          1131,     3,  5096,     3,    26,   138,    41,   291,  3272,    61,\n",
            "            33,     8,   167,  5871,  2546,    11, 16647,     6,   713,    79,\n",
            "            43,     8,  7402,  3575,   738,     5, 10792,  1836,    11, 23756,\n",
            "          3231,  6141,    12,    36,  3575,  2354,    11,  5871, 16647,    33,\n",
            "           859,   273,   350, 15086,     7,   578,  7402,  3575,   738,     5,\n",
            "         29197,  9487,    13,   305,  4536,  4371,    17,  2999,     7,    84,\n",
            "            43,     8,  2030,  3575,   738,   441,   284,   542,   563,   225,\n",
            "            36,   347,    16,  2193,  1335,    11,  2691,  3679,    21,  1073,\n",
            "             6,   999,     6,    11,  5962,   331,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[22714,    13,  5546,    13,  3575,    18,  3723,  4371,    21,     8,\n",
            "          9793,    13, 15027,    46, 11658,    16,  1547,     5,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   86,    48,   161,     6,    62,  8341,     8, 16436,    13,   638,\n",
            "          6961,  4481,    16,  4726,   338,     8, 15208,  5985,  5705,   308,\n",
            "         29969,  7925,   825,     5,   101,   169,     8,   251,    13,     8,\n",
            "          3538,  6266,    41,   134,  4748,     7,    61,    24,  4535,     8,\n",
            "           684,     6,   224,    38,  2074, 11048,     6, 17087,    16,    89,\n",
            "          7633,  1488,     6,    11, 14319,    16,   284,  1015,     5,   101,\n",
            "          4285,     8,  5985,  5705,   308, 17581,   138, 29969,  7925,    28,\n",
            "         21740, 12009,    16,     8,  6666,    11, 16080, 11683,     5,   101,\n",
            "           169,     8,   377,  3142,    23,   152,   973,    28,     8, 21740,\n",
            "         27742,  7385,   138,    12,     8,  2074, 11048,    12, 18253,     8,\n",
            "         21740,  1951,     5,    37, 25194,   772,  3130,    24,     8, 29969,\n",
            "          7925,   825,  7328,    97,    18, 17631,  8755,    12,  6300,   529,\n",
            "            18,  2157,    32,   235, 10529,  3889,    16,     8,  1805,   331,\n",
            "            16,     8,  1252,  4896,     5,    37, 21740,   138,   825,  4382,\n",
            "            16,    48,   161,    65,   248,  1055,    16,     3, 29856,     8,\n",
            "          6722, 16436,    30,   315,  2643,     7,     6,     3,    23,     5,\n",
            "            15,     5,     6,   415,     6,  1157,     6,    11,   344,  1440,\n",
            "             6,   437,     8,   743,  4709,    16,   151, 12337,    19,  4586,\n",
            "             5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   37, 16436,    13,   638,  6961,  4481,    16,  4726,    10,    71,\n",
            "         21740,   138,  1295,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 4190,  1035,  1383,  3480,   359,   251,  1918,  1868,    22,     7,\n",
            "           533,    11,   182,  1934,    21,  8209,     5,  1441,     3,     9,\n",
            "           422,   483,    16,  1035,  1383,    41, 15616,    16,     8,  1719,\n",
            "            13,  1046,    41,  4630,   196,    61,    61,    54,  1817,   109,\n",
            "             9,    26,     8,  6659,    87,   102,  3738,    17,  4749,   277,\n",
            "            21,     3, 12053,   856,  1058,     5,  4063,     6,     8,  1711,\n",
            "            13,     8,  1383,   581, 24768,    87,   202,    77,  9174,   138,\n",
            "             3,    17,  4624,    49,    53,     6,    21,  1304,    63,     6,\n",
            "          4191,    53,     6, 16685,    11,   119,  1017,  3240,  3026,  6032,\n",
            "            33, 13488,     5,   100, 14496,  6621,     3,     9,  1249, 19681,\n",
            "          1035,  1023,   387,  3920,    53,  5336,    12,   462,  2405,  3535,\n",
            "            87, 13238,  2009,  1711,     6,     3,    17,  4624,    49, 10664,\n",
            "            87, 16882,  1707,    41,  1161, 23532,    41, 18145,    13,  1046,\n",
            "            61,    11,   315, 15107,    13,     3, 13044,   196,    41, 18145,\n",
            "            13,   529,    18, 19405,    61,   201,    11,  1044,    18,    60,\n",
            "          9817,    63,    13,     8, 23532,    28,  2349,     3,    60,  2660,\n",
            "         11102,     5,     3, 22917,     6,     8,  3938,   251,    13,     8,\n",
            "          2290,  1023,    22,     7, 23532,    19, 25423,   338,   301,   956,\n",
            "           518,    41,   434, 29605,    18,   956,    23,   208,    18,  1326,\n",
            "            40,   524,    61, 12628,     5,     3, 28653,     7,     6,     8,\n",
            "          6268,   387,  3920,    19, 13612,   139,     8,  2290,  1023,   338,\n",
            "             3,     9,  3343,  3303,     3,   390, 25078,    26,    53,  8557,\n",
            "             5,  9006,     6,     8,     3, 19337,    18,  2360,    65,   107,\n",
            "          9060,    33,  6126,   338,     3, 19964,    18, 19337, 12628,    21,\n",
            "             8, 23532,    11,  2641,     3, 13044,   196,  6266,    41,    23,\n",
            "             5,    15,     5,     3, 13044,   196,  2292,    12,     3, 13044,\n",
            "           196,    18, 13520,    13,     8,  6268,   387, 16376,  1023,     5,\n",
            "            37, 25423,  3938,   331,    11,    65,   107,  9060,    33,  3334,\n",
            "            11,   258, 13612,   139,     8,  5508,    15,    26,     3, 13044,\n",
            "           196,  1719,    13,     8,  6268,   387, 16376,  1023,   338,    46,\n",
            "             3,  7600,   279,  3709,     3,   390, 18659,   387,  3920,    53,\n",
            "          1295,     5, 30871,   772,   504,   306,  4840,    49,  6873, 11102,\n",
            "             6,   306,  6268,   655,     6,   626,     3,    17,  4624,    49,\n",
            "         10664,     6,  1516,     3,    17,  4624,    49,   415,  1707,     6,\n",
            "            11,   626,  3938,    13,     8, 23532, 11704,  6932,     3,    60,\n",
            "          2660, 11102,   137,    37,  5336,   744,    22,    17,   174,   926,\n",
            "          2290,    42,   387,  3920,   251,    21,     8, 16629,   433,   788,\n",
            "            12,     8,  5480,  1405,     5,    37,  5237,  1693,     3, 21275,\n",
            "             8,  4784,   485,    13,     8,  4382,  5336,   147,  1895, 15171,\n",
            "             5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 4908, 19681,  1035,  1023,   387,  3920,    53,    21,  1231,  1034,\n",
            "          1275,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 4955,    23,     9,    75,  2358,  3918,  3792,    72,   145,   192,\n",
            "          4160,    13,     3,    17,   440,    83,    17, 13281,   892,     5,\n",
            "            86,    48,  1059,    13,    97,     6,     8,  8136,    13,     8,\n",
            "           842,    38,    46,  3640,  5608,    53,    13,     3,     9,  3599,\n",
            "           381,    13,  7213,   120, 18231,    26, 16216,  2258, 24339,     7,\n",
            "          4431,   120,  2130,     5,     3, 28643,     6,     8,    82,    32,\n",
            "         16464,   440,    47,    41,   127,    19,    61,  1702,    12,    36,\n",
            "             3,    60, 25181,    57, 26075,   813,   729,   155,   127,  2640,\n",
            "             6,    16,  4817,  2317, 27419,     6,    11,    16,  1090,    57,\n",
            "          1215, 20853, 15127,    15,    26,  2640,     5,   818,     8,  3739,\n",
            "          7314,    13,   490, 16216,  2258, 24339,     7,  5105,    57,     3,\n",
            "         10791,     3,    60,  7050,    53,    65,  2188,    15,    26,   163,\n",
            "          5665,     6,     3,     9, 16635,    13,  3739,  2116,   130,  4006,\n",
            "            91,    28,  2358,   494,    13,    78,  4992,  5233,     5,   100,\n",
            "            47,  3323,     3,   390,    30, 20298,    11, 11082,   120,  7347,\n",
            "           331,    28,  1445,    12,     8,  2343,   485,    13,  3165, 30073,\n",
            "          2640,    24,     6,    16,  9337,  5628,     6,     3,    40, 13365,\n",
            "         21264,     5,  2150,   120,     6,    30,  4645,  6082,     8,   772,\n",
            "            13,     8,  3739,  2116,   130,    59, 20863,    68,    79,   130,\n",
            "         17516,   557,  2569,    11,     3,  4931,    16,     3,     9,   182,\n",
            "         21700,   659,     5,  1960,     6, 16643,  2358,  3918,    28,  2640,\n",
            "            13,     3,     9,    78,  4992,  5233,    19,  1702,    12,    43,\n",
            "          4567,     5,   419,  4010, 17680,  1014,     8,  6518,    13,    48,\n",
            "             3,  1498,    54,   199,  4206,    11,  1792,   224, 30995, 11336,\n",
            "            16,     8,   647,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 4556, 22233,    15, 24751, 21765,     3,   104,   395,  2298,    17,\n",
            "            16,  7314,    58,   735,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   86,  1882,  1360,    16, 17792,  2618,     6,  1473,     8,   166,\n",
            "          1488,    13,  3150,  7752,     6,  4301,   106,  2960,  4900,  7952,\n",
            "            18, 14515, 30195,    43,   118,  2196,     5,    37,   126,  6722,\n",
            "           180, 25210,    18,  3881,   553,  4949,    41,   134,  3258,    15,\n",
            "            71, 15835,  7127,  2388,  6546, 27956, 28045, 18095,  9266,    47,\n",
            "          2650,   227,   180, 25210,    18,  3881,   553,   788,    12,    70,\n",
            "         25758,    11,     8,  1994,  2953,    57,     8,  2071,  5255,    19,\n",
            "          2847,  7765,   308,  4481,    41, 13026,   106,     9, 18095, 14326,\n",
            "          1360,   137,   461,   850,  1332,  6503, 20989,    41, 17954,  1685,\n",
            "          9139,    61,  4802,     8,  7313,  3094,   381,    13, 15935,    13,\n",
            "          2847,  7765,   308,  4481,    38,     3,     9,  2131,   221,  3113,\n",
            "             5,    86,    48,  1132,    62,    56,   915,  1100,   251,    81,\n",
            "             8,   180, 25210,    18,  3881,   553,  4949,     3,  7388,    30,\n",
            "             8,  5233,     6,  3739,  1554,     6,  7028,  2254,     6,  1809,\n",
            "             6, 29328,  4005,    13,   180, 25210,    18,  3881,   553,  4949,\n",
            "            11,  1055, 14106,  3629,   581,  2847,  7765,   308,  4481,     5,\n",
            "             1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[21112,    63,     7,    17,    63,  1258,   558,   302,     9,   180,\n",
            "         25210,    18,  3881,   553,  4949,     3,    23,   815,    35,    75,\n",
            "          1191,    40,    29,    15,  3797,  1639,  7925,   172,    29,    15,\n",
            "             3,     7,  2748,    32,   969,    90,    75,  1847,    23,     9,\n",
            "             5,    87, 20087,  3040,     7,    13,   180, 25210,    18,  3881,\n",
            "           553,  4949,    11,  1055,     3, 15288,    75,  4478,  1058,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  419,    17, 10270, 26043,    19,     3,     9,  6658,     6,  1028,\n",
            "             9,  7428, 12085,  9311,    24, 17613,  5696,   277,    28,     3,\n",
            "            60, 14907,     6,  3017,  4741, 13562,    13,  7414,  4866,  2267,\n",
            "          1453,   274,     8,     3, 26558,    13,     3,     9,     3,  8514,\n",
            "         17784, 12085,    30,     8,   337,   596,    38,     8,  3176, 25595,\n",
            "            37,  2291, 17212,     7,     8,   351,    13,     3,     9,  1868,\n",
            "            28,   686,   204,  8363,   399,   565,    23,  3745,   175, 28830,\n",
            "         13562,    13,  3017,  4741,  3176, 25595,     7,   383,     8,  4301,\n",
            "           106,     9, 18095,  1994,  1360,  2131,   221,  3113,    16,    84,\n",
            "          2189,   127,     7,    11,  4785,  5418, 19742,   920,    11,     3,\n",
            "         31488,    26,   175,  6032,   438,    46,  1936,  1705,    13,     8,\n",
            "          6803,    13, 25299,    40, 26043,     7,     6, 10444, 14194,    54,\n",
            "           161,  4799,    28,   119,   533,   124,  2481,    12,   370,  3452,\n",
            "            11,  1868,    18, 12809,   124,    12,   175,  1742,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  368, 10886,    21,     3,     9, 17656,    28, 23549,    11,   419,\n",
            "            17, 10270,  2133,  3484,  4477,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 5097, 10161,   476, 31864,   419, 30113,   162,  4993,     3,   390,\n",
            "            30,     8,  1952,    13, 29106,    75,     3,    32,  7437, 10073,\n",
            "            63,    41,  6618,   137,     3, 10744,  6294, 22177,   304,  6570,\n",
            "             8, 15202, 10369,     7,    21,    11, 10005,    13,  7784,     8,\n",
            "          5009,   257,    21, 29928, 18012,     3,  7316,    41,  4176,   371,\n",
            "            61,    44,   301,   755,    16,  1221,    28,  5731,  9920,    26,\n",
            "          6567,  3252,  4866,     3,     7,  9044,    32,     7,   159,    41,\n",
            "            89, 16568,   134,   137,     3, 24506,  6299,  3592,   101,  9112,\n",
            "             8,  1488,    13,  3479,  1221,    28,  9018, 18012,    20,  2032,\n",
            "           485,    38,     3,     9,   741,    13,     3,    89, 16568,   134,\n",
            "          4260,    57,   276,  7016,    12,   301,   755,    11,  2348,    21,\n",
            "            46,  1348,    13,   314,   203,   442, 11480,   120,    28,  9289,\n",
            "          3739,    11,  2252,  6207,   331,     5,   389, 10140,    52,    18,\n",
            "          2748, 10140,    52,    11,     3, 12088,   829, 14732,  2252,  9413,\n",
            "             7,   130, 14434,     5,   101,  8807,  1221,   139,   192,  1637,\n",
            "             3,   390,    30,     8,  1952,    13, 29106,    75,     3,    32,\n",
            "          7437, 10073,    63,    41,  6618,    61,    44,     8,   804,  1130,\n",
            "            18,   413,     5,  5061, 14797,   331,    45,     8,   192,  1637,\n",
            "           130,     3, 16466,    12,  2862,     8, 10369,     7,    11, 10005,\n",
            "            13,    48, 11685,  1573,     3,  7388,    30,  9915,     5,     3,\n",
            "         12200,  4254,  4578,  1266, 11480,   120,     6,   132,   130,  1516,\n",
            "          5859,   344,     8,   192,  1637,    16, 31546,  7669,     6,  9915,\n",
            "             6,     3,    17, 21783,  3297,   440,  1047,     3,  3781,  9553,\n",
            "             7,   159,     6,    11,     3,  5171,  1047,     3,   322,    26,\n",
            "            32,     7,   159,    41, 10376,    61,   298,  3823,   117, 31546,\n",
            "          7669,    11,     3, 10376,   298,     3,     7,   413,   630,    41,\n",
            "           134,   413,   630, 31546,     6,    11,  1923,  3180,    15,     3,\n",
            "         10376,  3670,    11,   779,  8435,  6461,     5,  4908,  9504,   342,\n",
            "         28820, 26625,  1693,  4313,  1923,  3180,    15, 31546,    11,  1923,\n",
            "          3180,    15,     3, 10376,    38,  2547,  1020,  2580,    21, 27687,\n",
            "          9915,    44,     8,   804,  1130,    18,   413,    41,   134,   413,\n",
            "           630, 31546,    10, 11007,  5688,     6,     3, 11039,   117,   668,\n",
            "          2712,  3410,  8572,     3, 12734,    18, 10917,     6,  1923,  3180,\n",
            "            15,     3, 10376,    10, 11007,  5688,     6,     3, 23758,   117,\n",
            "           668,  2712,  3410,  8572,     3, 22384,    18, 12734,   137,  8472,\n",
            "          8440,  3063,  9215, 18027,    28,  2186,   554, 11480, 31546,  7669,\n",
            "            11,  2755,     3, 10376,   298,     3,     7,   413,   630,   164,\n",
            "            59,  1984,  9289, 14732,    11, 29106,    75, 11698,    11,    48,\n",
            "           164,   991,    12,     3, 18687,    23,   106,    16,     8,  9915,\n",
            "           147,    97,     6,   237,   227, 18012,     3,  7316,  7784,    44,\n",
            "           301,  9125,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[18185,  1628,    13, 29928, 18012,     3,  7316,    12,   301,   755,\n",
            "            21,  5731,  9920,    26,  6567,  3252,  4866,     3,     7,  9044,\n",
            "            32,     7,   159,     3,  7388,    30, 29106,    75,     3,    32,\n",
            "          7437, 10073,    63,     5,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[27919,     5,   100,  1040,     3,  8345,    12,  9127,     8,  1308,\n",
            "            11,  7401,    13,   573,  3813,    11, 16866,  1087,    13,  2705,\n",
            "         12256,   298,     8,  1722,  3595,  4856,  2367,  3168,    42,  2699,\n",
            "            30,     3,     9,  1643,  2614,     5,    94,    92,  1416,    44,\n",
            "             8,  1339,    11,  2254,  8152,    12,  4028,   224,  1087,     5,\n",
            "            37,  1040,    92,  9048,    12, 19019,  4264,    42,  7821,  8334,\n",
            "            38, 12256,  2075,  3058,   912,    11,   240,   126,  6985,    21,\n",
            "             8,   394,   297,    13,     8,   573,    79,  1716,     5,  7717,\n",
            "             7,     5,    37,   810,  5936,     7,     3,     9,   475,    11,\n",
            "          1376,   543,  3719,    13,    71,  7443,    41,  3291, 20152,   636,\n",
            "          3426,    61,  3037,    18, 14615,    52,  1208,  1777,    41,   188,\n",
            "         14284,  5017,    61,  1144,    18,  6856,    52,  5414,     5,    37,\n",
            "           826,  1296, 16866,  5897,    56,    36, 11411,    10,  5637,  6767,\n",
            "            18, 25557, 31182,   117, 16426, 21035,     3,   184,  1799,    18,\n",
            "         25557, 31182,   117, 17867,   105, 20754,   109,  5780,   153, 31182,\n",
            "           117, 10820,  1142,    21,  9259, 31182,   117, 15757, 17406,     7,\n",
            "            11,  3092,    18,   371,    32,    75, 10064, 31182,   117,   232,\n",
            "             3, 18669,  4908,    18,  3174,    29,  5402,    37,  2726, 11137,\n",
            "            11,  7106,    53,     5,   180,  6146,  5897,   130,     3,  9942,\n",
            "            45,  1699, 21290,    11,  6664,  1625, 26228,  1040,  7201,   105,\n",
            "         21419, 31182, 15186,    10, 28026,     6, 12474,  4712,    35,     9,\n",
            "         10305,     6,   275,    71,  2571,    12,  6776,  1239, 12772,     5,\n",
            "         14490,     7,    13,     8,   810,    56,   462,   128,  7639,    30,\n",
            "           149, 12256,  8726,    70,  6270,    16,     3, 21139, 18804,    38,\n",
            "            79,   370,  1645,    12,   830,    81,  1465,   483,    16,    70,\n",
            "          2597,     5,     3,  7371,     6,    48,  1040,    56,    92,  1921,\n",
            "         12256,    12,   240,     3,     9,  4645,   320,    44,    70,   293,\n",
            "          1087,    11,  1099,   149,    79,    54,   408,  1812,    11,  9748,\n",
            "          1155,    12,  1979,    28,    70,  2597,     5, 29197,     7,     5,\n",
            "            86,  1773,    12,     8,  2847,  7765,   308,  4481,  5362,     6,\n",
            "         12256,    33,     3, 31256, 16959,    53,    70,   573,  3813,    11,\n",
            "         16866,  2231,   367,    11,    33,  2342,   126,  1155,    12,  1716,\n",
            "          6040,     6,   481,     6,    11,  3222,     5, 29635,    33,  3454,\n",
            "            12, 18717,     8, 21383,    11,  3938,    13,     8,   573,   190,\n",
            "           464,  9642,   120,    28,   165,   724,    11,   740, 13416,    28,\n",
            "          2193,  2371,     5,     3,     2,   446,     5,  1276,     2,     9,\n",
            "            89,   322,     6,   309,     5,  8100,  1468,   106,     6,   460,\n",
            "          2658,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 3092, 16866,    11,  3813,    16,     8,    97,    13,   576,  6961,\n",
            "           957,    10,     3, 29421,   127,    17,     7,     3,   184,  6315,\n",
            "            13,  2705, 12256,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  101,   915,     3,     9,   495,    13,  4301,   106,     9, 18095,\n",
            "          1994,  1360,    41,  5911,   553,     2,   308,  4481,    61,     3,\n",
            "            60,    18,    77, 17856,   213,     8,    97,  8572,   344,   192,\n",
            "          2847,   553,     2,   308,    18, 26093, 13562,    19,     8, 14783,\n",
            "            16,     8,  6678,     5,    71,  1283,    18,  1201,  5069,  1868,\n",
            "            47, 10246,    12,     8, 15118,  1775,    28, 11244,    13,    78,\n",
            "            60, 17703,     6, 19222,    11, 28582,   117,    11,    47,     3,\n",
            "            60,    18, 25930, 18716,    26,    38,  2847,   553,     2,   308,\n",
            "          4481,  1465,   227,     3,     9,  6722,    18,  2113,  1059,     5,\n",
            "           216,   410,    59,    43,     3,     9,  6658,  1994,    16,   112,\n",
            "            46,   265,  1496,   159,    11,   261,   150,  7757,     5,   621,\n",
            "          2847,   553,     2,   308,  4481,  7952,    11,     3,     9,   307,\n",
            "          3938,  1059,     6,     3,    88,  1632,  2847,   553,     2,   308,\n",
            "          4481,  1465,   541,     5,    86,    48,   495,     6,     8,    97,\n",
            "            12,   511,  2847,   553,     2,   308,  4481,  7952,    47,     3,\n",
            "          4240,   477,    45,     8,   166,  1465,     3, 23165,   794,    11,\n",
            "             3,  3840,   477,    45,     8,   743,  3161,    13,  3976,     5,\n",
            "           100,    19,    80,    13,     8, 14783,  2847,  7765,   308,  4481,\n",
            "            18,  2113,  1059,   344,   192, 13562,    13,  7952,    16,     8,\n",
            "          6678,     5,  4420,  4467,     7,    10,  2847,  7765,   308,  4481,\n",
            "             6,   419,  3663,    52,  1433,     6,   419,    18,    77, 17856,\n",
            "             6, 16532,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  419,  3663,    52,  1433,    13,  2847,  7765,   308,  4481, 11167,\n",
            "            15,    26,    28,     3,  5934,    18, 23165,     5,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[17277,  6873,   757,    11,   384,  1459,   364,    11,  4471,    33,\n",
            "          2583,  3379,    13,  1832,   533,   364,     6,    11,   592,    12,\n",
            "           175,   364,    19,     3,     9,  4431,   936,   269,     5,   100,\n",
            "          1068,   398,   916,    12,    36, 13841,    11,  5046,    38,   224,\n",
            "            57, 10524,  1884,   155,  2610, 25976,  1438,   383,    48,  2847,\n",
            "          7765,   308,  4481,  2131,   221,  3113,     5,   299,    28,   186,\n",
            "           533,  1002,  1083,     3,  7388,    30,     8,  1773,    12,     8,\n",
            "          2131,   221,  3113,     6,     8,  6537,    13,  1857,  5314,  7239,\n",
            "         28198,     6,     8,  1929,    13,  5314,  6873,   757,   494,    11,\n",
            "           364,     6,    11,     8, 11850,    13,  1899, 16534,    43,   118,\n",
            "         23773,    15,    26,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  86,    8, 1773,   12, 2847, 7765,  308, 4481,    6,   62,   54,   31,\n",
            "           17, 2612,  533,  358, 3148,    7,   12, 5314, 7239,   11,  384, 1459,\n",
            "            1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[    3, 10539,   683, 14196,  8087,    10,    37,  7385,    13,  2847,\n",
            "          7765,   308,  4481,  1221,   578,  1676,     3, 26836,  6244,    49,\n",
            "          1497,    32,     7,   159,     6,    11,   165,  1113,    30,  2847,\n",
            "          7765,   308,  4481,  1341,  1868,  6353,     6,    19,    59,   964,\n",
            "             5,   101,  4468,    48, 20036,  1132,    12,  6825,     8,  7385,\n",
            "            13,  1221,    28,  1676,     3, 26836,  6244,    49,  1497,    32,\n",
            "             7,   159,   859,  2847,  7765,   308,  4481,  1221,     6,    11,\n",
            "            12,  6570,     3,    99,     3,   287,   127,  9824,     3, 26836,\n",
            "          6244,    49,  1497,    32,     7,   159,  4131,    29,     7,  3739,\n",
            "          6353,    16,   175,  1221,     5,     3, 24506,  6299,  3592,    10,\n",
            "           101,   238,  9889,     8, 22057, 20123,    11,  3967, 10925, 16961,\n",
            "            21,  2116,  1260,   331,    30,    41,     9,    61,  7385,    13,\n",
            "          2847,  7765,   308,  4481,  1221,    28,  1676,     3, 26836,  6244,\n",
            "            49,  1497,    32,     7,   159,    42,    41,   115,    61,  5274,\n",
            "          1994,     6,  2833,  1707,     6,    42, 20544,   859,  2847,  7765,\n",
            "           308,  4481,  1221,    28,    11,   406,  1676,     3, 26836,  6244,\n",
            "            49,  1497,    32,     7,   159,     5,   101, 11338,     8,  7385,\n",
            "            13,  6244,    49,  1497,    32,     7,   159,  1221,     6,    11,\n",
            "             8,  5237,  1020,    41, 12224,    61,    21,   284,  2196,  6138,\n",
            "            13,  1046,     5,   101,   261,  6504,    18, 23677,     7,  2250,\n",
            "            12, 21603,    69,   331,     5,     3, 12200,  4254,  4578,    10,\n",
            "           101,     3, 31340,  6180, 22954,     3, 13903,     7,     6,    11,\n",
            "          1285,  8838,  2116,     6,    16,    69,  1132,     5,    37,  2201,\n",
            "            15,    26,  7037,    21,  7385,    13,  1676,     3, 26836,  6244,\n",
            "            49,  1497,    32,     7,   159,    47,     3, 12734,  6170, 14156,\n",
            "          2712,     3,  3597,     3, 22384,  4704,    18, 13606,  6370,   137,\n",
            "          2847,  7765,   308,  4481,  1221,    28,  6244,    49,  1497,    32,\n",
            "             7,   159,   141,     3,     9,  1146,  1020,    13, 20544,    41,\n",
            "          4078,    51,  1208,     3, 12224,  1300,  4271,     6,   668,  2712,\n",
            "             3,  3597,  1300,  4834,   104,  4416,  3288,     6,    45,  1003,\n",
            "          2116,    61,    11,    21,  5274,  2847,  7765,   308,  4481,  1994,\n",
            "            41,  4078,    51,  1208,     3, 12224,  1300,  4448,     6,   668,\n",
            "          2712,     3,  3597,  1300,  3076,   104, 24273,  4482,    45,   460,\n",
            "          2116,   201,    68,    59,    21,  2833,  1707,    41,  4078,    51,\n",
            "          1208,     3, 12224,  1300,  3840,     6,   668,  2712,     3,  3597,\n",
            "          4097,  4729,   104, 26195,  4347,    45,   662,  2116,   201,    38,\n",
            "             3,  2172,    12,  2847,  7765,   308,  4481,  1221,   406,  6244,\n",
            "            49,  1497,    32,     7,   159,     5,  8472,  8440,  3063,  9215,\n",
            "            10, 11383,     3, 26836,  6244,    49,  1497,    32,     7,   159,\n",
            "            19,  4352,  1017,   859,  2847,  7765,   308,  4481,  1221,    11,\n",
            "          5386,     8,  1020,    13,  5274,  2847,  7765,   308,  4481,    11,\n",
            "          2847,  7765,   308,  4481,    18,  3897, 20544,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[11383,     3, 26836,  6244,    49,  1497,    32,     7,   159,    11,\n",
            "          4301,   106,     9, 18095,  1994,  1360,    10,    71, 20036,  1132,\n",
            "            11, 10531,    18, 27557,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   37,   422,     3, 21585,    15,    13,     8,     3,  9905,  1655,\n",
            "            65, 14021,    12,    36,   399,   526,   179,  2017,   227,  3879,\n",
            "            12,  6758,     8,    95,  4914,    13,     3,  8135,  6159,    51,\n",
            "            18,  9942, 17133, 14063,    83,    77,     7,    38,   168,    38,\n",
            "           119, 11663, 23098,     7,     6,    11,  2640,     5,   611,     6,\n",
            "             8,  9272,  9398,    13,  1806, 12493,    16,   469,    22,     7,\n",
            "           554,   509,    75,  2936,     3,  9905,    19,    59,   801,     5,\n",
            "           101,  7922, 11515,    26,     3,  9905,  7677,  2017,   227,  3879,\n",
            "            11,    44,  8218,   107,   227,  3879,    28,  6400,   755,    18,\n",
            "          9339,   400,    26,   411,   208, 23703,    77,    41,   254,    63,\n",
            "           755,    18,   667,   900,    61,   258, 26048,    70,   422,     3,\n",
            "         21585,    15,    22,     7,   431,   104,   940,     3,   107,   865,\n",
            "             5,   304,  6570,   415,  1707,    13,  6400,   755,    18,   667,\n",
            "           900,    16,     8,   422, 24826,  9241,    17, 17801,   138,  2640,\n",
            "             6,    62,  3032, 17133, 10193,   235, 11366,   338,     3,     9,\n",
            "          3905,    32, 12088,  1774, 18156,    11,     3,     9, 11667,   414,\n",
            "            32,  5529, 18156,   718,     3,   102,   196,   122,   448,     6,\n",
            "             8,  1480,   414,    32, 10348,   138, 18156, 22730,   940,     6,\n",
            "            11,     8,     3,   120,     7,    32, 10348,   138, 18156,   301,\n",
            "         15837,  2292,     5,  6400,   755,    18,   667,   900,   576,    18,\n",
            "         16882,  1601,    28, 22730,   940,    11,   301, 15837,  2292,    16,\n",
            "             8,   146,    32,   537,   440,    11,   528,  6959,   440,    13,\n",
            "             3,  9498,   107,   625,    11,  8218,   107,   625,  7922, 11515,\n",
            "            26,     3,  9905,  7677,     6,    68,   163,    16,     8,     3,\n",
            "           699,   440,    13,     3,  9498,   107,  7922, 11515,    26,     3,\n",
            "          9905,  7677,     5,   506,   331,  3130,    24,  2426,    13,  6400,\n",
            "           755,    18,   667,   900,   190,     8,  1480,   414,    32,  5529,\n",
            "             7,    12,     8,     3,   120,     7,    32,  5529,     7,    47,\n",
            "           231,  3915,    16,     8,     3,   699,   440,    13,  8218,   107,\n",
            "          7922, 11515,    26,     3,  9905,  7677,     5,  6400,   755,    18,\n",
            "           667,   900,    47,     3,  6974,   915,    16,  9241,    17, 17801,\n",
            "           138,  2358, 18557,    11,  1855,   409,  1071,    32,   965,     6,\n",
            "            68,    34,   410,    59,   576, 16882,  1737,    28,     3,   102,\n",
            "           196,   122,   448,    18, 26093,   414,    32,  5529,     7,    16,\n",
            "             3,  9498,   107,    11,  8218,   107,  7922, 11515,    26,     3,\n",
            "          9905,  7677,     5, 27187,     7,    16, 11663,  4641,    15,  4866,\n",
            "            95,  4914,   640,     8,   315,  6266,    13,     8,   422,     3,\n",
            "         21585,    15,   227,   163,  8218,   107,   164,    36,   788,    12,\n",
            "          1884,  3026,    13,     3,  8135,     7,  8792, 11663, 23098,     7,\n",
            "             6,  1112,    16,     8,     3, 21585,    15,   788,    12,     3,\n",
            "         26289,    13,  6718,  1707,    57,  2179,    89,   322,     9,    11,\n",
            "            87,   127,     8,     3, 26289,    13,  1806,    18,  3903,  4334,\n",
            "             5, 17725,     8,  1675,   344,     8,   415,  1707,    13,  6400,\n",
            "           755,    18,   667,   900,    11,   422, 24826,     3, 31970,   485,\n",
            "           164,  4139,    12,     3, 12585,   823,  8759, 24639,    16,     8,\n",
            "         21118,    54, 29077,    30,     8,  3017,  4741,     3, 31970,   485,\n",
            "           274,  1806, 12493,    12,  2519,  9392,  1711,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[15186,    13, 24826, 11663,  4641,    15,  4866,   703, 15016,    16,\n",
            "          1021,     3,  9905,  7677,    12,  2576,   162,     8,   194,    12,\n",
            "          8759, 24639,    10, 17413,   772,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 1266,  4861,    10,  1326,    33,  5010,    12,   915,    48,  2908,\n",
            "            13,     8,  2639,  9859,  2984,     6,  5776,    11,  2569,    16,\n",
            "             8,   204,   727,  1331,  4379,    30,   638, 31148,   138,  5869,\n",
            "          2825,  1433,    11,  1284,    13,  9171,    41, 24291,   196,   196,\n",
            "            32,   382,   460,  2658,    61,    84,  1213,    30,  2083,  1902,\n",
            "         14962,     6,   460,  2884,    41,    77,   155,    23,  1427,  4355,\n",
            "            30,  1671,  1630,     3,   184, 12992,   460,  2658,    68,   442,\n",
            "          5041,    15,    26,   788,    12,  2847,  7765,   308,  2294,    61,\n",
            "            44,  1775,    13,  9885,     7,    11, 12788,  5623,     6,  1117,\n",
            "          7345,  7676,  2548,    13,  2854,    11,  3669,    41, 18206, 13582,\n",
            "           201,    71,  4312,     9, 12654, 22660,     6,  1547,     6,    16,\n",
            "          3561,    28,  1331,  2125,    13, 16682,  7137,    41,   196,   188,\n",
            "          3291,  4132,   201,  2312,     5,    41,  4302, 11788,  1309,    10,\n",
            "          2649,  1303,    23,  9920,    23,    32,    17,     5,    23,     9,\n",
            "          3974,     5,  1677,    87,     5,    61,   634,   204,   727,  1331,\n",
            "          4379,    30,   638, 31148,   138,  5869,  2825,  1433,    11,  1284,\n",
            "            13,  9171,    41, 24291,   196,   196,    32,   382,   460,  2658,\n",
            "            61,    19,     8,   204,   727,    16,     8,   939,    61,    19,\n",
            "             3,     9,  1585,    21,  4768,     6,  8702,     6,  2705,  7137,\n",
            "            38,   168,    38,  2913,  2481,    45,    66,   147,     8,   296,\n",
            "            12,   915,    70,   585,   772,    11,   606,  1087,    16,   638,\n",
            "         31148,   138,  5869,  2825,  1433,    11,  1284,    13,  9171,     5,\n",
            "            37,   605,    41, 24291,   196,   196,    32,   382,   460,  2658,\n",
            "            61,   808,   286,    16,  9279,   825,    11,     3, 12550,     3,\n",
            "          3232,   128,  5921,    12,   915,    70,  5778,  9114,   250,    13,\n",
            "           638,  6961,   104,  2294,    11,     8,   789,    22,     7, 19841,\n",
            "            30,   136,  7241,     5,   275,    57,    24,     6, 14250,     7,\n",
            "         20795,    70,  3148,     7,    28,  4768,    11,  4951,     8,  4290,\n",
            "           585,     5,    37,     3,    15,  1109,   295,  5812,     7,    11,\n",
            "          2273,    16,    70,  4120,   130,  5374,    12,  2156,    70,  5023,\n",
            "            44,     3, 24291,   196,   196,    32,   382,   460,  2658,     5,\n",
            "         21310,    13,  4292, 20542,  1361,   122,   297,     6, 30169,     6,\n",
            "         14252, 11953,     7,    33,   347,    16,    48,  9210,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  204,   727,  1331,  4379,    30,   638, 31148,   138,  5869,  2825,\n",
            "          1433,    11,  1284,    13,  9171,    41, 24291,   196,   196,    32,\n",
            "           382,   460,  2658,    61,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  100,  1108,  2075,     7,   572, 10524,   103,    59,  3531,    12,\n",
            "           452,  5856,   982,    16,     3,     9, 10063,  3107,    28,  2016,\n",
            "          7778,     6,    11,     8,  7702,    13,    70,  3338,    12,   103,\n",
            "            78,     5, 26358,    53,     3,     9,   495,   810,    13,  4338,\n",
            "         24639,  1291,     6,     8,  1108,  1099,     7,  3485,    89, 25481,\n",
            "             7,    11,     8,  2428,    13,     3, 19585,   533,  1291,    16,\n",
            "            46,  1246,    13,  1028,  6391,     5,    94,  3485,  2748,    15,\n",
            "             7,   192,  2254,    13,     3, 19585, 24639,  5856,    10,  7998,\n",
            "             6,    84,  2284,   452,  4222,    12,    16,  1497,  8367,     8,\n",
            "          2074,    28,     3, 30786, 18537,    11,  2869,     6,    11,  7246,\n",
            "           257,     6,    84,  2284,   592,    12,   452,  4222,    38,     3,\n",
            "             9,   607,    13,   610,     5,    37,  4338,   789,    16,  8993,\n",
            "           120,  8152,  7998,    21,     3,     9,   381,    13,   203,     5,\n",
            "         12741,     7,  3524,  4478,    11,  5102,   138, 17765,     3,     7,\n",
            "            17,    63,  2720,    26,   165,  2231,    12,  8000,     3,     9,\n",
            "          1516,  7352, 24639,  5856,   682,     5,   438,     3,     9,  1453,\n",
            "            13,   610,   147,     8,   251,  1164,     6, 24639,     7,   130,\n",
            "            59,  2098,   168,    57,  1215,  5255,  1162, 15093,     7,     6,\n",
            "             8,  9118,  6835,    13,     8,  1506,  4005,    11,   367,  1817,\n",
            "          6391,     5,   454, 31303,    57,   403,   449,   485,     6,  2136,\n",
            "            13,  2614,    11,  9241,   849,  3113, 31221,     6,     8,  4338,\n",
            "           789,   410,    59,  1822,     8,   452, 31841,    13,     8, 24639,\n",
            "          2486,     5,  3910,    13,  5936,    53,  5030,    12,     3, 30703,\n",
            "             3,     9,     3, 30669,  2074,     6,    79,  2937,    30,   358,\n",
            "           447,    11,  1929,   807,     6,   552,    34,    47,   396,  1480,\n",
            "            12,   103,   959,  3578,   143, 24639,     7, 13488,    41,  9381,\n",
            "          7246,   257,   137,    37, 10320,   710,    18,  1987,  1269,    13,\n",
            "            48,  3613,    16,     3, 11600,  2074,  5856,   405,    59,    21,\n",
            "            15, 16221,     8,   174,    21,  4912, 13059,    13, 12956,  3410,\n",
            "           190,  1231,  7998,     5,   100,    19,  6843,    21,     8,  2847,\n",
            "          7765,   308,  4481, 24639,  2066,     6,    28,   186,  4338,     7,\n",
            "           341,     3, 15716,    24,    79,   133,    59,  1845,     3,     9,\n",
            "         12956,     3,  3565,     8,    20,   900,  6682,    24,     8,  1994,\n",
            "            65,     3, 29286,  1019,    70,   684,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   86,  4787,     6,   365,    18,    60,  4787,  1041,    11,    16,\n",
            "          4010,     9,  6726,    10,  1901, 15568,    16,  5308,    31,     7,\n",
            "         24639, 13059,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 242,    3,    9,  960,  179,  988,   13,  175, 9838,    7,    6,  754,\n",
            "          719, 2442,    5,    9, 2935,  115,    7, 6471,   17,    7,    5, 1677,\n",
            "            5,    1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   71,  4545,  1193,   624,   122,  1433,  6503, 20114, 27239,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[23023,    10,   304,  6570,     8,  9570,    13,  7869,   205,  1058,\n",
            "           581,  4301,   106,     9, 18095,  1994,  1360,    41,  5911,  7765,\n",
            "           308,  4481,    61,  7717,     7,    10,   389,   539,    18,    40,\n",
            "         10333,     6,     3, 30027,     6,    11,  6478,  3689,    47,  4468,\n",
            "            30,  1221,    28,  5274,  2847,  7765,   308,  4481,  7952,     5,\n",
            "            37,   495,    11,   610,  1058,  1637,   284, 14280,    26,    13,\n",
            "           604,  1221,     5,    37,   610,   563,  1204,     3,  8745,    77,\n",
            "             9,  5771,    87,    52,   155,   106,     9,  5771,    11,     3,\n",
            "         30966,   524,   322,    32,  2436,   630,    11,     8,   495,   563,\n",
            "          1204,   306,    18, 12051,    13,  7869,   205,    41,     7,  2407,\n",
            "          3542,  1444,    61,   974,    12,     8,   337, 19299,     5, 12772,\n",
            "            10,   290,   130,   150, 11775,   120,  1516,  5859,   344,   192,\n",
            "          1637,    28,  1445,    12,  1246,    11,  7285,     6, 10343,   772,\n",
            "             6,    11,     3, 10067,  6716,     5,   461,     8,   220,     3,\n",
            "            52,    26,   239,    13,  2833,  1707,     6,     8,  1243,  2583,\n",
            "           643,  7902,    47,  4019,  1364,    11,  2526,   667,   357,    47,\n",
            "          1146,    86,     8,   495,   563,    41,   102,   701,  3274,     3,\n",
            "         10667,  4347,    11,     3, 11739,  2534,     6,  6898,   137,    37,\n",
            "         15572,  2475,    13,  2833,  1707,    16,   495,   563,    84,    47,\n",
            "          4019,  1200,   145,     8,   610,   563,    41, 19253,   477,     3,\n",
            "           208,     7,     5,     3, 17255,   477,    61,    41,   102,   701,\n",
            "          3274,     3, 11739, 17518,   137,   290,    47,   150,  1516,  1750,\n",
            "            16,  2526,   667,   357,  1425,    44, 12445,    97,     6,     8,\n",
            "          2475,    13,    27,  5211,  1049,     6,    11, 20544,   344,     8,\n",
            "           192,  1637,     5, 29197,     7,    10,     3,    10,   101,   410,\n",
            "            59,   253,  4019,   394,  6353,    16,     8,   563,   113,   130,\n",
            "          4260,    28,   306,    18, 12051,  7869,   205,    16,   811,    12,\n",
            "             8,   711,  1058, 19299,    44, 12445,     5, 20660,  3816,    10,\n",
            "            37,   516,    47,  3366,    57, 19143, 25656,    13, 14067, 20660,\n",
            "             7,     5,  5705,  6227,  1755, 21653, 19277, 27760,  1828,   567,\n",
            "           536,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 6859,    11, 18652,   655,    13,  1592,    18,  4135,     7,    15,\n",
            "         10368,   205,    16, 18027,    28,  2847,  7765,   308,  4481,   117,\n",
            "           188, 25942,  1601,  4330,  1361,   539,    18,    40, 10333, 14067,\n",
            "         20660,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 7333,  2748,    15,    86,     8,     3,  1498,    13,  2847,  7765,\n",
            "           308,  4481,     6,     8,     3,  1931,  3466,   155,    65,   582,\n",
            "             3,     9,  2404,   598,    13,  1260,  4640,    21,  1221,     3,\n",
            "          6319,    12,  2467,    16,    18,  6075,  8305,  4946,   189,    63,\n",
            "         10682,    29,    11,   659,  3741,   183,    63, 20253,    32,     7,\n",
            "           159,    33,  1561,  6716,     6,    24,  1457,  8325,    11,   885,\n",
            "          1130,    95,    37,  2674,    13,    48,   810,    47,    12,  6570,\n",
            "             8,  6637,    11,  9570,    13,     3,  1931,  3466,   155,  6326,\n",
            "             7,    21,  1221,    28, 16643,   183,    63, 20253,    32,     7,\n",
            "           159,    41,  4490,    61,   383,     8,  2847,  7765,   308,  4481,\n",
            "          2131,   221,  3113,  7717,     7,   100,    47,     3,     9, 11735,\n",
            "         23785,   810,    13, 12096,  1221,    28,  3087,   113,   130, 14434,\n",
            "            57,     3,  1931,  3466,   155,   344,  1332,    11,   932,     6,\n",
            "          6503,     6,    44,     3,     9,   508,  2705,  1035,  1530, 17656,\n",
            "         14798,     7,     6, 20726, 11208,    11,  1030,    13,     3,  1931,\n",
            "          3466,   155,  6326,     7,   130,  4759,    45,  3031,  1035,  3187,\n",
            "         18027,   130,  2348,    21,   220,   767,    45,    70,   166,     3,\n",
            "          1931,  3466,   155,    21,  7757,  1112,     6,    16,    18,  6075,\n",
            "          5998,  8305,     6,  2833,  7209,     7,     6,    11, 20544, 12772,\n",
            "         19636,    17,    63,    18,    15,  2632,  1221,    28,  3087,   130,\n",
            "          1285, 23045,  1246,    47,     3,  3959,   305,     2,  1298,   209,\n",
            "             3,    63,    52,     7,    11,     3,  4440,   130,  5069,    41,\n",
            "          2079,     3,  6370,    61,    37,   381,    13,     3,  1931,  3466,\n",
            "          7085,   399,  1868,    19,  2008,    16,  7996,   209,     9,  2035,\n",
            "          5354,  7393,     7,  1130,    18,   413,     6,  2208,  1221,    41,\n",
            "          2688,     3,  2712,    61,   130,   894,    21,   893,    46,    16,\n",
            "            18,  6075,  5998,   719,    42,   269,   842, 27594,  1707,   290,\n",
            "           130,   489,  3583,   562,  8305,     6,    13,    84,   314,  8457,\n",
            "           209,  6210,   741,    15,    26,    16,  2833,  7209,     6,   209,\n",
            "          1868,  4077,     3,  6932,    61,   141,  1317,  7209,     7,    11,\n",
            "           150,  1868,  3977,    41, 16691,   209,   115,    61, 14794,    13,\n",
            "             8,  2833,  7209,     7,  6935,   441,   192,  1274,    13,     3,\n",
            "             9,     3,  1931,  3466,   155,  4457,  7209,     7,   130,   788,\n",
            "            12,   842,  3338,  1215,     9,  2110,   115,   257,     6,   142,\n",
            "           102,     7,   159,     6, 12498, 11546,  2871,    11,    20, 10656,\n",
            "           257,  6980,    12, 28582,     3,  2092,  1130,    18,   413,     6,\n",
            "          1902,  1221,    41,  2773,     3,  2712,    61,   141,  7757, 14346,\n",
            "             6,   167,  5871,  1112,    16,  1227,  1462,  1225,    41,  4834,\n",
            "             3,  2712,    61,    11,  7590,    32,  5715,  1225,    32,    23,\n",
            "            26, 15102, 30619,    41,  4834,     3,  2712,    61,  6742,     7,\n",
            "          2759,  1221,   130,  6164, 16781,    30,     3,    17,     9,    89,\n",
            "             9, 16091,     7,     6,    21,  1058,    13,  3017,   189,    63,\n",
            "         10682,    29,  3087, 29197,    37,   169,    13,     3,  1931,  3466,\n",
            "          7085,    21,     8,   758,    13,  1221,    28,  3087,    19, 20218,\n",
            "             6,    11,     8,   731,  7209,  1080,  9379,    24,     3,  1931,\n",
            "          3466,  7085,    33,     3,     9,  1346,    11,  1231,   194,    12,\n",
            "          1865,  3087,  1221,    16,     8,    91, 10061,  1898,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   37, 29576,    13,  7338,  3466,  7085,    16, 18027,    28,  4955,\n",
            "            23,     9,    75, 13349, 20253,    32,     7,   159,   383,     8,\n",
            "          2847,  7765,   308,  4481,  4266,   221,  3113,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   86,  1480,  1882,  7887,  2847,  7765,   308,  4481,    47,   166,\n",
            "           120,  4771,    16, 17792,  2618,     6,  1473,    11,  3060,  7313,\n",
            "            12,    66,    13,     8,  7985,     7,    13,  1473,     5,    37,\n",
            "          1244, 15201,    13, 17792,  2618,  3545,  4457,     6,     8,  9943,\n",
            "          2833,    12,  6264,    11,  2665,     8,  5274,    11, 19302,     3,\n",
            "          1092,  2847,  7765,   308,  4481,  1488,     6,    65,  4260,     3,\n",
            "             9,   508,   381,    13,   224,  1221,    28,   248,  1269,    11,\n",
            "          5105,  1995,    13,  3435,  2704,     3,   390,    30,     8,  2830,\n",
            "          1539,   747,    41,   553, 26346,   137,   304,  1068,  1737,    11,\n",
            "           698,     8,  1058,  4293,    13,  5274,    11, 19302,     3,  1092,\n",
            "          1488,     6, 17792,  2618,  3545,  4457,    65,  2127,     3,     9,\n",
            "           464,   563,    11,     3, 23148,    46,  7763, 10919,     6,   379,\n",
            "             8,  4891,     6,   778,  6337, 15600,     6,    11,   633,  1058,\n",
            "          5559,    21,  5274,    11, 19302,     3,  1092,  1488,     5,    37,\n",
            "          1058,  2704,   164,   370,   128, 21479,  5782,    21, 10902,     8,\n",
            "          5274,    11, 19302,     3,  1092,  2847,  7765,   308,  4481,  1488,\n",
            "            66,   147,     8,   296,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 4292,  6361,    83,   920, 14067,  7187,     7,    45, 24739, 13516,\n",
            "            13,  1179,  4013,   679,   624,    15,    11, 23208,   120,    27,\n",
            "           195,  2847,  7765,   308,  4481,  6320,     7,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  100,  6478,   810,     3,  8287,    12,  3613,  6145,     7,    13,\n",
            "         20649,     9,    26,    32,    40,    41, 11359,    61,    11,   165,\n",
            "           192,   711,     3, 27787,  7006,     6,   445,    18,  1395, 22758,\n",
            "          1313, 11374,    32,    40,    41, 10604,  7323,    61,    11,   411,\n",
            "            18,  1395, 22758,  1313, 11374,    32,    40,    41,  7039,  7323,\n",
            "           201,    16,  1268,   826,     3,     9,   712,  6742,    16, 24899,\n",
            "            11,    12,  9127,     8,  3438,  4264,    16,  1268,    57,  5508,\n",
            "           138,  1693,    13,  1268,  5977,  1026,    44,   633, 17222,    97,\n",
            "           979,   227,    16, 24899,     5,   389,  8759,  6742,    41,  1752,\n",
            "            42,   910,    51,   122,    61,    13,     3, 11359,    47, 19092,\n",
            "            12,  1003,  1695,  6496,     5, 11716,  5977,   130,  4759,  1884,\n",
            "            12,  2672,  3602,    11, 11363, 11558,  1640,    11,  5864,   477,\n",
            "           227,    16, 24899,     5,  1698,  3106,    47,  5508,    15,    26,\n",
            "            16,   305,   635, 15107,    11,    47,    88,    26,     5,    37,\n",
            "            46,     9,   120,  1422,   130, 21527,    45,     3,  4801,   624,\n",
            "          1601,  1268,    57,    16, 16377,  1575,    16, 16629,   783,    21,\n",
            "           507,   107,    44,  6862,  1956,   254,     5,    71, 16742,    26,\n",
            "           412, 13201,  6480,    18,  4211,    87,  4211,  1573,    47,   261,\n",
            "            12, 30389,     8,    46,     9,   120,  1422,    44,     3,     9,\n",
            "           301,  5017,  2247,    13,     3, 10667,   536,  1725,    87,    51,\n",
            "           122,     5, 11716, 15107,     3,  9921,    12,     8,    97,    13,\n",
            "            16, 24899,   130,  1465,    21,     3, 11359,    11,     8,     3,\n",
            "         27787,  7006,    13,   284, 17222,    97,   500,     6,  2199, 10678,\n",
            "            53, 15107,    92,  3217,  1465,   772,     5,    37,  2030,  6145,\n",
            "             7,    21,   321, 17166,  1637,   130,  6970,    16,     8,     3,\n",
            "         20042,    23,  1982,  5508,    13,  1268,  4759,   968,   477,   227,\n",
            "            16, 24899,    21,    66,  7404,    10,  4097,  5176, 18930,     5,\n",
            "          3301,  1725,     3, 11359,    87,    51,   122,     6,  4097,  4542,\n",
            "         19423,     5,  3840,  1725,     3, 10604,  7323,    87,    51,   122,\n",
            "            11,     3, 10667,  1298,    18, 16029,   940,  1725,     3,  7039,\n",
            "          7323,    87,    51,   122,    41,    29,  2423,  2938,   137,     3,\n",
            "         15072,     6,     8,     3, 11359,  6145,    47,  1146,   145,     8,\n",
            "             3, 27787,  7006,  6145,     7,    68,  6002,    15,    26,    30,\n",
            "             8,     3, 17063,   345,   357,   308,   948,     3, 19017,    32,\n",
            "          6137,     5,    37,     3, 27787,   155,    15,    12,     3, 11359,\n",
            "          5688,     7,   130,  5711,   441,     3,     9,  1426,   147,     8,\n",
            "         17222,    97,   979,     6,   983,    34, 10535,  6891,   344,  7404,\n",
            "             5,   465,  1516,  5859,    16,  1268,  6145,     7,   130,   435,\n",
            "           344,     8,   192, 17166,  1637,    44,   284, 17222,    97,     5,\n",
            "             3,  8656,   975, 19732,    53,  2580,   130,  4313,   224,    38,\n",
            "          1268, 17151,   257,    11,  3224, 10242,     5,   101,  3217,    24,\n",
            "          1693,    13,   305,   635, 15107,  3798,     8, 11444,    13,     8,\n",
            "          4773,    97,   227,     3,     9,   712,    16, 24899,    13,     3,\n",
            "         11359,     5,    86,   811,     6,    16,     8,   865, 17222,    97,\n",
            "           979,     8,    46,     9,   120,  1422,   130,  3060,    72,   344,\n",
            "         15107,    11,     8,   792,  2672,   866,    13,   284,   865, 17222,\n",
            "            97,   500, 14833,    95,    12,     3,     9,  2349,    41,  8172,\n",
            "            29,    10,  6374,  6210,   788,    12,  6179,    91,     5,    37,\n",
            "          2569,   772,    33,   359,   811,     7,    12,     8, 14144,     7,\n",
            "            15,  6678,  5099,   712,  6742,    13,  8423,  6645,  4845,    16,\n",
            "          1268,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[27695,  4900,  4264,    13, 20649,     9,    26,    32,    40,    16,\n",
            "          1268,   227,     3,     9,   712,  6742,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 2255,  1409,    17,   440,   440,     9,   115,    41,   382,    15,\n",
            "           855, 19485,   201,    46, 16681,    18,  2376,  1170,  2945,   686,\n",
            "           209, 15102, 30619,     6,    47,  3754,    21,  1058,    13, 26054,\n",
            "          1580,  1994,    16,  6503,     5,  2255,  1409,    17,   440,   440,\n",
            "             9,   115,    19, 19092,  6344,  1926, 11937,   334,   220,  1274,\n",
            "            21,     3,     9,   792,    13,  2641,  6742,     7,     5,  7155,\n",
            "           596,  1951,   560, 25808,     6,  1227,   291,    52,   107,    32,\n",
            "            15,     9,     6,  5467,  4174,     7,    51,     7,     6,  3507,\n",
            "         22018,     6, 16633,   397,   302,    23,     9,     6, 12085,     7,\n",
            "             6,  2192,  1133,     6,    16,  7316, 14081,    11,  6676,   122,\n",
            "           120,   658, 11658,     5,   101,   934,   270,     3,     9,     3,\n",
            "          3959,    18,  1201,    18,  1490,   388,    28, 15199,    15,     7,\n",
            "            18,  3897, 26054,  1580,  1994,   113,  1597,     3,     9,  7313,\n",
            "          9018, 12368,  7198,   227,  4281,   662,    91,    13,  2641,  6742,\n",
            "             7,    13,     3,    17,    15,  1409,    17,   440,   440,     9,\n",
            "           115,    41,  6361,    83,  1528,  6742,   314, 26898,  5453,   137,\n",
            "           216,    47, 10246,    21,   161,   413,    11,     3,    17,    15,\n",
            "          1409,    17,   440,   440,     9,   115,    16,  7316,     7,   130,\n",
            "         28723,     5,  9874,     9,   162, 10529,     3, 13492,   509,  5715,\n",
            "          1225, 19721,    11, 17133, 14063,    83,    77,   130,   787,    84,\n",
            "          3217,   150,  4179,    16,  3739,  3976,     5,   216,     3, 14064,\n",
            "           365, 16103, 18309,   102,    88,    60,     7,   159,    28,  3161,\n",
            "            13,   112,  3976,     6, 15495,     3,     9,     3,    17,    15,\n",
            "          1409,    17,   440,   440,     9,   115,    18, 14515,     3,  1433,\n",
            "         21367, 23599,     5,  9006,  2116,     3,  6475,  2186, 11683,    11,\n",
            "          1200,  8659,     7,    33,   906,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[13836,   120,  9018, 12368,  7198,  1968,    28,     3,    17,    15,\n",
            "          1409,    17,   440,   440,     9,   115,    16, 26054,  1580,  1994,\n",
            "             1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[    3, 26953, 18256,  4630, 13110,    10,  1027,    63,  3881,   553,\n",
            "            18,   308,     6,     3,     9,  6642,    18,   390, 12956,     6,\n",
            "          3217, 12894,  1455,    11, 17133, 17890,   485,    16,     3,     9,\n",
            "          3944,  7739,  3689,     5,   101,   230,   934,     8, 20003, 13577,\n",
            "           447,  4710,   772,    13,  3944,   220,  3739,  3689,    28,  1027,\n",
            "            63,  3881,   553,    18,   308, 12956,    16,  1547,     5,     3,\n",
            "         24506,  6299,  3592,    10,   101,  4468,    46, 20003,  1693,    13,\n",
            "             3,     9,  1249,  3728,    60,     6,  1486,    18, 21746,    26,\n",
            "             6,  6504,  3375,     6, 27346,    18, 20388,  3944,   220,  3689,\n",
            "            44,  9526, 11441,    16,  1547,     5, 19188,  3008,  9742,    44,\n",
            "           709,   586,   203,   130,     3, 15097,    11, 21306,  7604,  4077,\n",
            "            10,  6982,    12,   911,   893,  1027,    63,  3881,   208,    18,\n",
            "           308, 12956,    41,   254,     9,    26,   173,     9, 16254,   117,\n",
            "           204,  5453,   399,  6742,    61,    42, 27346,     5,   389,  6076,\n",
            "           765,  1773,   358,    47,   261,    21,  6504,  2121,    41, 10734,\n",
            "             7,    13,   662,    61,    13,  3008,    38,   168,    38,    12,\n",
            "             3,    35,  3491,   273,  9742,  1640,   203,    11,  2749,    28,\n",
            "            42,   406,     3,   287,   127,  9824,  1124,     6,    11,   273,\n",
            "          9742,   586,   104,  2517,   203,     5,    94,    47,    92,   261,\n",
            "            12,  2862,  7366,  3008,    21, 17133, 17890,   485,    41, 10734,\n",
            "             7,    13,  1296,   137, 19204,     6, 16273,     7,     6,    11,\n",
            "          6138,  6570,   127,     7,   130,     3,    51, 23552,    12,  1058,\n",
            "          9587,     5,  5245,  6742,     7,    13, 12956,    42, 27346,   130,\n",
            "         19092,  6344, 23253,  6073,  1009,     3,     9, 11769,    18,  2113,\n",
            "         10672,   358,  2059,   477,  3943,     5,    37,  2329,  6138,    47,\n",
            "             8,   381,    13,  3008,    28,   166,     3, 16526,    13,     3,\n",
            "         18018,  6049,     3,  5934,    18, 23165,    18, 26093,  2847,  7765,\n",
            "           308,  4481,  2059,   477,   227,     8,  1025,  6742,     6,   552,\n",
            "             8,  7774,   381,    13,  1488,    41,  3870,   603,  1693,     3,\n",
            "            29,  2423,  4440,     6,   423,  1693,     3,    29,  2423, 26556,\n",
            "            61,    43,   118,  5153,     5,    37,  1693,    47,   612,    16,\n",
            "             8,   399,    18,  1409,   235,  3297,  2074,     6,    84, 14280,\n",
            "            26,    13,    66,  3008,    28,  2841, 20726,   180, 25210,    18,\n",
            "          3881,   553,  4949,  2637,   113,  1204,   386,  6742,     7,    13,\n",
            "         12956,    42, 27346,     5, 15186,    13,  1455,    11,    12,  1171,\n",
            "          2020,    47,     3,   390,    30,     8,  1455,  2074,     6,    84,\n",
            "         14280,    26,    13,    66,     3, 15097,  3008,   113,   130,   801,\n",
            "            12,    43,  1204,    44,   709,    80,  6742,    13,   810, 12956,\n",
            "            42, 27346,     5,   100,  3689,    19,  3366,    28, 14067, 20660,\n",
            "         25656,  1547,     6,   205, 16840, 20173,  2658, 29511,   632, 23702,\n",
            "          2938,     6,    11,    19,  4912,     5,   377, 13885,  2365,   134,\n",
            "            10, 13095,  3049, 11940,    11,  1515, 12992,   460,  2658,    41,\n",
            "          6757,  1340,  1647,   201,  5400,   957,   591,  1742,   130,     3,\n",
            "         22529,     6,    13,  4068,  9065,  4853,   410,    59,   942,  7468,\n",
            "          6683,    11,  2307,  2861,   519,   130,     3, 15097,    11, 21306,\n",
            "          7604,    12,   911,  1027,    63,  3881,   553,    18,   308,    41,\n",
            "            29,  2423,  2368, 11989,  6982,    42, 27346,    41,    29,  2423,\n",
            "          2368, 11989, 15070,  1915,    18,  1409,   235,  3297,     6,     3,\n",
            "          4959,  1488,   130,  5573,    11,  1285,    16, 13577,   447,  4710,\n",
            "          1693, 17543,    13,   586, 10239,    16,     8,  1027,    63,  3881,\n",
            "           553,    18,   308,   563,    11,     3,  4241,    13,   586,     3,\n",
            "         15003,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[    3, 29421,   447,  4710,     6,  1455,     6,    11, 17133, 17890,\n",
            "           485,    13,     8,  6642,   180, 25210,    18,  3881,   553,  4949,\n",
            "         12956,    41,   956,    63,  3881,   553,    18,   308,    61,    10,\n",
            "             8, 20003, 13577,   447,  4710,   772,    13,     3,     9,  3944,\n",
            "          6180,  6504,  3375,     6,  1486,    18, 21746,    26,     6, 27346,\n",
            "            18, 20388,   810,    16,  1547,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[31109, 22018,   164,    36,  1968,    28, 19311,   102,   127,    77,\n",
            "          4278, 27198,  1465,    41, 23927,   345,   591,  1220,    61,   445,\n",
            "          5365,  7331,     6,  1989,   213,   132,    19,  8304, 24387,     6,\n",
            "         11736,   302,   580,    32,  4078,     6,    42,     3, 13958,     9,\n",
            "          3113,  9683,     5,    94,    19, 19363,    12,   125,  5996,    48,\n",
            "         15037,   164,    36,  2665,   179,   227,   767,    12,   203,     5,\n",
            "           101,  5530,   192,  1488,    13,     3, 23927,   345,   591,  1220,\n",
            "           445,  5365,  7331,    28, 12368, 22018, 17358,    53,   147,    72,\n",
            "           145,   431,   767,     6,   213, 23179,  4749,  3798,   227,     3,\n",
            "            15,  1497,    23, 19001,     9,   115,    47, 16781,     5,    86,\n",
            "             8,   166,   495,     6,     3,     9, 11696,    18,  1201,    18,\n",
            "          1490,  2335,  2569,    28,     3,     9,  8401,  7393,   892,    13,\n",
            "         12368,  7198,    11,    44,  8606,     9,     6,    11, 17443,  9683,\n",
            "            13,     8, 11736,   302,   580,    32,  4078,    30,     3, 19045,\n",
            "             5,     3, 23927,   345,   591, 27198,  2505,  3666,  1465,     5,\n",
            "         31109, 22018,   399, 15777,    30,  3918,    28,    82,   509, 31411,\n",
            "           342,     6,   258,     3,    52,   155,  3090,   603,     9,   115,\n",
            "             5,   451,    47, 17785,    12,     3,    15,  1497,    23, 19001,\n",
            "             9,   115,    45,     3,    52,   155,  3090,   603,     9,   115,\n",
            "           507,   767,   227,  1994,     3, 26558,   250,    13, 20974, 18310,\n",
            "          5854, 13224,     7,   117,  2594,    11, 12368,  1681,  3798,    30,\n",
            "             3,    15,  1497,    23, 19001,     9,   115,     5,    86,     8,\n",
            "           511,   495,     6,     3,     9,  2208,    18,  1201,    18,  1490,\n",
            "          2335,  7513,  2569,    28,  3176,     6, 17271,    63,    11, 28358,\n",
            "          6358,  6809,    29,  1628,     6,    11, 22018,    16,  1087,    13,\n",
            "          1444,   840,     6,    11,    47,   787,     3,     9,  8209,    13,\n",
            "         31926,     5, 19636,   767,   865,   255,    47,  2833,  1601,    21,\n",
            "          3094, 12413,     5,     3, 19045,  3217,    90,  1598,    32,  1433,\n",
            "         21367, 23599,    11, 17443,  9683,    13,     8, 11736,   302,   580,\n",
            "            32,  4078,    28,  1317,     3, 14762,   580,    32,     7,   138,\n",
            "           110,  2865,     5,     3, 23927,   345,   591, 27198,  2505,    47,\n",
            "          1465,    11,   205,  7016,  2505,    21,   119, 26907,    13,     3,\n",
            "         31650,     3,  1433,  6977, 24101,    47,  2841,     5,   451,   141,\n",
            "           128,  4179,    16, 23179,  4749,    28,   306,  6742,  4301,  1225,\n",
            "            32,  1370, 19721,    68,     3,  7361,  4019, 23484,     5,   461,\n",
            "          1130,    18,   413,     6,   160,  6103,     3, 19045,  3217,     3,\n",
            "             9,   422,   126,   269,    16,  1010,    32,  8172,    40,   851,\n",
            "           138,     3, 14762,    90,  1938,  2199,   255,   410,    59, 15524,\n",
            "            13,   136,   126, 12368,   807,     6,   160,  7109,  4490,  2604,\n",
            "            47,  1401,    87,  1458,     6,    11,   255,    47,   708,    30,\n",
            "             3,    15,  1497,    23, 19001,     9,   115,     5,  2759,   767,\n",
            "           227,     3,    15,  1497,    23, 19001,     9,   115,     3, 26289,\n",
            "           255,    11,   160,   384,  2196, 12368,  4179,    11,  7109,  4490,\n",
            "          2604,    47,   944,    87,  1458,     5,  7155,   753,    13,   175,\n",
            "           192,  1488,  1285,  3616,   580,    32,     7,   138,  9683,    11,\n",
            "            46,  3282,    13,  4912,  7922,    26, 12057,  2552, 15220,    30,\n",
            "             3, 19045,     5,   421,   351,  6490,     8,  5113,    24, 12368,\n",
            "         22018,   164,    36,   183,    35,   179,    12, 17133, 10896,    16,\n",
            "           824,  1488,    13,   445,  5365,  7331,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[30393, 31109, 14472,  2256,   297,    16,     3, 23927,   345,   591,\n",
            "          1220,   445,  5365,  7331,   438, 22218,    16,   205, 12905,  1575,\n",
            "            30,   262,  1497,    23, 19001,     9,   115,    10,    71,  3750,\n",
            "            13,  2759,  6320,     7,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[    3, 26953, 18256,  4630, 13110,  3430,     3, 10744,  6294, 22177,\n",
            "            10, 13836, 18787,    13,     3, 15267,  4035,  5715,  2258,   509,\n",
            "             7,   159,    65,  5597,     8,  2557,  4640,   358,     3,     9,\n",
            "         12342,     8,  4301,   106,     9, 18095,  1994,  4481,    41,  5911,\n",
            "          7765,   308,  4481,    61,  2131,   221,  3113,     5,     3, 13151,\n",
            "             6,   132,    19,    46, 10839,   174,    12,   253,     8,  1020,\n",
            "          2580,    21,     8, 12914,  3098,    16,  1488,    13,     3, 15267,\n",
            "          4035,  5715,  2258,   509,     7,   159,   859,  2847,  7765,   308,\n",
            "          4481,  1221,     5,   100,   810,     3,  8287,    12,   253,  4462,\n",
            "          1020,  2580,    21,     8, 12914, 18787,    13,     3, 15267,  4035,\n",
            "          5715,  2258,   509,     7,   159,    16,  1547,  4800,  5946, 15397,\n",
            "           134,  3430,     3, 24506,  6299,  3592,    10,   100,   495,    18,\n",
            "         15247,   810,  1285,     3,  4013,  1488,    13,  2847,  7765,   308,\n",
            "          4481,  1968,  4035,  5715,  2258,   509,     7,   159,    41, 21907,\n",
            "            61,   113,     3, 10304,     8,  7415,    41,  2128,  7415,    61,\n",
            "            16,  1353,    13,  1246,     3,     6,  7285,     6,    11,  2847,\n",
            "          7765,   308,  4481,  1994, 20363,     5,    37,   610,   563,  1285,\n",
            "          7404,    24,     3, 10304,  7415,   406,  4035,  5715,  2258,   509,\n",
            "             7,   159,  5899,    57,  7211, 20267,    18,  3233,    63,   526,\n",
            "         15447,  3741,  6363,    44,    69,     3,   449,    17,    23,  1208,\n",
            "           124,  1530,   383,  1186,    18, 15881,   460,  2658,     5,   749,\n",
            "           115,   179,   554, 10475,    32,     7,    53,  2580,     6,   224,\n",
            "            38,  8659,    13,  8363,   140,   195,   155,   302,    41,  7407,\n",
            "           201,   892,    13,  1100,  2833,  1707,     6,  8659,    13,  2833,\n",
            "          1049,     6,  2175,    13,     8,  1204, 11035,  8839,   257,     6,\n",
            "            11,   169,    13, 29867,     6, 19347,     6,  7869,     3,    75,\n",
            "             6,    11,   136,   119,   806,  4845,   130,  4759,    11,     3,\n",
            "          2172,   344,     8,   192,  1637,     5,     3,  7371,     6,     8,\n",
            "         10343,  8755,     6,   114,     3,   122,   120,    75,   920, 24731,\n",
            "         14063,    77,    41,   566,   115,   188,   536,    75,   201,  1385,\n",
            "          6280,   205,    18,    60,  6645,  3619,    41,   107,     7,    18,\n",
            "          4545,   345,   201,    11,     3,  4203,   189,    52, 24339, 23474,\n",
            "           257,  1080,    41,  3205,   448,    61,   130,     3, 16466,    12,\n",
            "           253,    91,     8,  1516,  6028,    28,     3, 21907,     3, 12200,\n",
            "          4254,  4578,    10,     3,  7407,    41,   667,    26,    26,     7,\n",
            "          5688,  2423,   940,     5,   940,     6,   668,  2712,     3,  3597,\n",
            "          1877,  1458,  6996,     5,  2122,   117,   276,  2423,     2,  5311,\n",
            "          6982,    11,   306,     3,   122,   120,    75,   920, 24731, 14063,\n",
            "            77,   593,    41,   566,   115,   188,   536,    75,  3155, 15731,\n",
            "             3,   122,    51,     3,  6210,    41,    32,    26,    26,     7,\n",
            "          5688,  2423, 23913,     6,   668,  2712,     3,  3597,     3, 14912,\n",
            "          4949, 29045,   117,   276,  2423, 11739,  2534,    61,   130,  1516,\n",
            "          1020,  2580,    21,     8,   606,    13,     3, 15267,  4035,  5715,\n",
            "          2258,   509,     7,   159,   859,     8,  2847,  7765,   308,  4481,\n",
            "          1488,     5,    71,  1146,   381,    13,  8248,  2847,  7765,   308,\n",
            "          4481,  1488,  1597,     3, 21907,     6,     3,  2172,    12,     8,\n",
            "          8107,    12,  5274,  1488,    41,  3390,     5,  6170,     3,   208,\n",
            "             7,  1283,     5,  5170,   137,  2048,    13,   358,   447,  4301,\n",
            "          1225,    32,  1370, 19721,    41,    32,    26,    26,  5688,  2423,\n",
            "           755,    28,   668,  2712,     3,  3597,  8613, 10892,     5,  1298,\n",
            "           117,   276,  2423, 10667, 12703,    47,   435,    12,    36,     3,\n",
            "             9,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  368,    18, 26558,  6676,   122,   120,   658, 11658,    11, 22914,\n",
            "           358,   447,  4301,  1225,    32,  1370, 19721,  3918,    16,  8248,\n",
            "          2847,  7765,   308,  4481,  1221,    38,   779,  1020,  2580,    21,\n",
            "             3, 15267,  4035,  5715,  2258,   509,     7,   159,    10,     3,\n",
            "             9, 17413,   810,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 3388, 22749,   308,  6463,  9562,    10,    37,  2847,  7765,   308,\n",
            "          4481,  2131,   221,  3113,   741,    15,    26,    16,  1516,  4640,\n",
            "             3,    60, 17939,  1628,     6,  6149, 11214,  1068,  1035,   124,\n",
            "             5,   101, 18277,     8,  1113,    13,     8,  2847,  7765,   308,\n",
            "          4481,  2131,   221,  3113,    30, 12498,  9529,   124,   463,    11,\n",
            "          3739,  6353,    12,  8432,  4640,   358,    31,     7,  4782, 14694,\n",
            "             7,    45,     3,     9, 23871,   500,    13,   903,     5,     3,\n",
            "         24506,  6299,  3592,    10,  4737,    15,    26,    18,  6757,  1693,\n",
            "           344,     3,     9, 11735,  2982,    18,   390, 13488, 20810,    13,\n",
            "         12498,  9529,     6, 15118,  3721,  2149,    41, 20804,    61,  3187,\n",
            "             6,    11,  1444, 20588,    13,  2847,  7765,   308,  4481,    16,\n",
            "          3431,   138,  8008,    41,   134, 13585,    29,   137,   101,  1285,\n",
            "            66,  9529,  1081,  5817,  1628,   383,     8,  2131,   221,  3113,\n",
            "            41, 25019,   627,   104, 15881,  3547,  6503,    61,    11,    46,\n",
            "          5299, 13422,   232,    15,  3113,  1059,    41, 30404,  2208,   104,\n",
            "         25019, 11363,  6503,   137, 14542,  6353,   130,  9529,  1081,  5817,\n",
            "          1628,    11,  3852,    49,  7316, 19571,    16,   321,  8811,     5,\n",
            "         24420,  6353,  1285,  3739,  6803,     6, 16101, 15905,     6,  5859,\n",
            "           640,  1308,    13,  9529,  6881,     6, 18712,  1693,   344,  5547,\n",
            "             3, 20804,  5685,     7,     6,  2847,  7765,   308,  4481,  1488,\n",
            "             6,    11, 16101, 15905,     6,    11,  1113,    30, 20544,    11,\n",
            "          3739,  6138,    44,  2777,   477,     5,     3, 12200,  4254,  4578,\n",
            "            10,  5500,  1825,    15,  1081,  5817,  1628, 13665,    57,   204,\n",
            "          5406,    11,  3852,    49,  7316, 19571,  6292,    57,   204,  7561,\n",
            "           383,     8,  2131,   221,  3113,  1059,     6,    28,   150,  5859,\n",
            "            16,  1246,     6,  9529, 20363,     6,    42,   508, 12662,     3,\n",
            "            32,    75, 11593,     5,  2571,     7,    12,     3, 20804,   130,\n",
            "         10298,  6426,  3519,   865,     6,    11,    97,    45,     3, 26558,\n",
            "            12,  2833,  6870,  1936,    57, 12210,  3519,     6,    28,  1516,\n",
            "         18712,     7,   344,  5547,  2847,  7765,   308,  4481,  1488,    11,\n",
            "            72,     3, 20804,  3088,    41,    52,   107,    32,  3274,  4097,\n",
            "          4959,   201,   705,  9529,  1081,  5817,  1628,    41,    52,   107,\n",
            "            32,  3274,     3,     2, 19997, 12703,     6,    11,  1200,   554,\n",
            "         31386, 16735,    41,    52,   107,    32,  3274,  4097,  1828,   137,\n",
            "          7338, 24790,  6881,   130,     3,  4127,  2176,  1054,    28,  1146,\n",
            "          4709,     7,    16,  9529,  1081,  5817,  1628,     6,  3852,    49,\n",
            "          7316,  5872,     6, 10979,     7,    12,   414,    32, 15100,  6881,\n",
            "             6,    11,  1936, 16735,    12,     3,  8514,  6310, 14991,     7,\n",
            "             5,    37,  2547, 11007,    13,  1687,  1936,    41,  2990,     3,\n",
            "         15062,   784, 12734,   755,   104, 17638, 13679,     3,   102,     3,\n",
            "         11739,  5268,    11,   207,  5014,  6138, 13665,    41,    51,  5249,\n",
            "             3,     2,   357,    44,  2777,   477,    10,  4674,     3, 22787,\n",
            "           784, 22776,   104, 23758, 13679,     3,   102,     3, 11739,  1808,\n",
            "            61,   383,     8,  2131,   221,  3113,  1059,     5,  8472,  8440,\n",
            "          3063,  9215,    10,     3,  2092,     8,  2847,  7765,   308,  4481,\n",
            "          2131,   221,  3113,     6,  3431,   138,  8008,    31,     7,  9529,\n",
            "           358,    31,     7,  5676,   222,   979,   130,     8,  7230,    12,\n",
            "             3, 20804,  5685,    11,     3,     9,  7198,    13,  9529,  1081,\n",
            "          5817,  1628,     6,  3852,    49,  7316,  5872,     6,    11,  1413,\n",
            "         31386, 16319,     6,  3323,    44,   415,  6881,     5, 18027,  5706,\n",
            "            46, 12498,  9529,   383,     8,  2131,   221,  3113,  1059,   141,\n",
            "          1146,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[25921, 14694,     7,    16,     8,    71, 15835,  5500,  1825,    15,\n",
            "          2686,  2149,   383,     8,  2847,  7765,   308,  4481,  4266,   221,\n",
            "          3113,    16,  3431,   138,  8008,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[28045, 18095,    15,     7,    43,   118,     3,     9,   779,  5888,\n",
            "            12,   452,   533, 13448,   437,   336,  4160, 28045, 18095,    15,\n",
            "             7,    33, 14669,    26,    11,  1465,    18, 12797,    15,    26,\n",
            "             3, 11840, 22213,   621,   180, 25210,    11,   283,  9984,     6,\n",
            "           180, 25210,    18,  3881,   553,  4949,    19,     8,  1025,   801,\n",
            "          4301,   106,     9, 18095,     3,  5885, 12699, 19944,  6716,    16,\n",
            "          6917,    86,     8,  2332,  1726,    13,   180, 25210,    18,  3881,\n",
            "           553,  4949,  7952,     6,  3739,   753,    33,   882,   529,  9500,\n",
            "            11,    59,    66, 18024,  1221,    54,    36,  5285,    12, 17981,\n",
            "            42,  3606,     8,  8209,    37,  3739,   503,    13,     8,  1994,\n",
            "           164,  1137,  1112,    16, 10343,  8755,  8840, 10356,    13,   212,\n",
            "           302,  1528,  3102,   180, 25210,    18,  3881,   553,  4949,    11,\n",
            "          4891,     8,  1717,  2392, 14676,  8755,  1691,    16,  4193,    13,\n",
            "          1994, 20363,    11,  2757,  4891,    13,     8,  1994,    86,    48,\n",
            "          1132,     6,     8,   585,  2116,    30,  2392, 14676, 17334,    16,\n",
            "          2847,  7765,   308,  4481,  6501,  2664,     7,    17,  1660,  6503,\n",
            "            33,     3, 31340,    11,  2639,  2984,    33,  9112,   506,   331,\n",
            "            33,  2033,   359,    16,     3, 20861,     8,  9009,    13,     8,\n",
            "          1994,     6,   813,  6715,     7,   159,    11,     3, 26243, 12206,\n",
            "         14418,    86,     8,   903,    13,    24,     8,   915,   810,     3,\n",
            "          8287,    12,  2497,     8,  1113,    13,  2392, 14676, 17334,    16,\n",
            "          2847,  7765,   308,  4481,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[14906,    13,  2847,  7765,   308,  4481,    30,  2392, 14676,  8755,\n",
            "            10,     3,     9,  8109,  1132,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  276, 11982, 19968,    63,  6105,    13, 16686, 13167,  4657,    38,\n",
            "             3,     9,  8253,  8557,   383,     8,  6344, 10791,   280,  4005,\n",
            "            13,    16,    89,  7633, 19601,     5,   290,    19,  2459,     3,\n",
            "             9, 13840,   174,    12,  1344,     3,     9,  1573,    12,  8877,\n",
            "          3990,  4921,    11, 12812,     3, 19787, 21826,    15,     7,     3,\n",
            "          9942,    45, 16686, 14219,    16, 11432,  5977,     5,    86,    48,\n",
            "           810,     6,    62, 11411,   276, 11982,    18,  2408,   748,    12,\n",
            "          8341,     8,  5014,     3, 19787, 12973,   257,    13,     8,   206,\n",
            "          2482,    32,  4010,     7,    23,    26,  3619,    41,   567,  3619,\n",
            "           117,     3,  9082,    61,    13,  5274, 19944, 12398,  4301,   106,\n",
            "             9, 18095,   204,    41,   134, 25210,    18,  3881,   553,    18,\n",
            "         15070,  1813,  4900, 14219,   130,  4759,    45,  1543,  1355,    29,\n",
            "           144,  2366,    13,   180, 25210,    18,  3881,   553,  4949,    18,\n",
            "            77,    89,  7633,   781,    32,   427,   948,    87,  2305,  5554,\n",
            "          4256,   357,  2640,    57,  6173,  3728,    52,    23, 14165,   257,\n",
            "             6,    11,     3, 19787, 21826,    15,     7,   130,  3990,  3676,\n",
            "            57,   276, 11982,    18,  2408, 10224, 18459,    21,     3,  6480,\n",
            "            18,  4211,    87,  4211,  1693,     5, 10582,  5111,    24,     3,\n",
            "          9082,    47, 29103, 15596,     3, 19787, 12973,   920,    44,   142,\n",
            "          9249,     3,  4440,    41,   134,    49,  4440,   137, 16821,  5932,\n",
            "         14632,    11,     3,  6941,  2152,    35,  7578,  1693,  3217,    24,\n",
            "             8,  5631,  4440,    47,     3,     9,  6746,     3, 19787,    18,\n",
            "         18693,   127,   353,    16,   180, 25210,    18,  3881,   553,  4949,\n",
            "            68,    59,    16,   119, 12637,    18,  5715,   106,     9, 18095,\n",
            "            15,     7,     5,   101,    92,   435,    24,     8,   813,   120,\n",
            "            40,    18,    23,  5529, 15447,  8050,   536,  8120,    12,     8,\n",
            "             3, 19787, 12973,   920,  5631,  4440,    16,     3,  9082,    11,\n",
            "         18294,     3, 12990,     8,   999,    13, 16686, 14219,     5,   506,\n",
            "           772,  3130,    24,   180, 25210,    18,  3881,   553,  4949,   164,\n",
            "            43,  7347,     8,   815,   295,  6722,    18, 12675,  6565,   383,\n",
            "           165,  9009,     3, 26486,    57, 16686,  3619,     3, 19787, 12973,\n",
            "           257,     5,     3,  7371,     6,   276, 11982,    18,  2408,   748,\n",
            "            54,   370,     3,     9,  1934,   598,    21,     3, 19175,     8,\n",
            "          5014,     3, 19787, 12973,   257,    13, 16686, 13167,     5,  7933,\n",
            "         13738,  6058,  4666, 15083,    10,    86,    48,   810,     6,    62,\n",
            "             3,  8287,    12,  9127,     8,  5014,     3, 19787, 12973,   257,\n",
            "            13,   180, 25210,    18,  3881,   553,  4949,     3,  9082,     5,\n",
            "           242,    48,  1730,     6,    62,   261,   276, 11982,    18,  2408,\n",
            "           748,    12,  3990,  4921,    11, 12812,  6722,    18,  9942,     3,\n",
            "         19787, 21826,    15,     7,    28,   306,  1738, 10696,    11, 29103,\n",
            "         11102,     5,   100,  1573,    54,    36,  1989,  1934,    16,     3,\n",
            "         19175, 16686,     3, 19787, 21826,    15,     7,    45,  2358,  1543,\n",
            "          1355,    29,   144,  2366,    24,   557,  3480,   306,  6145,     7,\n",
            "            13,     3, 23414,    40,  3005,  8402, 20725,    11, 11717,     5,\n",
            "           101,  6164,  4313,    46,     3,  9082,     3, 19787, 12973,   257,\n",
            "           353,    44,  5631,  4440,     6,    84,    19,   359,    21,  8050,\n",
            "           536, 11293,     5,  7053,     6,    62,  3217,    24,     8,  6565,\n",
            "           344,  8050,   536,    11,     3, 19787, 12973,   920,     3,  9082,\n",
            "           228,  3391, 16686, 29328,    16,     3,     9,  2358,  1543,   825,\n",
            "             5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  276, 11982,  9553, 21826,    15, 12812,   297,   338,   276, 11982,\n",
            "            18,  2408,   748,     3, 15503,  5014,     3, 19787, 12973,   257,\n",
            "            13,     8,   206,  2482,    32,  4010,     7,    23,    26,  3619,\n",
            "            13,   180, 25210,    18,  3881,   553,  4949,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  101,  8413,     8, 17581,   138,   799,   483,   399,  1781,    41,\n",
            "         24488,    61,   338,     3,     9,  2847,   357,  7824,  1229,    16,\n",
            "            46,   828,   628,   213,     3,     9,  9068,    13,  2847,  7765,\n",
            "           308,  4481, 13315,     3, 20923,    12, 15726,  4099,  5790,  6935,\n",
            "             5,  2146,  1601, 13080,  4838,  2250,    11,  4896,    97,   615,\n",
            "          2462,   130,   261,    21,     3,     9,    97,   939,   331,  1693,\n",
            "             6,    11,     8,   772,  7972,    24,     8, 18426,  1124,   130,\n",
            "          2714,    44,     8,    97,    13,     8,  9068, 22494,     6,    11,\n",
            "            24,     8,   731,     3, 24488,    16,     8,   562,   952,  9859,\n",
            "            12,     8, 22494,     5,    86,   811,     6,     8, 11233,  1951,\n",
            "            13, 21001, 16540,     7,    11,     8,  9570,    13, 18426,  6867,\n",
            "           130, 18277,    16,  2736,     5,     3, 24488,    13,   705,   145,\n",
            "           204,     3,    87,   107,    47,  1702,     3,     9,   711, 13932,\n",
            "            21,     8,  3239,    13,     8,  2847,  7765,   308,  4481,  9068,\n",
            "            16,     8,  7463,  3064,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[19715,    13,   180, 25210,    18,  3881,   553,  4949,   799, 12940,\n",
            "          5790,    16,     3,     9,  6940,     3,   390,    30,  2847,   357,\n",
            "          7824,  1229,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   37,   381,    13,  5977,    16, 11432, 12341,    33, 11721,  3094,\n",
            "             6,    68,  1561, 18870,    11,   936,  5016,   257,    16,   186,\n",
            "          1488,   991,    12,   769, 12331,  1982,   331,   463,    11, 10321,\n",
            "         10308,    16, 29103,    53,  4290,  7469,     5, 19474, 11747,    54,\n",
            "         18807,    15,   186,    13,   175,   982,    57, 11185, 29103,    53,\n",
            "          1437,    18, 27785, 18870,     5,   506,  7778,  2389,  1457,   306,\n",
            "            95,    18,  6849,  7686,    11,   788,    12,  2136,    13,   539,\n",
            "          6429,     7,    79,    33, 23625,   120,  1256,    21,  7004,    12,\n",
            "         12761,    11,   610,  1067,    13,     8, 11407,    18, 15956,  5973,\n",
            "           889,     5,   947,     6,    62,  5970, 10069,     6,   306,    18,\n",
            "         11258,  2562, 12341,    21,     3,    23, 25503,   585,    16,   280,\n",
            "          2056,    24,    54,    36, 18526,    26,    30,     3,     9, 11306,\n",
            "          1487,     6,   338,   539,  1339,    12,   766, 29103, 11102,    57,\n",
            "             3, 13275,     8,  1339,  2384,  8902,  1462,     6,  2384,  6255,\n",
            "             7,     6,  1318,   683,    32,    63,    11,     3,  6463,  4416,\n",
            "           421, 10069,  3106,  4537,    11, 12586, 12045,    54,  1153,    36,\n",
            "         18526,    26,    11,  2127,    16,   186, 25642,    38,   168,    38,\n",
            "            16,  3472,  2625,     7,   190,   514,    18,   235,    18,  7248,\n",
            "          2976, 16783,    11,   514,    18,   235,    18, 16422, 28373,     7,\n",
            "             5,  5433,     6,     8,  3409,    13,  3160,  6494,     7,     6,\n",
            "            28,   865,  7119,  6031,    42, 12586,  2245,  3345,    30,  1693,\n",
            "            13,  3150,  7347,  1383,     6,     3,  7161,     8, 23543,    13,\n",
            "          2592,  2179,     7, 15652, 12341,     6,  4767,  1551, 21286,   120,\n",
            "          3032, 12341,     5,   432,  2691,    11,  1391,    18, 11966,     7,\n",
            "            33, 11652,   347,    41,  5948,     7,  1303,   115,    35,    23,\n",
            "            52,    32,  4960,    23,     5, 12651, 16420,     5,    23,    32,\n",
            "            87, 12146,  7318,    12,  4410,     8,  2077,    13,  2592,  7690,\n",
            "         11747,   338, 13938,     6,   539,  1339,     5,   101,   857,    48,\n",
            "             3, 23319,  1737,     7,   592,    12,     8,   579,    11,  6103,\n",
            "          2020,    13, 10069, 12341,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  389,  2384,    18, 23799,  5073,  4885, 20589,    21, 23672,    15,\n",
            "            26, 15135,  6031,    11, 27684, 15148,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   37,  2847,  7765,   308,  4481,    41,  5715,   106,     9, 18095,\n",
            "          1994,  1360,    61,  2131,   221,  3113,    24,   808,   147,     8,\n",
            "           296,    16,  1882,  1360,    65,   141,   664, 15166, 18827, 11737,\n",
            "            30,     8,  1342,    13,   151, 13448,     5,    94,  6571,     7,\n",
            "             3,     9,  1450,     3, 18018, 10113,     3,  6836,    45,     3,\n",
            "             9, 18018,  6049,    12, 19302,     3,  1092,  1221,    28,    46,\n",
            "         24810,  6138,     5,  2900,   120,  8209,    11,  4193,    13,  1994,\n",
            "         20363,    19, 18158,    21,  1231,  1058,     5, 13995,     7,  7024,\n",
            "          2197,  3223,    24,    57,     8,    97,  3976,  2385,     8, 16686,\n",
            "          4002,   429,   993,  1909,   610,     5,   611,     6,    34,    19,\n",
            "             3, 22468,    12,   129, 22538, 12223,    38,  1116,    38,     8,\n",
            "           166,     3, 18018,  3475,     5,   290,    19,    46,  5299,  5971,\n",
            "            13,  3468,  2392,  3920,   277,    13,  2847,  7765,   308,  4481,\n",
            "          6571,    53,    46,   778,     3, 26558,    21,  1231,  3739,   758,\n",
            "             6, 10133,  2420,    13,   306,  1020,  1221,    11,     3,  5833,\n",
            "          1523,  3487, 17127,     5,    86,    48,  1132,     6,    62,  3332,\n",
            "            12,  2075,    11,  5530,   359,  4251, 21826,    15,     3, 15329,\n",
            "          2392,  3920,   277,     6,     3, 17332,   205,    18,    60,  6645,\n",
            "          3619,     6,   749, 10379,   155,   106,    77,     6, 12762,   155,\n",
            "            77,     6, 14843,  4748,   374, 10656,  5255,     9,     7,    15,\n",
            "             6,   679,  2781,   183,    63, 20253,    71,     6,  3037,   109,\n",
            "          1598,    77,  5783,     6,  2740,  2528,  9705,  1859,   159,  2945,\n",
            "            18,   138,  6977,    11,   301, 19114,   261,    16,     8, 10664,\n",
            "            11,   758,    13,  2847,  7765,   308,  4481,     5,  1813,  4900,\n",
            "          2071,    32, 21715,    11,     8,  1075,    13,   175,     3, 15329,\n",
            "          2392,  3920,   277,    19, 12566,     6,     3,   390,    30,     8,\n",
            "          2084,     7,   347,  6501,   833,     5,   389, 20552,   757,   331,\n",
            "          4891,   590,    28,    70, 18712,    28,     8,   793,  1994, 13324,\n",
            "            19,    13,     3,    76,    17,  5463,  3172,    16,     8,   758,\n",
            "            13,  2847,  7765,   308,  4481,     5,   264,   856,   585,    11,\n",
            "            16,    18, 10437,  1693,    13,   175,  2392,  3920,   277,    19,\n",
            "         11741,    15,    26,    16,     8,   915,  8616,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 2158,   109,    13,  7945, 21826,    15,    86, 19381,  6546,  3318,\n",
            "          3920,   277,    16,     8,  5267,  6715,     7,   159,    11, 23740,\n",
            "            13,  2847,  7765,   308,  4481,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[    3, 10744,  6294, 22177,    10, 10368,   309,    20,  4638,    23,\n",
            "          4392,    19,  1017,   383,  8999,    11,   164,  1137, 14497,   224,\n",
            "            38,   554,  1987,  5347,    41,  6383,   434,   137,   100,   810,\n",
            "            47,     3,  8287,    12,  9127,     8,  1504,    13,     8,  7869,\n",
            "           309,    18,  8610,    53,  3619,    41,   553,  9213,   345,    61,\n",
            "             3,    52,     7,  2518,  4853, 31595,    15,     6,    84,    65,\n",
            "             3,     9,  1516,  1504,    30,  7869,   309, 16325,    11,   276,\n",
            "         12733,     5,     3, 24506,  6299,  3592,    10,   100,  2269,    18,\n",
            "         14309,   138,   810,    47,  4468,    28,  3538,  9841,   887,   113,\n",
            "           141, 23496,   276, 12733,    11, 10630,  9841,   887,   113,   141,\n",
            "           150,   806,  7469,    38,     3,     9,   610,   563,     5,   679,\n",
            "          2781,   792,  7869,   309,   944,    18, 30966,  7869,   309,    41,\n",
            "          1828,   599,  9195,    61,   308,    61,  1425,   130,  8413,   338,\n",
            "             8,  8021,    75,     7,    63,     7, 10368,   309,  9273,  5747,\n",
            "             5,   584,  9213,   345,    47,  8413,   338,     3,     9,   584,\n",
            "          9213,   345, 12716,    23,  2917,    15,     3,  3577, 18161,  5747,\n",
            "             5,    37,  1425,    13,  2392, 28843,   944,   599,  9195,    61,\n",
            "           308,   130, 11338,     3,   390,    30,     8,   792,   944,   599,\n",
            "          9195,    61,   308,    11,   584,  9213,   345,  6145,     7,     5,\n",
            "          6642,    47, 21527,   338,     8,     3, 12145, 20905, 12737,    11,\n",
            "           332, 13159,  5747,     5,  7871,   206,  2482,    32,    17,  1599,\n",
            "          4251,  8886,   159,    51,     7,    41,    52,     7,  2518,  4853,\n",
            "            61,    16,     3, 11055,   130,     3, 16466,   338,     3,     9,\n",
            "          2067,  1824,  7296,   180,  9082, 21849, 12575,    53,   282,  8735,\n",
            "          5747,     5,    37,    73, 13804,     3,    17,    18,  4377,     6,\n",
            "          2695,    18, 19687,    26,     6,    11,     3, 23190, 21294,   188,\n",
            "          3830,   130,  3032,     5,  3188,    52,   189,    31,     7, 12299,\n",
            "          1601, 28820, 26625,    47,  2930,     5,    37,   616,   365,     8,\n",
            "          8435,    41,   188,  6463,    61,    47, 11338,    11,     8,  1340,\n",
            "          1647,   701,    47,  4187,     5,   432, 11775, 15282,   130,  3032,\n",
            "           338,   391,   988,  2853, 19997,    41,   448,  2941,    21,     3,\n",
            "         30578, 25274,     6, 19500,     6,  9652,   137,     3, 12200,  4254,\n",
            "          4578,    10,  9273,   944,   599,  9195,    61,   308,  1425,   130,\n",
            "            59,  4019,   315,   344,     8,   192,  1637,     5,  3318, 28843,\n",
            "           944,   599,  9195,    61,   308,    47,  4019, 13665,    16,   276,\n",
            "         12733,   887,    41,   102,  2423,     3,     5,  4542,  6982,     6,\n",
            "            11,   584,  9213,   345,    47,  4019,  1936,    16,   276, 12733,\n",
            "           887,    41,   102,  2423,     3,  4200,  7256,     3,  2172,    12,\n",
            "             8,  7415,     5,  3318, 28843,   944,   599,  9195,    61,   308,\n",
            "            47,  1364,    16,   887,    28, 10188,    87, 18943,    11,     3,\n",
            "          9697,     3,    52,     7,  2518,  4853, 31595,    15,     7,   145,\n",
            "            16,   273,    28,     3, 21320,     6,    28, 11775, 11978,    16,\n",
            "           887,    28,     8,     3,  9697,    66,   400,    41,   102,  2423,\n",
            "             3,     5,  6348, 13520,     5,   584,  9213,   345,    47,  1146,\n",
            "            16,   887,    28, 10188,    87, 18943,    11,     3,  9697,   145,\n",
            "           273,    28,     3, 21320,     6,    68,   132,    47,   150, 11775,\n",
            "         11978,     5,    86,   276, 12733, 24753,     6,  2392, 28843,   944,\n",
            "           599,  9195,    61,   308,    11,   584,  9213,   345,     6,     8,\n",
            "         11007,  5688,  1936,    57,     3, 14912,  3891,   648,    16, 10188,\n",
            "            87, 18943,    41,   102,  2423,     3,     5,  5865, 13520,    11,\n",
            "          1936,    57,     3, 15062,  3072,   648,    16,     3,  9697,     3,\n",
            "          2172,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  679,  2781,  7869,   309,    18,  8610,    53,  3619,    41,   553,\n",
            "          9213,   345,    61,  6145,    11,     3,    52,     7,  2518,  4853,\n",
            "         31595,    15,   164,    36,  1968,    28,   554,  1987,  5347,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[    3, 10539,   683, 14196,  8087,   304,  6825,     8,  1103,     6,\n",
            "          3860,     6,    11,  8136,    13,  2749,  3513,    45,   662,  1440,\n",
            "            81,  4945,    28,  2847,  7765,   308,  4481,    16,     8,   569,\n",
            "         15997,  1059,     5,     3, 24506,  6299,  3592, 25388,    17,  1528,\n",
            "           810,    28,  4772, 16180,    26,  8917,     5,  3525,    49,  7609,\n",
            "            41,     2,  3328,   203,   625,   201,   113,  4114,    16,     8,\n",
            "          4150,  6881,    13,   662,   315,  1440,    41,   279,  7275,   173,\n",
            "             6,   907,  1323,     6,  5308,     6,    11, 12627,   201,   130,\n",
            "          1380,    81,     8,  1112,  1906,   383,     8,  2131,   221,  3113,\n",
            "             6,   126,  8966,    42,  9076,   383, 15997,     6,  2836,    13,\n",
            "           569,    11,  3973,   380,     6,    11,    70,  1103,    81,  2847,\n",
            "          7765,   308,  4481,  2131,   221,  3113,     5,  2747,    47,     3,\n",
            "         11665, 22573,     6, 10763,  3676,     6,    11,  5776,    12,   738,\n",
            "          1693,     5,     3, 12200,  4254,  4578, 23277,    18, 16443,  2749,\n",
            "          7609, 11704,    45,  9278,     6,   305,    45,  5308,     6,   305,\n",
            "            45, 12627,     6,    11,   305,    45,     8,   907,  1323,    61,\n",
            "           130, 19257,     5, 19204,  2196,  1829, 12103,    16,    70,  1444,\n",
            "           280,  1087,    11,  3973, 29440,     5,     3, 30010,    26, 14340,\n",
            "             7,    16,  8966,     6,     3, 22375,  3266,     6,    11,  2123,\n",
            "          1705,    13,     8,  1994,    26,     3,   390,    30,   251,   347,\n",
            "            16,     8,   783,     5,   290,    47, 13503,   729,    15,   485,\n",
            "            16,     8,  6643,    13,     8, 12766,     6,  2924,    24,     8,\n",
            "          2131,   221,  3113,  4161,   135,    16,     3,     9,  1126,   194,\n",
            "             6,   237,   713,    79,  4114,    16,   315,  9757,    11,  2625,\n",
            "             7,     5,  8472,  8440,  3063,  9215,    37,   569, 15997,  2953,\n",
            "            57,     8,  2847,  7765,   308,  4481,  2131,   221,  3113,  2130,\n",
            "             8,  1809,    21,     8,   821,    13,   186, 13792,     7,     6,\n",
            "           578,    46,  1113,    16,     8,  8136,   569,  5178,    11, 19016,\n",
            "            13, 17813,     7,     5,   100,   331,    54,  3052,   533,  2481,\n",
            "            12, 11052,  3266,    12,  1154,    28,     8,  1113,    13,     8,\n",
            "           569, 15997,    16,  2749,  7609,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 1915,  7239,     7,     6,  6382,     6,    11,     8,  3860,    13,\n",
            "          2749,  3513,   383,     8, 15997,  1059,  2953,    57,     8,  2847,\n",
            "          7765,   308,  4481,  2131,   221,  3113,    10,     3,     9, 19647,\n",
            "           810,    16,   662,  1440,     5,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  818,   712,    18,  8725,     3, 11840, 30117,   795,     3,     9,\n",
            "           126,  2034,    30,     3, 21324, 20113,    11,  2071,  7925,  6316,\n",
            "         15651,    11, 26481,   729,    15,   485,     6,    34,  5696,     7,\n",
            "            45,   731,  3240,    18,   235,    18,  5983,     7,    15,  5688,\n",
            "            11,     3,     9,   306,  2328,   670,  1080,    44,     8,   928,\n",
            "          6510,   593,     6,  2932,  4421, 18906, 15282,     5,   304,  1115,\n",
            "            48,   682,     6,    62,  4277,   276,  4555, 17664,    41,  3174,\n",
            "            17,  2455,    18, 21661,    86, 11788,    21,  7871,  7845,  6536,\n",
            "           201,    46,  4580, 18355,  4732,    21,     8,  3619,  1756,    18,\n",
            "           390,  1693,    13,   712,  2358,   769,  9791,  7830,     7,     5,\n",
            "           276,  4555, 17664, 11531,     7,     8,  7889,    13,   689,   545,\n",
            "            18,  9500,  6510,  8253,  5275,     6,    12, 12700,  3613,  1756,\n",
            "            13,   284,  3619,     3,   390,    30,     8,  3893,   165, 20267,\n",
            "           138,  8874,    41,    60,  6106,   106,   201,   338,     8,     3,\n",
            "         21159, 10077,    15,    11, 10531,  7765,  8742, 16783,     6,  6898,\n",
            "             5,    94,  4028,     7,  3714, 18355,    11, 21744,  3621,     6,\n",
            "           379,  1756,    18,   390,  9068,  1693,     6, 10356,    13,  2358,\n",
            "           538, 26661,     7,     6,    11,     3,    15, 12804,    26,   257,\n",
            "            13,  2325, 14415,     7,    13,  2358,   538,    11,  2358,   538,\n",
            "          3508,     7,     6,    28,   423,  1413,    32,   883,  2020,    28,\n",
            "           679,  2414,    17,    22,     7,   712,    18,  8725,   331,  1910,\n",
            "             5,  4292,  3663,  4710,    11, 29103, 11102,  4193,     6,  1009,\n",
            "          2268,    11, 11432, 16148,    38,  8735,     7,    11,    57,     3,\n",
            "         20861,   975,  7621,   663,    28, 27198,    11,   205, 14871,    18,\n",
            "           134,    15,  1824,    18,   390, 11110,     6,   504,  8417,  4179,\n",
            "            16,     8,  1418,    12,  2862,  3400,   769,  9791,  7830,     7,\n",
            "            11,    12,  6570,  1756,    13,   843,   689,   545, 17334,     6,\n",
            "             3,  2172,    12,  6510,  3893,  1693,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  276,  4555, 17664,    10,    71, 12045,    21,     8,  2149,  6049,\n",
            "             6, 17379, 22536,    18,   390, 10582,    13,  7871,  7845,     3,\n",
            "         11840, 26859,    15,  4733,  2747,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  101,    43,  4468,     3,     9,   810,    13,  2213,  3239,    16,\n",
            "             8, 12231,  8455,    45,  7123,  1956,     2,     3,    40,     3,\n",
            "             2,   204,  4122,  1956,    77,     8,  1719,  6970,    57,     8,\n",
            "             3, 13011, 25657,  4132, 19208,   478,     5,   100, 17894,    52,\n",
            "          1978,  2253,   478,     3, 28400,     8,  6112,    13,     8, 12231,\n",
            "         18389,    63,  5994,    28,    27, 22034,    44,     3, 23074,    11,\n",
            "             3, 12451,     3,     2,    51,     5,   101,  5148,     8,    27,\n",
            "         22034,     6, 13129,    18,  1846,    86,    89, 11096,    26, 11418,\n",
            "         15762,    41,   518, 19056,   201,    11,  2759,  5893,    29,   432,\n",
            "          5643, 11418, 10173,     7,    11,    69,  1767,   772,    45,   430,\n",
            "         12231,  8455,  3719,    11,  2862,     3,     9,   792,    13, 10635,\n",
            "             6,   519,  3747,  1021, 22716,  4820,    41,   476,  6582,     7,\n",
            "            61,   640,     8,  1057,     3, 25754,  2490, 20829,  1956,    16,\n",
            "          2776, 22884,   307, 20341,     5,     3,  3626,     8,   309,  4547,\n",
            "         11425,  1573,    30,     8,  3334, 10173,     6,    62,  2862,   431,\n",
            "          2606,  9068,     7,    42,     3, 31761,  2865,    13,     3,   476,\n",
            "          6582,     7,   578,   874,    42,    72,   724,     5,   101,  2862,\n",
            "         10372,   591,  3959,   853,    27,     6, 14405,  3328,   591,   853,\n",
            "          2466,     6,    11,     3,  4552,  1828,    46,    15,  3113,   853,\n",
            "          2466,    87,  4057,  6289,     3,   476,  6582,     7,     5,    37,\n",
            "          5688,    13,     3,   476,  6582,     7,  4313,    38,   724,    13,\n",
            "          9068,     7,    47, 14105,   755,  2577,    87,  4177,     6,  4201,\n",
            "         11864,    42,   305,  5988,     5,   101,   435,    24,   910,    13,\n",
            "             8,  9068,     7,  4313,    43,  3150,  8413,  2357,     7,    16,\n",
            "             8,   549, 19056,   454,  2466,  3719,     5,   101,   261,   175,\n",
            "          2357,     7,    16,    69,     3,  5628,  4900,   827,  3438,    41,\n",
            "           134,  2326,    61,  8213,    13,     8,     3,   476,  6582,     7,\n",
            "            16,   175,  9068,     7,     6,    13,    84,     3,  4314,   141,\n",
            "             3,   476,  6582,     7,    28,     3,     2,   519,     2,  7307,\n",
            "             5,   101,   261,     8,     3,  9942, 20286,    45,     8,   180,\n",
            "          2326,   825,  7307,    12,  7037,     8,  2332,  3294,  1681,    41,\n",
            "          5166,   371,    61,    16,     8,  4723,    11, 12231,  8455,  9068,\n",
            "             7,   117,     3, 29111,     8,  9068,     7,    57,  7466,  2708,\n",
            "            32, 17456,  2357,     7,     6,     8, 13150,     7,   130,     3,\n",
            "             2,  3274,  1300,  4225,     3,     2,  4097,  3341,   756,   220,\n",
            "           283,     3,     2,    21,   391,  6084,     3,     2,   209, 16593,\n",
            "             3,   157,   102,    75,    11,     3,     2,  3274,  1300,  1808,\n",
            "             3,     2,  4097,  2266,   756,   220,   283,     3,     2,    21,\n",
            "           391,  6084,  2490,   209, 16593,     3,   157,   102,    75,     5,\n",
            "            37, 13150,    13,     8,  3334,    27, 13286,    47,   435,    12,\n",
            "            36,     3,     2,  3274,  1300,  4508,     3,     2,  4097,  4165,\n",
            "           756,   220,   283,     3,     2,     5,   506,  2620,    33,  4700,\n",
            "            28,   284,   119,   441,     8, 30879,    11,    28,  6678,  2620,\n",
            "            16,     8,  4723,  8455,   306,    18,  2754,     7,  2213,  3239,\n",
            "          6266,     5,    37, 13150,     7,    33,   952,    92,  4700,    28,\n",
            "             3,     9,  7687,  5158,  4995,    49,    27, 13286,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   71, 23086,    13,  2042, 25947,    16,     8,  3387,    49,  8455,\n",
            "             5,  2466,     5,    37,     3, 13011, 25657,  4132, 19208,  7257,\n",
            "             5,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  101,   934,     3,     9,   495,    13,     3,     9,  2208,    18,\n",
            "          1201,    18,  1490,  3955,   113,  7513,  2569,    12,    46,  1067,\n",
            "          3882,    32,  8180,     7,    17,    28, 11244,    13,  6377,   235,\n",
            "             7,   159,    11, 13665,  3176,     3,     9,  1071,   485,     5,\n",
            "         29648, 28914, 12586,    41, 19045,    61,  5105,    44,    24,    97,\n",
            "            47,  6238,    21, 22490,   694,  6191, 23353,   155,   159,     5,\n",
            "          4877,     6,     8,  1868,    22,     7, 10979,    12,     3,    32,\n",
            "         28197,    51,  1863,    47, 16124,   788,    12,     8,  4301,   106,\n",
            "             9, 18095,  1994,  1360,    41,  5911,  7765,   308,  4481,    61,\n",
            "          2131,   221,  3113,     5,   461,  3831,    12,     3,    32, 28197,\n",
            "            51,  1863,    80,   215,   865,     6,     8,  1868,   141,  3739,\n",
            "           120,     3, 18687,    15,    26,    28,  1516,  3176,    11,     3,\n",
            "            32,    40, 17899,    63,  1453,     5,   451,   365, 16103, 13591,\n",
            "            29,    17,   414, 23643, 23353,  3730,    57,     3,    32,   235,\n",
            "            40,  1208,  1725,  1863,    28,   112,    17,  4478,  1693,    13,\n",
            "             8, 23353, 12544,     3, 27338, 22490,   694,  6191, 23353,   155,\n",
            "           159,     5,   100,    19,     3,     9,   775,   495,     3, 20968,\n",
            "             8, 18827,  1113,    24,     8,  2847,  7765,   308,  4481,  2131,\n",
            "           221,  3113,   141,    30,  1868,   124,    21,    46,  2904,  2665,\n",
            "           179,  1706,     5,   101,  4230,     8, 21961,    13,     3,  1931,\n",
            "         29368,  5275,    38,     3,     9,   194,    12,  1709,  1126, 14497,\n",
            "             5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 4455, 26730,  9259,  6191,  8271,   302,   155,   159,    10,   411,\n",
            "         28197,  3113,  2570, 13555,     7,  6984,    12,     8,  2847,  7765,\n",
            "           308,  4481,  4266,   221,  3113,    11,     8, 22672,    13,  7338,\n",
            "         29368,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   37,  1113,    13, 28911,     3,  9621,   106,  1215, 13903,     7,\n",
            "            30,     8,     3,  2165,  1433,  1567,  3438,    16, 19536,     3,\n",
            "         14901,    29,     3,    29,   155,  4055,    15,    19,     3, 28400,\n",
            "            57,     3,    89,    15,    51,   235, 12091,     3,   226,    18,\n",
            "          2866,  4926,     3,    26,    99, 22513,     5, 11628,    18,  9390,\n",
            "          3017,  7583,     3,     9,  3422,     7,  1225,    41,  3221,    61,\n",
            "           192,    18,  9621,   106,  1215, 13903,     7,  6126,    57,    46,\n",
            "             3, 27090,   757,  4425,   152,   433, 21151,     3,     9,  1147,\n",
            "          2376,   993,    13, 20624,    52,  9925,     3,   226,    18,  2866,\n",
            "         13182,     5, 15907, 11048,  8111,     3,  9942,    45,  3017,  4741,\n",
            "             3,    26,    99, 22513,  4264,  6731,     3,     9, 15208,  2025,\n",
            "            13,     3,  2165,  1433,  1567,    45,     8,  1413,  2248, 10646,\n",
            "          1719,  2400,     3, 14901,    29,    11, 23383,     3, 10432,     7,\n",
            "             5,   100,  2025,    19,  7246,   920,    28,     3,     9,  7321,\n",
            "            13,  5986,     3, 18944,   788,    12,     3,     9, 28911,  1355,\n",
            "          4718,    13,     3,  3221,     3,  9621,   106,     7,  1341,    12,\n",
            "             8,     3,     2,  1714,     2,   279,    11,     3,     2,  2596,\n",
            "             2,   279,    19,    32,  2916,    15,     7,     5, 23907,    11,\n",
            "          3031,  4526,    13,  4333,  1158,   190,   186,    18,  6965, 11356,\n",
            "         17551,  9944,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 3657,   106,   106,    18,  1570, 12160,    26,   419, 14836,    13,\n",
            "          3833,  1433, 15907,    16,  7254,   106,  2504,  1788,   221,     3,\n",
            "         16018,    15,    26,    57,  8618, 11584,     3,     4,    18, 25619,\n",
            "           309,    99, 22513,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[    3, 26953, 18256,  4630, 13110,    10,  4564,    18,   858,    18,\n",
            "          2864,  5084, 23486,    41,  9138,   134,    61,  2604,    19,     3,\n",
            "             9,  4772, 13158,   155,  1528,  2604,    13,  5084,  1783, 20363,\n",
            "             5,  1592,    18,    60, 14913, 29216,    26,    12,    51,  5984,\n",
            "            41, 11120,  6227,    61,    19,     8,  2045,  1068,  1573,    12,\n",
            "          6825,     8, 20363,    13,  5084,  9683,    45,     8,  3714,  4301,\n",
            "           106,     9, 18095,  1994,    41,  5911,  7765,   308,  4481,   137,\n",
            "         21194,  2116,    43, 18277,     8,  3739, 11978,    13,   301,  3063,\n",
            "            11,  8383,  6227,  7586,    16,  1221,    28,  2847,  7765,   308,\n",
            "          4481,     5,  4063,     6,     8,  2674,    13,    48,   810,    47,\n",
            "            12,  6825,     8,   813,  6715,     7,  1225,  6339,    13,   301,\n",
            "          3063,    11,    13,  8383,  6227,    16,  2847,  7765,   308,  4481,\n",
            "          1221,     5,     3, 24506,  6299,  3592,    10,   101,  4006,    91,\n",
            "             3,     9,  1249, 13866,     6, 29825,   810,     3,  8287,    44,\n",
            "             3, 17768,     8,   813,  6715,     7,  1225,  6339,    13,   301,\n",
            "          3063,    11,  8383,  6227,    57,  6990,     8,  9990,  8435,    13,\n",
            "          2847,  7765,   308,  4481,    16, 10061,     7,     5,   301,  3063,\n",
            "            11,  5738,  8668,  7586,   130, 11338, 29825,   120,    57,   204,\n",
            "          2252, 25099,    28,  2490,  1714,   203,    13,   351,    16,  5738,\n",
            "         12586,     6,    11,     8,  3055,   130,  3495,    16, 16698,     5,\n",
            "           301,  3063,  2604,    47, 11338,    30,     8,  1873,    13,     8,\n",
            "          3053,    42,    59,    13,     3,  4788,  9709,   689, 17947,  2197,\n",
            "             6,   272,    18,  6972,     6,    11,  5084, 16690,     7,     5,\n",
            "            37,   792,  2604,    41,  5517,     3,   632,   104,  3420,    61,\n",
            "            47,  5105,    45,     8,  4505,    13,     8,  2030,  7586,  5105,\n",
            "            16,   284,  1719,     5,  8668,  2604,    47, 11338,    21,   284,\n",
            "            13,     8,   305,     3, 11846,    15,     7,  4014,     8,    46,\n",
            "         20844,   138,  4924,  1315,    12,     8,  5294,   260,    35, 11971,\n",
            "          1982,  9683,     5,    37,     3,  5490,  1879,  1252,  4772, 13158,\n",
            "           155,  1528,  8668,  2604,    47,     8,  4505,    13,   284,   712,\n",
            "          6899,  1047,  2604,    11,   620,    26,    45,     3,   632,    41,\n",
            "            29,    32,  9683,    61,    12,   944,    41,  9128,   603,   440,\n",
            "          9683,   137,     3, 12200,  4254,  4578,    10,   555,  6189, 18358,\n",
            "            18, 21182,  2847,  7765,   308,  4481,    16, 10061,     7,    41,\n",
            "           526,   152,  1246,  7123,     3,     2,   627,   203,   117,     3,\n",
            "         28168,   283,   201,   379,  1902, 17251,  6210,    16,    18, 31386,\n",
            "         14319,    21,   136,  1137,   147,     3,     9,  1243,  1130,    18,\n",
            "           413,    13,   968,   477,   130,  1285,     5, 23045,   301,  3063,\n",
            "            11,  8668,  7586,   130,   957,     3,     2,   586,    11,   335,\n",
            "             3,     2,  7973,  6898,     5,    71,  1101,  1465, 13080, 18712,\n",
            "           344,   301,  3063,    11,  8668,  7586,    41,   345,  2741,   739,\n",
            "         18712,     3,    52,  3274,     3, 22426,  5062,   117,   391,   357,\n",
            "          3274,     3, 12100,  3651,   117,     3,   102,     3,     2,     3,\n",
            "         10667,  6982,    47,  6970,     5,   938,     3, 26893,  8435,  1693,\n",
            "             6,     8,  6624,  1340,    18,  2700,    21, 20544, 21332,    47,\n",
            "           460,    21,   301,  3063,  2604,    11,     3, 12451,    21,  5738,\n",
            "          8668,  2604,     5,  2150,    12,  2209,  3767,    18,   329,    15,\n",
            "           972,  9990,  1693,     6,    16,    18, 31386, 20544,  4019,  1936,\n",
            "           859,  2847,  7765,   308,  4481,  1221,     3, 12072,    28,    46,\n",
            "           301,  3063,  2604,     3,     2,  1755,    41,  2152,    18,  6254,\n",
            "             3, 10667,   519,   117,  8383,  5835,  4225,     6,   668,  2712,\n",
            "             3,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  749,  6715,     7,  1225,  6365,  3286,   663,    13,  4004,   222,\n",
            "         27684,    57,   301,  3063,    11,  8668,    16,  2847,  7765,   308,\n",
            "          4481,    86, 10061,     7,    10,    37,     3, 20482,  7765,   308,\n",
            "          4908, 13866,  9165,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   86,  1332,  6503,     6,     3,    15, 12194,     7,    45,   186,\n",
            "          2315,   831,  6036,    11,  9612,    12,  9179,    66,   529,    18,\n",
            "            15,   935,  5560, 27503,    11,   828,  8305,    12,  1709,  9612,\n",
            "            45,   271,   147, 19496,     6,  8996,   525, 13310,  1277,     6,\n",
            "            11,  1709,     8,  3060,    13,  2847,  7765,   308,  4481,    28,\n",
            "             8,  1288,    12,  2667,   324,     8,  8435,    13,  3714,  4301,\n",
            "           106,     9,  6722, 13315,    30,     8,   573,  2798,    15,  4638,\n",
            "          1433,  7328,   533,   124,  3580,  1344,    11,  1961,  1098,    11,\n",
            "          1103,     6, 11967,  2270,   761,     6,  1099,   928,  4616,    13,\n",
            "            66,  1221,     6,    11,  7131,    21,  3134,  1656,   784,     3,\n",
            "           908,  4998,   867, 17212,     7,  2725,   655,    16,  3055,     6,\n",
            "            84,    54,  9054,    42,  1656,     6,    33,  7509,  1702,   784,\n",
            "             3,   908,   683,   302,  1844,  5377,   440,  1099,     7,   149,\n",
            "             8,   615,    19,  3492,    11,   149,     8,  8916,    13,     8,\n",
            "           573,    19,  2012,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 391,  257,   53, 4575, 1863, 2686,    3, 2092,    3,    9, 4266,  221,\n",
            "         3113,   10,   71, 5923,   52,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[    3, 10539,   683, 14196,  8087,    10,   101,     3,  8287,    12,\n",
            "          2075,     8, 24753,    13, 10257,  1917,    11,     3,   287,   127,\n",
            "          9824,  2197,    11,  6825,     8,  1675,   344,   135,    11,  1994,\n",
            "         20363,    11, 20544,    16,    16, 10061,     7,    28,  2847,  7765,\n",
            "           308,  4481,     5,     3, 24506,  6299,  3592,    10,  2847,  7765,\n",
            "           308,  4481,  1221,   130,  8807,   139,     8,   826,  1637,    10,\n",
            "          5998,   563,     6,  9786,   124,  1745,    41,   196,  5211,    61,\n",
            "           563,     6, 20983,     6,    11,   529,    18,  3042,  7003,   127,\n",
            "             7,     5,  5388,    18,  5911,  7765,   308,  4481,  1221,   130,\n",
            "          1285,    38,     3,     9,   610,   563,     5,    37,  1637,   130,\n",
            "             3,  2172,     5,     3, 12200,  4254,  4578,    10,   290,    47,\n",
            "           150,  1750,   344,  1221,    28,    11,   406,  2847,  7765,   308,\n",
            "          4481,    16,  1353,    13, 10257,     6, 17688,     6,  8363,     6,\n",
            "         19398,     6, 27008,    63,     3, 27845,  1994,    41, 12926,   201,\n",
            "          6676, 13177,     6,  6658, 23328,  3338,    11,  1584, 30793,    23,\n",
            "             9,    41,   102,  3155, 25079,   137,  3525,    49,  1246,    41,\n",
            "           667,    26,    26,     7,  5688,    41,  2990,   201,     3, 12734,\n",
            "          4241,   117,   668,  2712,  3410,  8572,    41,  3597,    61,    10,\n",
            "             3, 12734,  4853,    18, 12734,  4613,   117,     3,   102,     2,\n",
            "             3,  5311,  6982,     6,  6658,     3,    32,   115,  7593,   757,\n",
            "             3, 26836,  1994,    41, 25032,   308,    61,    41,  2990,     6,\n",
            "             3, 21280,  3072,   117,   668,  2712,     3,  3597,    10,     3,\n",
            "         11039,  2577,  5783,     5,   927,  3166,   117,     3,   102,  2423,\n",
            "         11739,  2688,    61,    11,     3, 12926,    41,  2990,     6,     3,\n",
            "         22724,  4314,   117,   668,  2712,     3,  3597,    10,  1300, 27184,\n",
            "          4525,     5,  4327,   591,   117,     3,   102,  2423, 11739,  1808,\n",
            "            61,   130,  4019,  1968,    28,    27,  5211,  7209,     5, 12892,\n",
            "         10257,    41,  2990,     6,  3594, 19621,   117,   668,  2712,     3,\n",
            "          3597,    10,  1682,  3747, 17234, 23758,  2555,   117,     3,   102,\n",
            "             2,  5311,  6982,    11,  1798, 10257,    41,  2990,     6,     3,\n",
            "         25168,  3914,   117,   668,  2712,     3,  3597,    10,  1300,  4608,\n",
            "         23440,     5,   940,  2079,   117,     3,   102,     2,  5311,  6982,\n",
            "           130,  1020,  2580,    21,    27,  5211,  7209,     5,  3525,    49,\n",
            "          1246,    41,  2990,   117,     3, 12734,  4613,   117,   668,  2712,\n",
            "             3,  3597,    10,     3, 12734,  4834,  2292,     5, 17304,   117,\n",
            "             3,   102,     2,  5311,  6982,     6,  2847,  6251,    41,  2990,\n",
            "             6,     3, 19162,  2368,   117,   668,  2712,     3,  3597,    10,\n",
            "          1300, 24622,  6039,     5,   591,  3341,   117,     3,   102,  2423,\n",
            "         11739,  2606,   201,     3, 12926,    41,  2990,     6,     3, 23913,\n",
            "          5373,   117,   668,  2712,     3,  3597,    10,     3, 14489,  4450,\n",
            "          6996,  4200,   591,   117,     3,   102,  2423, 10667,  6982,    11,\n",
            "           975,  2897,  3268,   842,  3338,    41,  8360,   371,    61,    41,\n",
            "          2990,     6,  3594,  1298,  2517,   117,   668,  2712,     3,  3597,\n",
            "             3, 12734,  3951,  3486, 15300,  3449,   117,     3,   102,  2423,\n",
            "         11739,  4165,   201,   130,  4019,  1968,    28, 20544,     5, 12892,\n",
            "         10257,    41,  2990,     6,  8808,   632,  2534,   117,   668,  2712,\n",
            "             3,  3597,    10,     3, 20734,  3449,    18,  4201,     5, 20579,\n",
            "           117,     3,   102,     2,  5311,  6982,    11,  1798, 10257,    41,\n",
            "          2990,     6,     3, 17255,  4560,   117,   668,  2712,     3,  3597,\n",
            "             3, 21280,  3341, 10106,     5, 20176,   117,     3,   102,     2,\n",
            "          5311,  6982,   130,    92,  1020,  2580,    21, 20544,     5,  8472,\n",
            "          8440,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[14627,    53,    11,     3,   287,   127,  9824,  2197,    33,  1968,\n",
            "            28,  2847,  7765,   308,  4481, 20363,    11, 20544,    16,   305,\n",
            "          4122,  1221,  4260,    16,  9299,    10,     3,     9, 29825, 12556,\n",
            "           138,   810,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[28045, 18095,  1994,  1360,    41,  5911,  7765,   308,  4481,    61,\n",
            "          2131,   221,  3113,    65, 19170,     8,   296,    11,  2953,  8030,\n",
            "          9824,   485,    11, 20544,    30,    46, 19534,   593,    16,     8,\n",
            "             3,  1498,    13,   941,  4404, 24122,  6126,    12,    18,  5522,\n",
            "            30,     8,     3,  5771,    83,  1433,    11,  2071, 20853,   485,\n",
            "            13,  5274, 12498, 19944, 12398,  4301,   106,     9, 18095,   204,\n",
            "            41,   134, 25210,    18,  3881,   553,    18,  7318,  6490,    24,\n",
            "          2847,  7765,   308,  4481,   164,    36,  1702,     3,     9,   626,\n",
            "          5536,     6,  2953,    57,     3,     9,  1405,    31,     7,  9114,\n",
            "           626, 11432, 10931,   100,  7489,    19,  3510,    57,    46,  3250,\n",
            "          1693,    13,  2071,    32, 21715,    11,  3739, 13324,    13,    48,\n",
            "         24261,  1994,    94,    19,   230, 11961, 10320,    24,  2847,  7765,\n",
            "           308,  4481,    19,    59,     3,     9,   964,    18,  3044,  9311,\n",
            "             6,    68,    19,  1446,     3,     9, 11556, 16556,  2071,  1863,\n",
            "             6,     3, 16730,    57,     3,     9,   939,    13,  6518, 14399,\n",
            "            57,   315,  2288,   109,  4866,    11, 11432, 12009,    37,  1994,\n",
            "            54, 10321,    36,  8807,    16,    44,   709,   874,   315, 17258,\n",
            "            41,    77, 16377,  1575,     6, 19944,     6,   813,    18, 15329,\n",
            "             6,   813,    18,  8514,  6310,  1225,     6,    11,  1687,    42,\n",
            "             3,    60,  5451,    61,   549, 11414,     8,  6722,  7294,     7,\n",
            "          1223,     3,    75,    63,    17, 25216,  2871,   383,     8,  2332,\n",
            "          1726,    13,  7095,     6,    16,     8,   826, 16556, 17258,     6,\n",
            "            34,    19,     8,  2290,  1402,    24, 17601,    15,     7,    46,\n",
            "           966,  2629,  1294,    26,   138,  6363,     6, 14399,     6, 11483,\n",
            "            40,  3676,    11,  6997,    57,     8,  9392,     6, 10090,    11,\n",
            "         24731, 15165,  1002,  2351, 26460,   785,   492,   180, 25210,    18,\n",
            "          3881,   553,  4949,     3,     9,    20, 19117,    11, 30136,  2071,\n",
            "          5255,    19,     8,  2392, 21682,  1809,    13,   165, 15102,  6894,\n",
            "            53,  3303,     6,    84,   523,    12,    36,  3427,    26,    57,\n",
            "           936, 22618,     9,  2260,     6,  2932,   271,   705,  8877,  2387,\n",
            "           179,    57,     8,  2290,  9392,   358,    37,   775,  2071,    32,\n",
            "         21324,  6427,    13,  2847,  7765,   308,  4481,  2311,     8, 22039,\n",
            "            13,  3918,    57,   928,  1868,  6803,    11,  1315,    12,     8,\n",
            "          3944,    18,  9500,     6, 16556,    20,  5517,   297,    13,     8,\n",
            "          1317, 11432, 19821,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 2847,  7765,   308,  4481,    10, 30369,   697,     8,  3739, 13324,\n",
            "            13,  1405,    31,     7,  9114,   626, 11432, 10931,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   86,   455,    12,  6570,     8,  1113,    13,  2847,  7765,   308,\n",
            "          4481,    30,  1712, 26641, 27213,   124,     6,    46, 26903,  6546,\n",
            "           810,    47,  4468,    16,  1013, 10352,  3491,    41,   196,    17,\n",
            "             9,   120,    61,    57, 24235,    53,    46,   367,  3719,    12,\n",
            "         14961, 12966,     7,    11,  8260, 16588,    28,    46,   828,   441,\n",
            "             8,   415,   309, 25985,     5,   438,  2848,    12,     8,  6081,\n",
            "          3035,  1059,     6,     8,   585,     3,  8287,    12,  9127,    10,\n",
            "          5637,   149, 27213,   124,    47,  3566,   117, 16426,  1112,    16,\n",
            "             8,   169,    13,    27,  6227,   441,  4761,  1087,   117,   232,\n",
            "         10153,     8,  2267,    13,     8,   647,    21,     8,  2345,    16,\n",
            "             3,     9,   783,    17,  1601,   296,     5, 23483,   295,     7,\n",
            "           857,    24,    10,  5637, 27213,  1087,    43,     3,     7, 22411,\n",
            "           323,     6,   237,   713,   574,    28,     8, 13855,    47,  2697,\n",
            "            95,   190,   951,    42,     8,  1284,   117, 16426,     8,   593,\n",
            "            13,  1125,  1707,    13,     8, 14961,    15,     7,    65,  1936,\n",
            "           117,  4067,  3258,     6,     8,  1901,    47,  3323,    80,    18,\n",
            "          1343,    11,   420,    18,  3035,     5,  4213,     6,   772,   504,\n",
            "            24, 10153, 18537,  1587,  1125,   783,    33, 12355,  5560,    10,\n",
            "            79,    33, 14057,    38,   578,     8,  1055,    12,   893,  8726,\n",
            "            42,  5676,    35,     8,  1675,   344,     8,  2345,    11,     8,\n",
            "         13855,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[16365,   138,  2686,    44,     8,  2900,    13, 10039,  3035,    10,\n",
            "           389, 19746,    52,  6546,  9165,    13,     8,  6502,  2345,    16,\n",
            "          1013, 10352,  3491,    41,   196,    17,     9,   120,    61,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 1813,  4900,  2071,  5255,     7,   916,    12, 13591,   859,  6917,\n",
            "             6,  4422,   920,  3127,    11,     3, 27667, 15183,     5,    37,\n",
            "          6831,    13,  6472, 27154,    21,  5673,    16,     8,  2290,  2074,\n",
            "            19,  4462,    12,     8,  3060,    13,    46,  7821,  6722,     5,\n",
            "          5154,     7,  9689,    24,  3607,  3060,  6313,     7,    28,     8,\n",
            "          7321,    11,  7322,    13,  5673,    66,   400,     7,    16,     8,\n",
            "          2290,  2074,     5,   611,     6, 23941,  3830,    13,    48, 22455,\n",
            "            33, 25976,     5,  9217,    23,    32,    26,   102,     7,   159,\n",
            "             3, 13958, 13662,    18,    18,   235,   115, 21007,     3, 24335,\n",
            "           815,    63, 18095,    41,  3463,   553,    61,   795,    46, 11082,\n",
            "           120,  3255,  2071,    32,  3734,    12,  2075,     8,  1413,  4895,\n",
            "           344,  6472, 12338,    16,  2290,    31,     7,  4324,  6873, 11102,\n",
            "            11,  6722,  7322,     5,  2149,   447,  7952,    13,    71,     5,\n",
            "             3, 13958, 13662,    28,   332,  8878,    19,  6478,    57,   386,\n",
            "         12613,  2072,    23,     6,    28,   315,  9211,  6137,     7,     3,\n",
            "         14177,    16,  4324,  6873, 11102,  3345,    30,     8,  6472, 17668,\n",
            "            44,   175,   386,  2072,    23,     5,   947,     6,    62,   504,\n",
            "            24,     8,   332,  8878, 14340,    12,     3,     9, 16080,  9211,\n",
            "          6137,  2225,     8,  6722,    12,  4234,    16,  4075,     6, 18526,\n",
            "            11, 21151,  3976,    16,  9211,  6137,     7,    24,   130,  1540,\n",
            "         11853,    12,     8, 31352,  6722,     5,    37,   701,    13,   175,\n",
            "           772,    19,   192, 10533,     5,  1485,     6,    62,  3217,    24,\n",
            "             8,  6831,    13, 14610, 16080,  1742,  1250,    21,     8,  7821,\n",
            "          6722,    12, 20720,  5673,    66,   400,     7,    24,     8,  6722,\n",
            "            65,   470, 15110,     5,  5212,     6,     8,  2077,    13,  5673,\n",
            "         13485,   164,   163,    36,  3982,    21,     3,     9,   168,    18,\n",
            "         17094, 16686, 31595,    15,    68,    59,    21,  4251,  8886,   447,\n",
            "         16686, 11683,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[    3, 14808,   257,    13, 16025,     3, 24335,   815,    63, 18095,\n",
            "            12,     3,     9, 16080,  9211,  6137,    13,  9217,    23,    26,\n",
            "          9280,   159,     3, 13958, 13662, 24033,     7,    34,    21,   358,\n",
            "           447,  7952,    13, 11853,  9211,  6137,     7,     5,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[29120, 25108,  8788,   160,  2704,    13,  6237,  2847,  7765,   308,\n",
            "          4481,    28,   160,   384,     6,    11,     8,  7544,  3976,   255,\n",
            "          7865,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[21963,    10,    46,    73,    60,    75, 12905,  3843,     3, 18018,\n",
            "            13,  2847,  7765,   308,  4481,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 2867,  5997,    11, 14057,   569, 15997,     7,   130,  1968,    28,\n",
            "           647, 12368,  7198,    11,   993,  1020,    13, 16434,    22,     7,\n",
            "          1994,    41,  6762,   137,   611,     6,     8, 11737,    13, 14057,\n",
            "           569, 15997,  3345,    30,   315,  3739,  6518,    13,  8502,    43,\n",
            "            59,   118,     3,    15, 12804, 14134,     5,    37,  2674,    13,\n",
            "            48,   810,    47,    12,  9127,     8,  2860,    13, 14057,   569,\n",
            "         15997,    42, 30170,    30,  2241,  1809,    11,   647, 12368,     3,\n",
            "          1313, 11827,    32,  2593,    16,  1221,   113,    33,   840,    28,\n",
            "            42,    33,    44,  1020,    21,  8502,     5,    71,   792,    13,\n",
            "             3, 26782, 12766,  1221,    41,   526,   152,  1246,    13,     3,\n",
            "          3940,   203,    61,   113,   141, 10394,    13,  2594,   982,    41,\n",
            "          3288, 24242, 12368,  7198,   784,   134,  6931, 13679, 12210,  8248,\n",
            "         12368, 22018,   784,  3698,   196, 13679,     3,  4608,  8502,    61,\n",
            "           365, 16103,  8649,     3, 19045,    11,  6567,  8118,  4478,  2505,\n",
            "             5,   301,   782,  6972,     7,    47,  8413,    57,    80, 14865,\n",
            "          2118,   822,   105,  4135,    25,   557,   473, 23633,    58,  1239,\n",
            "          3152,   226,    15,    40,    18,   390,     3,  8886,    32, 17685,\n",
            "            47,  4468,    12,  6825,  3518,  9954,  1052,  2908,    41,    52,\n",
            "          7381,   553,    61,  1750,  1968,    28, 30170,    16,   284,   563,\n",
            "             5,   304,  6825,   928,  5859,    16, 12368,     3,  1313, 11827,\n",
            "            32,  2593,     3,   390,    30, 30170,     6,   769, 10739,  1693,\n",
            "            47,  3032,    16, 11696,  1221,    28,  8502,    41,    29,  3274,\n",
            "          1902,    61,    11,   554,    18,    26,  1194,    23,     9,  2637,\n",
            "            41,   134,  6931,    18,  3698,   196,     6,     3,    29,  3274,\n",
            "          2059,    61,   338,     8, 29308,  7586,    13, 16434,    22,     7,\n",
            "         14326, 15186, 13380,    15,    18,    75, 12905,  3268,  3876,    18,\n",
            "           683,  9750,  1496,    15,   988,    41, 16759,   134,    18,   683,\n",
            "           509,   122,   137, 19378,  2241,   584, 12122,  1693,     3, 14622,\n",
            "         23633,    12,   529,    18,    40,   782,   120,  1221,  5111, 30170,\n",
            "            47,  1968,    28, 13665,     3,    52,  7381,   553,    16, 24097,\n",
            "             3, 13958,     9,  3252,    16,   180,  6931,  1221,    11,    16,\n",
            "             8,   646,  2214,     3,    32,    75,  3389,  9538,     3,   122,\n",
            "            63,  4502,    11,     8, 14486,  7708,   291,   548,  1982,     3,\n",
            "         11846,    83,    15,     7,    27,     3,     2,   584,    16,   283,\n",
            "          3597,  1221,     5,  7389,   483,    13,     3, 16759,   134,    18,\n",
            "           683,   509,   122,    16,  1221,   113,  2196, 30170,    47,  4019,\n",
            "          2123,     3, 14622,    12,   175,   529,    18,    40,   782,   120,\n",
            "            16,   180,  6931,    18,  3698,   196,   563,     6,    68,    59,\n",
            "            16,  8502,   563,     5,   421,   772,  6360,    24, 14057,   569,\n",
            "         15997,     6,    42, 30170,     6,   429,    36,     3,     9,     3,\n",
            "           287,   127,  9824,     3, 18018,    13,  1221,    28,   180,  6931,\n",
            "            42,   283,  3597,     6,    84,   656,   135,    72,  9930,    12,\n",
            "             8,  6567,  8292,  1863,    13,   647,  8502, 13324,     5, 24654,\n",
            "          5329, 21221, 24721, 28338,    10,    37,   367,   988,  2579,     3,\n",
            "         31505,  1037,   347,    44,  5477,  2915,   940,    87,     7, 20522,\n",
            "          3436,    18,  4305,  7412,  1206,  3449, 20445,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 1915,   565,   757,    26,   569, 15997,    19,     3, 29604,    28,\n",
            "          2241,  1809,    11, 12368, 29912,    16, 16434,    22,     7,  1994,\n",
            "             1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   37,  2847,  7765,   308,  4481,  2131,   221,  3113,    65,  2237,\n",
            "            12,  6937,  8030,  9824,   485,     6, 20544,     6,    11,   569,\n",
            "            11,  1456, 17879,     6,   952,  4840,  2256,    53,  2550,   533,\n",
            "             5,    37,  1730,    13,    48,   810,    47,    12,  1463,  5001,\n",
            "            16,  2550,   533,  3976,     6,   169,    13,   364,     6,    11,\n",
            "            73,  3493,   174,    21,   364,   859,   412,     5,   134,     5,\n",
            "          3513,    11,    12,    20,   747,   342, 12338,   640, 14798, 10133,\n",
            "             9,     5,  2747,   130,  6796,    45,     8,  6503,   412,     5,\n",
            "           134,     5,  1384,  6134, 10035,     7,    15, 11418,    45, 12171,\n",
            "          2269,    18, 14309,   138,   367, 13484,  4759,   344,  1186,  1902,\n",
            "            11,  1671, 12992,  6503,    45,  1914,  3707,  6355,   519,  3940,\n",
            "           837,  3513,     6,  1293,    15,    26,    12,  4221,     8,   412,\n",
            "             5,   134,     5,  2074,     5, 11418, 16467,  1044,    18,    60,\n",
            "         16262,    70,  3976,    13,  6261,    11,  7562,     6,   169,    13,\n",
            "          7757,     6, 15457,   364,     6,    11,    73,  3493,   174,    21,\n",
            "           364,     5,  3750,     7,    13, 23093,  6261,    11,  7562,  4659,\n",
            "          4019,   190,     8,   810,  1059,     6,    12, 24753,  1917,    13,\n",
            "          5743,    11,   314,  5988,     6,  6898,     6,    57,  1671,  6503,\n",
            "             6,  1917,  1296,   648,  1146,   145,   778,  1360,   412,     5,\n",
            "           134,     5,  7982,     7,     5,  2048,    13,  7744,  7757,     6,\n",
            "         15457,   364,     6,    11,    73,  3493,   174,    21,  2550,   533,\n",
            "           364,    92,  4659,  4019,     5,  1266,  2165,  1433,  1917,    13,\n",
            "         23093,  2550,   533, 10461,   130,  2030,   859,  1021,     6,   705,\n",
            "          7226,    26,     6,   712,     6,  3955,     6,  1589,    11,   978,\n",
            "          2837,   447, 16467,     6,    28,  1246,    11,  1073,  8378,  2197,\n",
            "          1710,   147, 23785,     7,     5,  5209,     6,  3955,     6,    11,\n",
            "          8107,   120,  7226,    26, 16467,    92,  2196,  1146,    73,  3493,\n",
            "           523,    21,   364,     5,  2678,  1893,  2197,    16, 10014,    13,\n",
            "          2550,   533, 10461,    11,  2550,   533,  1058,  6360,     3,     9,\n",
            "         11214,  1028,    15,  1169,  6856, 11879,   344,     8,  1055,   174,\n",
            "            21,    11,     8,   169,    13,  2550,   533,   364,   383,     8,\n",
            "          2847,  7765,   308,  4481,  2131,   221,  3113,     5, 25813,  2550,\n",
            "           533,  2428,    33,   271,     3, 12940,     3,  6974,    57,  1021,\n",
            "             6,   705,  2337,    26,   151,    13,   945,    11,   887,     6,\n",
            "            28,     8,  1055,    21,  8148, 23044,     7,    12,  6624, 11850,\n",
            "            11,     3, 27908,  3938,    45,  2847,  7765,   308,  4481,     5,\n",
            "             1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[11145,     7,    16,  2550,   533,  3976,     6,   313,   169,     6,\n",
            "            11,    73,  3493,   174,    21,   364,   859,   412,     5,   134,\n",
            "             5,  3513,   190,     8,   166,   668,   767,    13,     8,  2847,\n",
            "          7765,   308,  4481,  2131,   221,  3113,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   86,  4075,  2936,  1994,  4891,    30, 10274, 20556, 21642, 13335,\n",
            "            41,  4170,   382,    61,  5357,   704,  3607, 26547,   648,    11,\n",
            "           731,   583,     6,     3,  6667,  1167,    40,  3676,    57,   168,\n",
            "           147,     3,     9,   985,    13,   770,   411,  7359,   180, 25210,\n",
            "            18,  5911,   553,  4949, 17953,     7,     5,  8799,    53,   731,\n",
            "          7321,  6344,    18, 12675,  6826,     7,    65,   937,   359,  7639,\n",
            "            28,  1445,    12,     3,    15, 12804,    26,  1014,   441,  2290,\n",
            "         16686,  2074, 14966,    11,  5790,     5,   611,     6,   787,     8,\n",
            "          1146,  3505,  1080,    13,   411,  7359,     6,  4034, 10356,    13,\n",
            "          6344,    18, 12675,  6826,     7,    28,   731,    66,   400, 23446,\n",
            "          3048,    46,   539,  1921,    28,   150, 15109,  1275,   347,     5,\n",
            "            86,  1773,    12,    48,   174,     6,    62,   915, 12928, 10333,\n",
            "             6,     3,     9,  3714,  1295,    11,   166,  1573,   876,    21,\n",
            "             3, 21925,    53,   731,  7321,  6344,    18, 12675,  6826,     7,\n",
            "            45,   411,  7359,   331,  2238,     5,   101, 14434, 12928, 10333,\n",
            "            30,   321,   441,  1868,    11,   640,  1868,     3, 13804,   802,\n",
            "         18497,    11,   411,  7359, 17953,     7,   117,    69,   772,   504,\n",
            "            24, 12928, 10333,    54, 12700,  2862,   731,  7321,  6826,     7,\n",
            "           666,     3, 12100,    66,   400,  7321,     6,    91, 27245,  1895,\n",
            "           538,    18,   858,    18,   532,    18,  1408,   411,  7359,  6826,\n",
            "           580,   277,    21,    48,  2491,     5, 12928, 10333,    19,   539,\n",
            "            18,  7928,    11,   347,    21,   946,    44,    10,  2442,     5,\n",
            "         12651,  9339,     5,   287,    87,   929,  1468,    35,  9339,    87,\n",
            "          9504, 10333,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  391,  5152,    53,  5586,  5532,   835, 11298, 12928,  2366,   441,\n",
            "          9874,     9,    18,   566,  3481,  1813,  4900, 29659,     7,  1461,\n",
            "            45, 10274, 20556, 21642, 30117,   331,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[23023,    11,    71,   603,    10,  7338, 15878,    65,   582,     8,\n",
            "          1068,    13,   124,   383,     8,  2847,  7765,   308,  4481, 22494,\n",
            "             5,   100,   810,     3,  8287,    12,  6570,  2472,    11,  1868,\n",
            "          5044,    13,   414,    32,     7, 15652,    18,  3897,     3,  1931,\n",
            "         15878,  5998,     7,    28,   671,  4577,     7,     5,  7717,     7,\n",
            "            10,    71, 11735, 12556,   138,   810,    13,  1221, 12096,   120,\n",
            "         13007,    12,  2467,   192,   414,    32,     7, 15652,    18,  3897,\n",
            "             3,  1931, 15878,  5998,     7,    44,    46,     3, 20866,  6546,\n",
            "             3,   449,    17,    23,  1208,   124,  1898,    47,  4468,    45,\n",
            "          1718,    12,  1797,  6503,     5,  2747,  4759,    45,    69,  3150,\n",
            "          1790,   810,   338,   951,  4577,     7,    41,  6757,  4759,    16,\n",
            "          1186,   104, 15881,  6503,    61,   130,   261,    38,     3,     9,\n",
            "           610,  2939,     5,    37,  2329,  6138,    41,  9275,     7,    89,\n",
            "          4787,    61,    47, 14841,   190,     8,  1296,    18,  7771,  1575,\n",
            "          2604, 11372,  2247,   834,     7,  9022,    61,    38,   399,  1767,\n",
            "           585,     5, 24420,  6353,  1285,  3338,    18,   235,    18, 15116,\n",
            "            41,  6245,   188,    61,  1080,    11, 14057, 16696,    13,  1722,\n",
            "          6498,    87,    77,    18,  6075,  1130,    18,   413,  4141,     5,\n",
            "         12772,    10,   290,   130,   668,  4056,   414,    32,     7, 15652,\n",
            "          5998, 14936,   344,  1718,    11,  1797,     6,    13,    84,     3,\n",
            "         27452,   130,  4468,   190,   671,     5,  2747,    30,     3, 22367,\n",
            "          2472, 19144,     7,    11,     3,  4240,  1868, 19144,     7,   130,\n",
            "             3, 16466,     5,    37, 15572,  1246,    41,  1201,     7,    61,\n",
            "            13,  1221,  9112,  1009,   671,   784,  3436,     6,  1413, 17231,\n",
            "           699,   620,    41, 20835,   448,    61,  4678,   104,  3539,   908,\n",
            "            47,  1364,   145,   273,  9112,  1009,   951,    41,  4122,     6,\n",
            "             3, 20835,   448,  6897,   104,  4581,     6,   276,     3,   184,\n",
            "            40,    17,   117,     3, 11739, 13883, 17656,  1348,   431,  2247,\n",
            "           834,     7,  9022,    47,  1146,    28,   671,     3,  2172,    12,\n",
            "           951,    41,  4433,     5,  4704,     3,   208,     7,     3,  3940,\n",
            "             5,  5988,     6,   276,  3274,     3, 11739,  6982,     6,    38,\n",
            "            47,  6659,    31,   431,  2247,   834,     7,  9022,    41,  4327,\n",
            "             5,  2712,     3,   208,     7,     3,  4729,     5,  7561,     6,\n",
            "           276,  3274,     3, 11739, 15070,   377,  3221,  1917,     3,  7361,\n",
            "          1126,   344,     8,   192, 16396, 11372,     5,  5988,    16,  1186,\n",
            "            87, 15881,    11,  2853,  5988,   344,  1718,    87, 28680,     6,\n",
            "           276,  3274,     3, 16029, 15070,    37,  5971,    21,    16,    18,\n",
            "          6075,  1130,    18,   413,    87, 21682,  6498,    47,  4313,    16,\n",
            "           192,   671,  4577,     7,    41, 15062,  6210,     5, 29197,    10,\n",
            "          3953,  4577,     7,   383,     8,  2847,  7765,   308,  4481, 22494,\n",
            "          9028,  1146,  1868,    11,  2472,  5044,     3,  2172,    12,   951,\n",
            "          4577,     7,     5,   290,    47,   150,  1516,  1750,    16,   377,\n",
            "          3221,  1917,    11,   174,    21,    16,    18,  6075,  1130,    18,\n",
            "           413,  4577,     7,    87, 21682,  6498,   344,     8,     3,  1931,\n",
            "         15878,   192,     3, 20226,  2197,     5,     3,     2,   460,  2658,\n",
            "            37, 10236,     7,     5,   446, 14100,  2384,  1790,    57,  3559,\n",
            "            13,  2776,  6626,   295,    49,  1863,    11,   216,  4665,  1863,\n",
            "          2941,    11,  1079,  2142,  1306,     3,   184,  3885,     7,  2051,\n",
            "             6,  3937,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 3953,  4577,     7,   383,     8,  4301,   106,     9, 18095,  1994,\n",
            "          1360,  2131,   221,  3113,    33,  1968,    28,   306,  5044,    21,\n",
            "           321,  6659,    11,  1221,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 3388, 22749,   308,  6463,  9562,    10,     3, 24597,   985,    13,\n",
            "          1221,    28,  1874,   169,   128,   607,    13, 24345,  4404,  5815,\n",
            "          7450,  1874,  1058,     5,    37,  2859,    13, 24345,  4404,   557,\n",
            "          3048,    64, 28679,  3843,    16,  4577,     7,   344,  1221,    28,\n",
            "          1874,    11,    70,  4640,  3580,     5,   100,   772,    16,  1936,\n",
            "          5217,    21, 11233,    42,  6565,  1951,    11, 13665,   592,    12,\n",
            "             8,  1393,    13,  2084,    18,   390, 24345,  4404,    21,  1221,\n",
            "            28,  1874,     5,   100,  1040,  8788,     8,   408,    13,  1868,\n",
            "         11453, 10972,   810,     3, 10920,   458,  6657, 20399,    22,    24,\n",
            "             3,  8345,    12,  2075,    11,  3391,   539,    11,  1231,  1901,\n",
            "            81, 24345,  4404,    16,    30,    75,  1863,     5,    37,   810,\n",
            "            19,  4006,    91,    16,  3561,    28,   586,    41,  2032,    49,\n",
            "            61,  1221,    28,  6748,  1874,    38,  2583, 13173,   277,     5,\n",
            "             3, 24506,  6299,  3592,  3430,     3, 15610,  5121, 14408,    10,\n",
            "            37,   810,     3, 29529,     7,    28,     8,  1296,  2245,    13,\n",
            "             8,  7897, 14670,  4732,     5,  5245,   529,    18,     9,  6615,\n",
            "          3113,  9612, 11474,  3008,    41, 10061,     7,    28,  1874,     6,\n",
            "            30,    75,  1863,  4640,  3580,    11,  5903,    61,    21,  8917,\n",
            "            81,     8,  5102,     6,  2704,    11,   523,  1918, 24345,  4404,\n",
            "             5,   304,  6570,  1901,    81, 24345,  4404,     6,  4381,    30,\n",
            "            75,  1863,  4577,     7,    33, 13590,    26,     5,   242,    46,\n",
            "          8650,    13,  2084,    18,   390, 24345,  4404,   347,    12,  1221,\n",
            "            28,  1874,     6,     3,     9,  1132,    13,  2456,    19,  4468,\n",
            "            30,     8,  2084,    30,  1874,  1868,    18,    60, 16262,  6353,\n",
            "            13, 24345,  4404,  4344,   261,    57,  1221,    28,  1874,     6,\n",
            "          8839,    15,    26,    28,    46,   367,   960,    11,  3719,   859,\n",
            "          6445,    11,  7609,  1260, 24345,  4404,    12,  1221,    28,  1874,\n",
            "             5, 10965,     6,   175,  2245,  3806,  3785,    21,     8,   606,\n",
            "            13,     3,     9,  1464,  2689,    24,  4951,    46,   539,    11,\n",
            "          1231,  3071,    30, 24345,  4404,    16,    30,    75,  1863,     5,\n",
            "            86,     3,     9,  4487,   810,     6,  1845,  2020,    11,   178,\n",
            "          2020,    13,     8,  1464,  2689,    33, 14841,   859,  1221,    28,\n",
            "          1874,    11,    30,    75,  1863,  4640,  3580,     5,  2678,     7,\n",
            "            15, 14484,    13,     8,  1464,  2689,    19,  2303,    57,     8,\n",
            "          3148,    13,  8474,  5235,  2251,     5,     3, 27333, 21202,  3430,\n",
            "             3, 15438,  4132, 17684,  8015,    10,    37,  3721, 25577,  3201,\n",
            "          1533,    29,  6015,    18,   567,    23,   354,   526,   729, 10126,\n",
            "             8,   810,    47,  1215,  9045,    15,    26,    45,  4727,  5142,\n",
            "           365,     8, 10098,  3721,  2200,    86,  4571,  3745,  3892, 19237,\n",
            "             7,  1983,     5,    37,   772,    56,    36,  1028,     7,    15,\n",
            "          1109,   920,   190,   539,    18, 20393,     6, 11409,    18,    60,\n",
            "          4931, 10142,     6,  8474,  5235,    18,    60,  1493,    53,    11,\n",
            "          9972,    44,  2193, 13653,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[    3, 28318,     7,    46,   539,    11,  1231,  7478,    30, 24345,\n",
            "          4404,    16,    30,    75,  1863,    10, 10015,    13,  1868, 11453,\n",
            "         10972,   810,   458,  6657, 20399,    22,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   37, 12498, 19944, 12398,  4301,   106,     9, 18095,    41,   134,\n",
            "         25210,    18,  3881,   553,    18,  7318,    65,  3060,   640,     8,\n",
            "           296,     6,     3,  5490,    16,     3,     9,  2131,   221,  3113,\n",
            "          2847,  7765,   308,  4481,    84,    19,     3,     9,   936,     3,\n",
            "           172,    32,   106,  9798,  1994,    24,    19,  2953,    57,     3,\n",
            "             9,  3714,  4301,   106,     9, 18095,    41,  3881,   553,    61,\n",
            "          6035,   816,    12,    43, 23809,    16,  3645,    42, 28821,  3795,\n",
            "             7,    16,     8,  2332,  2847,  7765,   308, 22494,  1719,     5,\n",
            "            37,  1252,  2847,  7765,   308,  4481, 22494,   708,    16,  2846,\n",
            "          1468,    26,  2444, 19573,     6,  1473,    22,     7,  7518,  5463,\n",
            "          7985,     5,    37,  1252,  1773,    12,     8,  2847,  7765,   308,\n",
            "          4481,  2131,   221,  3113,    65,   118,     3,   107, 31303,    57,\n",
            "             8, 17224,   381,    13,    16,    89,  7633,   151,     6,   186,\n",
            "            13,  4068,   174,  9786,   124,   274, 22247,  5937,    53,    12,\n",
            "             8,  1994,     5,    37, 24878,    19,   271, 10298,    57,     3,\n",
            "             9,  2711,    13,  1994,   610,    57,   452,   533, 14418,    11,\n",
            "         21801,  1058,    21,   273,   113,    43,   118,     3, 18229,     5,\n",
            "           290,    19,   150,   964,  1181,    18,  5911,  7765,   308,  4481,\n",
            "          7757,   347,    44,    48,    97,     5,   611,     6,     8,   174,\n",
            "            12,   253, 11208,    24,    54,   919,     8, 19235,    65,  2237,\n",
            "            12,     8,   606,    13,     3,     9,   381,    13,  4962,   138,\n",
            "          4845,    38,  1055,  4341,    21,  4863,  6353,     6,   902,    16,\n",
            "             8, 20215,    11, 19302,     3,  1092,     5,  1875,   186,    13,\n",
            "           175, 28542,   757, 11208,    33,   341,   271,  7463,    16,  3739,\n",
            "         10570,     6,   771,  2371,    43, 13090,    12,  6634,     8,  4616,\n",
            "            16,    84,    70,   169,    19,     3, 10863,   326,    18,    40,\n",
            "         10333,    42, 21801,     5,    94,    19,   359,    12,  5607,  3962,\n",
            "            24,   126,   251,    81,  2847,  7765,   308,  4481,    22,     7,\n",
            "          3739,   753,     6,  1058,   931,     6,    11,  6353,    19,  1883,\n",
            "            30,     3,     9,  1646,  1873,     5,    37,   711, 21545,    13,\n",
            "          1058,  3048, 18149, 12758,   124,     6,    11,     8, 12206,  9570,\n",
            "            13,     8,  8697,  4373,    19,   341,   271,  7463,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 2847,  7765,   308,  4481,    10,     3, 31334,    15, 15715,  2149,\n",
            "             6, 11767,   419,  3791,  2748,    53,    11,  8566,    13,     3,\n",
            "         29809,  5154,    53, 24500,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[20114,     3,  2092,     8,   166,   360,   767,    13,     8,  2847,\n",
            "          7765,   308,  4481,  2131,   221,  3113,     6,  4151,  8205,  2503,\n",
            "          6960,  6926,   150,    18,  3466,   155,   127,  3101,    12,  1428,\n",
            "             8,  1020,    13,     3, 13505,  2847,  7765,   308,  4481,    16,\n",
            "           175,  3803,     5,   290,    33,   230,  1710,  3315,    24,     8,\n",
            "          5217,  1968,    28, 12103,   592,    12,   384, 17997,     7,    11,\n",
            "          2692,    43,   708,    12,    91,  1123,  9031,     8,  1055,  1393,\n",
            "          1968,    28,     3, 13494,  2847,  7765,   308,  4481, 13315,     5,\n",
            "          1404,  2797,    43, 14399,  5274,    11,  6149, 19598,  2660,  2317,\n",
            "          1722,     6,  5014,     6, 12368,     6,    11,  2550,   533,  7198,\n",
            "             7,     5,   282,  1894, 13591,     7,    45,   165,   166,  6772,\n",
            "            13,     8,  2131,   221,  3113,     6,  8205,  2503,   640,     8,\n",
            "           684,    43, 20917,   120,   708,    12,     3,    60,  8751,   175,\n",
            "          3803,     6,   780,   132,    19,  4358, 12334,    24,  7821,  7019,\n",
            "          3101,    33,   147,   120, 28219,     6,    16,    15, 10073,   179,\n",
            "            11,  6149, 10947,     5,   101,  9112,     8,  8205,   234,  7019,\n",
            "          3101,    21,  1894,    22,     7,     3,   324,  7985,     7,    11,\n",
            "           386, 23995,    38,   168,    38,  1038,  3101,    11,  2279,    30,\n",
            "             8,  2859,    12,  1344,  2084,    18,    77, 10816,     6,   331,\n",
            "            18, 11570,    11,  2205,    18,    60,  4931,  4864,    21,     8,\n",
            "             3,    60,    18,  8751,    53,    13,  4151,  8205,  2503,    12,\n",
            "           384, 17997,     7,    11,  2692,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[14490,     8,  5068, 17904,    10,   389, 24122,    18,  1570, 10816,\n",
            "         15703,    26,   663, 11167,    12,  4224,     8,   419,    18, 22696,\n",
            "            53,    13,  4151, 17069, 14093,    12,  3712,  1184, 11097,  2660,\n",
            "            11, 22317,   383,     8,  2847,  7765,   308,  4481,  4266,   221,\n",
            "          3113,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  374,   297,    23,     9,    19,     3,     9,   779,   452,   533,\n",
            "           962,  4388,    11,  6658,   169,    13,     3, 19738, 23193,   776,\n",
            "          3180,    15,     6,    84,    19,   182,  8325,    16,  8390,  1440,\n",
            "             6,    47,   435,    12,    36,     3,     9,  1020,  2945,    13,\n",
            "         19398,     5,   100,   161,     3,  8345,    44,     3, 17768,     8,\n",
            "          1113,    13,     3,     9,  4709,    16,  6658,   169,    13,     3,\n",
            "         19738, 23193,   776,  3180,    15,    30,     8,   647,  9054,    13,\n",
            "         19398,    16,  1410,     5,     3,  3626, 22781,     7,    13, 19398,\n",
            "         20588,    11,    13,     3, 19738, 23193,   776,  3180,    15,   169,\n",
            "            11,  2982,    18,  6728, 13440,     7,    13, 20544,    11,  2074,\n",
            "          4342,     6,     3,     9, 13789,  7291,    32,  1295,     3,   390,\n",
            "            30,    46,  7095,    18,   221,     9,   189,   825,   937, 13440,\n",
            "             7,    13,   633, 15600,    13, 19398,  9054,     5,   438,   150,\n",
            "           483,    16,     3, 19738, 23193,   776,  3180,    15,  5962,     6,\n",
            "             8, 24753,    13, 19398,   344,  1246,  7123,    11, 12185,    16,\n",
            "          1410,    16,   460,  2445,    47,  5861,    44,  1682,  2938,  4040,\n",
            "         14156,  2712,  3410,  8572,    41,  3597,    61,     3, 22493, 21160,\n",
            "             5,  3747,   201,    28,     3,     9,   280,  1672,  6833,   406,\n",
            "         19398,    44,  7123,   203,  4081,    12,   204, 20734,   203,  4743,\n",
            "         25211, 14855,     5,  5268,    21,   887,    11,   204, 26195,   203,\n",
            "          4743,  9285, 14962,     5,  7318,    21,  1076,     5,   282,  4078,\n",
            "            53,     3,     9, 10587,   663,    13,  6658,   169,    13,     3,\n",
            "         19738, 23193,   776,  3180,    15,    16,  6503,     6,     8, 24753,\n",
            "           133,    36,  3915,    57,    81,  4357,  6370,    16,   460,  2445,\n",
            "            11,     8,   280,  1672,  6833,   406, 19398,   133,   993,    57,\n",
            "          4097,  3264, 17482,     5,  4271,    18, 12734, 10938,   215,   859,\n",
            "           887,    11,  4097,  4834,    41, 12100, 18629,     5,  4056,    61,\n",
            "           859,  1076,     5,   304, 12692,     6,     3,     9, 11306,    68,\n",
            "          1516,  4709,    16,   647, 19398,  9054,   228,    36,  5105,    57,\n",
            "          6247,   750, 10919,    21,  8659,    13,     3, 19738, 23193,   776,\n",
            "          3180,    15,   169,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[14906,    13,     3, 19738, 23193,   776,  3180,    15,  5962,  4709,\n",
            "            30,   647,  9054,    13, 19398,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   37,  2674,    13,    48,   161,    19,    12,  8341,     8,  8136,\n",
            "             7,    13, 18898,    29,     6,  5093,     6,    11, 25101,    23,\n",
            "           152,  3081,  1918,  9738, 20638,  8149,    45,     3,     9,  2269,\n",
            "            18, 14700,  3503,     5,    71, 25444,    11, 18355,  1573,    47,\n",
            "           261,    28,     3,     9, 18906,  1295,    11,     3, 11944,  3081,\n",
            "          9986,    46,     3,     9,    26,     3, 24344, 19144,     5,  1377,\n",
            "          3081,    16,     8,   386,  1440,   497,    24,    79,   103,    59,\n",
            "           214,   149,    12,  1154,    28,    48,   686,    13, 26046,    11,\n",
            "            43,    59,  1204,   761,    16,    48,  1445,     6,    28,     8,\n",
            "          5294,     7,    16,     8,   386,  1440,   271,   182,  1126,     5,\n",
            "          5093,  3081,    43,     8,  2030,  5294,    13,  2136,    13,  2410,\n",
            "            81,  9738, 20638,  8149,    11, 18898,    29,  3081,    33,     8,\n",
            "          2102,   113,  6264,    12,   578,   141,     8,   167,  1488,    13,\n",
            "          9738, 20638,  8149,     5,    86,  1353,    13,  6363,     6,     8,\n",
            "          2942,     3,  9925,     6,    68,   859,   273,   113,   410,    59,\n",
            "             6, 25101,    23,   152,  3081,   410,    59,   788,    12,  2136,\n",
            "            13,  1103,     5,  5205,    26,    57,     8,  2131,   221,  3113,\n",
            "            12,  3884,    70,  2287,   367,     6,  3081,    33,  5684,  4376,\n",
            "            81,  9738, 20638,  8149,     5,   242,     8,   386,  1440,     6,\n",
            "            34,    19,  1702,  1316,    12,   240,  3629,    16,  1353,    13,\n",
            "         24641,  1725,   806, 18870,    12,  1154,    28,  9738, 20638,  8149,\n",
            "            44,   496,    11,    24,     8,   761,  1390,    21,     8,  4526,\n",
            "            24,   428,   592,    12,    48,  6945,   560,     8, 29514,    24,\n",
            "           995,  3081,    12,  1344,  2016,  3266,    12,  3531,    12,  9738,\n",
            "         20638,  8149,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[18991,    22, 27631,     7,    30, 14183, 20638,  8149,    10,    71,\n",
            "          4737,    18,   254,    83,    17,  9709,  9165,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[    3,   318, 13026,   106,     9,  6722,    19,     3,     9,  6722,\n",
            "          3919,    13,     3,  4246,  1014,   182,  1224,    11,   186,   119,\n",
            "         19601,    24,  7931,   788,    12, 17324,     7,    13,    48,  6722,\n",
            "             5,   304,   253,    91,     8,  1128,    13,  4301,   106,     9,\n",
            "          6722, 17324,     7,    13,    80,   686,    12,   430,     6,  6642,\n",
            "          5932,     7,    54,    36,  7901,    15,    26,   338,     8,  5882,\n",
            "           109,   348,    18,   518,   202,   860, 12628,     5, 28045,  6722,\n",
            "           331,    47,  1026,    45,  5945,  4739,   868,  1166,    21,  3318,\n",
            "         18485,  2784,    45, 13200,  4481,  4508,     5,    37,  5882,   109,\n",
            "           348,    18,   518,   202,   860, 12628,    19,     3,     9,  1252,\n",
            "         14632, 12628,    16,    84, 14632,    19,  3032,    12,    66,  5932,\n",
            "             7,    28,     8, 11641,    13,   411,    41,    51,    29,    61,\n",
            "            11,    19,  3919,    13,  5874,  6624, 14632,     5,   389,   359,\n",
            "          1147,    16,    48,     3,    60,     7,    49,  1836,    19,     8,\n",
            "          5932, 14632,    13,   192,  4301,   106,     9, 19601,   338,     8,\n",
            "          5882,   109,   348,    18,   518,   202,   860, 12628,     5,  5212,\n",
            "             6, 10356,    13,     8,  1128,    13, 17324,     7,    45,     8,\n",
            "          6642,    13,     8,  6722,     5,    37,   741,    13,    48,     3,\n",
            "            60,     7,    49,  1836,    19,    46, 14632,    11,     8,  1128,\n",
            "            13, 17324,     7,    13,   321,  5932,     7,     5,    37,   772,\n",
            "            13, 10356,  6642, 17324,    54,    36,   261,    12,   253,    91,\n",
            "           119, 19601, 17324,  4301,   106,     9,  6722,    38,   168,    38,\n",
            "            54,    36,   261,    16,     8,  1057,    13,   533,    38,     3,\n",
            "             9,  2848,    21,     8,  9421,    13,  4845,    21,  4301,   106,\n",
            "             9,  6722, 17324,  6138,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 8566,    13,  5882,   109,   348,    18,   518,   202,   524,   901,\n",
            "         11498,   189,    51,    12,  2862, 17324,    16,  6642,  5932,     7,\n",
            "            13, 28045,  6722,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   37,  3053,    13, 10531, 15165, 25049,   150,  1395,    19,     3,\n",
            "             9,  2714,   813,  6715,     7,  1225,  2945,    16,  1221,    28,\n",
            "         25567,  1874,     5,     3,  8212,     6,   132,    19,   150,  1157,\n",
            "         25567,  1874,  7468,   478,   190, 25567,    18,  9500,  1181,   729,\n",
            "          2505,    11,     8,  1393,    13, 19350,  1014,   224,     3,     9,\n",
            "          5336,    43,    59,   780,   118,  4162,     5,   611,     6,    46,\n",
            "          4862,  1160,   478,    19,    16,   286,     6,    30,  1690,     6,\n",
            "            21,  1076,   147,     8,  1246,    13,   943,     6,   826,  3071,\n",
            "            28,     3,     9,  4640,   771,    11,    46,  4193,    13,     8,\n",
            "          1055,  1393,     5,   100,   794,    19,    92,   347,    12,  1076,\n",
            "             3, 12072,    28,  1364, 25735,    63, 13499,  3976,     5,   101,\n",
            "           934,   386,  1488,    16,  1076,   113,   130,  1023,    26,    21,\n",
            "           529,    18,  9500,  2081,    11,   435,    12,    43, 29106,    75,\n",
            "         25049,     9,   537, 23599,     5,    37,  1221,  2196,   150, 25735,\n",
            "            63,  3976,    11,    66,   130,     3, 14064, 12223,    38,  1736,\n",
            "         12518,  2260,    45,     3,     9,   813, 15165,  2329,     5,   282,\n",
            "            48,  8209,    47,    59,  1702,    44,    46,  2283,  1726,     6,\n",
            "           132,    47,     3,     9,  7230,    16, 19350,  1014,  2016,  5872,\n",
            "             5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[14204, 15165, 25567,  1874,     3, 12072,    38,  5415,   138, 29106,\n",
            "            75, 25049,     9,   537, 23599,     3,   104,     3,     9,   934,\n",
            "            13,   386,  1488,    28,  6678,  1132,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  282,     8,  2847,  7765,   308,  4481,  6722,  3060,   640,     8,\n",
            "          7895,     6,  2600,  5533,     7,    11, 13950,    18,    15,  2169,\n",
            "             7, 22247,   440,  4143,    12,     8,  2131,   221,  3113,     6,\n",
            "         18094,    53,   237,     8,   167,   306,    18, 18816,  1087,     6,\n",
            "           379,     8,  6503, 12653, 17793,     5,   282,     8,  1252,  5362,\n",
            "          1659,  4632,    11,  2259,     7,  3666,    16,  8473, 10874,     6,\n",
            "          2600,    22,     7,  1827,  2284,     3,   104,     3,  4931,  5456,\n",
            "             3,   104,  1632,  5684, 10320,     5,  9151,    15,    26,   590,\n",
            "             3,     9,  7501,    18,   235,    18, 28296, 23945,    51,     6,\n",
            "          1296,  1827,  2284,    13,  2600,    33,  7245,     3,  5304,    16,\n",
            "           648,    13, 15093,     7,    10,  3487,  1131,    15,  7379,    63,\n",
            "           297,    12,  8839,   452,  3620,   523,   117, 13599,  7606,    11,\n",
            "         26544,   117,   109,   624, 11438,  2637,    21,   452,   207,   117,\n",
            "            26,   159, 10559,    45,   936,    12,   173,   117,     7,    63,\n",
            "            51,  4243,    13,  6018,  7785,   117,   232,     8,  1004,    21,\n",
            "           538,     3,    60,    18,    77, 13858,     5,   611,     6,   284,\n",
            "            13,   175,  1296,  2284,    19,     3, 29365,    11,     3,   324,\n",
            "             7,   757,     5,   282,   224,     6,     8,  1827,  2284,    13,\n",
            "          2600,    16,     3,     9,  1252,  5362,  6731,   321,  1465,    11,\n",
            "          2841,  8393,    13,  2600,    11,  2710,    18,   144,    18, 15599,\n",
            "             5,   282,   224,     6,    27,   915,     3,     9,  4083,   196,\n",
            "            18,   279,  3597,    41,  1649,  7928,     7,    18,   427,  1725,\n",
            "           545,   297,    18, 21153,   485,    87,   279,  5236,    18,   254,\n",
            "            23,    52,  1071,     7,    18, 29979,    61, 23945,    51,    12,\n",
            "          6481,     8,  4896,  1827,  2284,    13,  2600,    16,   648,    13,\n",
            "         31090,     5,   784,  5359, 13733,  9262, 21680,     3,  6727,  4611,\n",
            "          2990,   908, 20255,  3535,    13,  3699,  3467,    10,  3559,    13,\n",
            "            27, 25503,  1331, 16541,    19,     8,   785,    13, 10898,    17,\n",
            "         13553,    11,   165,   738,   164,    59,    36, 23350,    42,     3,\n",
            "            15, 19422,    12,  1317,  1471,    42,  1694,    12,     3,     9,\n",
            "           570,  3473,   406,     8,  2405,  3535,     3,  5235,    31,     7,\n",
            "          3980,  1545,  6059,     5,   611,     6,  1105,   164,  2281,     6,\n",
            "           946,     6,    42,   791,  2984,    21,   928,   169,     5,   100,\n",
            "          9838,   164,    36,     3,     9,  9818,    26,     5,   465,  6755,\n",
            "            19,   787,    81,     8,  7452,    13,     8,  2405,     5, 13504,\n",
            "           225,  2401,    12,     8,   926,  1790,   988,    13,     8,  1037,\n",
            "            21,     8,   423,  9838,     5,    41,  3881, 20455,  2632,  8275,\n",
            "            12,    66, 20114,     7,     5,    61,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 3349,    16,  5324,    13,  7538, 16661,    40,    10, 19289,  2048,\n",
            "             7,    13,  3349,    16,  3699,  9605,  2260,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[    3, 26953, 18256,  4630, 13110,    10,    37,  2847,  7765,   308,\n",
            "          4481,  2131,   221,  3113,    65,  2953,   779, 17879,     7,  4388,\n",
            "           437,  1332,  6503,     5,    37,   351,    13,     8, 21402, 31924,\n",
            "          2131,   221,  3113,  9028,    24,  6313,     7,    16,     8,  7952,\n",
            "          1917,    13,  2847,  7765,   308,  4481,   103,    59,  3614, 23534,\n",
            "            13,     8,  4166,     5,     3, 10539,   683, 14196,  8087,    10,\n",
            "            37,  2674,    13,    48,   810,    47,    12,  1344,     3,     9,\n",
            "          9272,  3060,   825,    13,  2847,  7765,   308,  4481,    28,    97,\n",
            "            18, 17631,  8755,  1009,  1659,  1036,    12,  3531, 16487,    12,\n",
            "             8,  4896,  1419,    13,     8, 22494,    11,     3, 31256, 10558,\n",
            "          1783,     5,     3, 24506,  6299,  3592,    10,    86,    48,   810,\n",
            "             6,    62, 18277,     3,     9, 18913,   825,    28,    97,    18,\n",
            "         17631,  8755,  1009,  1659,  1036,     3,   390,    30,  1039,    18,\n",
            "         23536,   982,     5,   101,   261,   331,    45,     8,  7054,  1166,\n",
            "             7,    21, 14326,  4330,    11, 19715,    41,   439, 23125,    61,\n",
            "            11,     8,  1166,    21,  5479,  2854,    11,  5623,    41,  4778,\n",
            "          4132,    61,    44,  1079,     7, 24704,   636,    21,  7054,    11,\n",
            "             8,   119,  1440,     6,  6898,     5,  2070,     8,   331,  5608,\n",
            "            13,  5899,     6, 16599,     6,    11, 22449,  1488,     6,    62,\n",
            "          2639,     8, 16080,    18,    77,    89,  7633,    18,    60, 28161,\n",
            "            41,   134,  5705,    61,   825,    11,   435, 24672,    26,  1275,\n",
            "            38,   168,    38,   825,  8755,     5,     3, 22265,     6,    62,\n",
            "          2930,  1540,  2895, 24228,  5275,    12,     8,  1275,    11,  8755,\n",
            "            11,   876,  3255,  1453,  3621,     5,     3, 12200,  4254,  4578,\n",
            "            10,   101,  1597,    46,  4585,   126,   180,  5705,   825,    28,\n",
            "            97,    18, 17631,  8755,  1009,  1659,  1036,  2254,     5,  7053,\n",
            "             6,    62, 16742,    26,     8,   825,    28,     8,  7450,  7113,\n",
            "           397,    18,   439,    76,    17,    17,     9,  4509,   455,   825,\n",
            "            12,  3606,   165,     3, 28209,    29,    17,  1405,     5,    86,\n",
            "           811,     6,    62, 14434,    69,   825,     3,   390,    30,     8,\n",
            "           490,    18,  7276,  1419,  2196,    45,     8,   480, 23125,     6,\n",
            "             8,  9677,   789,     6,    11,  1506,   783,     5,   101,    92,\n",
            "          2269, 27769,   920,    69,   825,   338,   331,    45,     8, 18104,\n",
            "           427,    21,  5308,     6, 12207,     6,    11,     8,   907,  1323,\n",
            "             5,  8472,  8440,  3063, 22164,    10,    37, 15663,    11,   126,\n",
            "           825,    13,    48,   810,   228,    36,  8152,    21,   710,    18,\n",
            "          1987, 21332,    13,  2847,  7765,   308,  4481,     6,    84,   228,\n",
            "           199,     8,   789,  2967,    21,     3,     9,   126, 22494,     5,\n",
            "            86,   811,     6,    45,     8,  3503,    13, 11297,  1035,  1438,\n",
            "             6,    69,   825,    65,  2021,  2793,   250,    34,  5344,     7,\n",
            "            66,     8,  8755,    38,    97,    18, 17631,     6,    84,     3,\n",
            "         17441,     8,  2883,  2637,    13, 16686,  3060,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 2977,    18, 17954,  1318, 13555,     7,    13,     3,     9, 13836,\n",
            "           120,  7127,  5041,     7,   757,  2847,  7765,   308,  4481, 20481,\n",
            "          5154,    28,  2900,    18,  2962,   102,  4596,    17,  4734,  4401,\n",
            "             7,  1009,  9509,  6630,    10,  5154,  2958,    11, 23545,   257,\n",
            "             1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[25388,    17,  1528,   585,    54,  3391,     8,   408,     6,  3498,\n",
            "            11,  8868,    13, 10570,     5,     3,  4868,    48,     6,   360,\n",
            "         10570,  6300, 19647,  2254,     6,    11,   273,    24,   103,   164,\n",
            "            59, 14529,    70,   423,  1055,     5,    86,    48, 18204,     6,\n",
            "            62,  6481,   149, 19647,   585,    54,  4139,    12,     8,   408,\n",
            "             6,  3498,    11,   239,    18,   235,    18,  1135,  1180,    13,\n",
            "             3,     9,  3689,     6,    91,  9424,     8,   464,  8281,    11,\n",
            "          3079,    24,  6758,   175,  7548,     5,    86,   692,    78,     6,\n",
            "            62,  3314,    30,    41,    23,    61,  1895,  4732,     7,    30,\n",
            "             8,  1075,    13, 19647,   585,  5815, 10570,    11,    41,    23,\n",
            "            23,    61,    69,   351,    13,  4580, 19647,   585,  4468,    38,\n",
            "           294,    13,     8, 28297,   810,    13,     8,  4646, 20805,  3689,\n",
            "            41,   134,  5045,    35,    53,    21,   486, 12042,  3188,  2160,\n",
            "           195,   257,    28,   262, 12150,    12, 18680,  9529,   201,     3,\n",
            "             9,  9068,  6504,  3375,  6478,  3689,    13,  7468,   151,  9742,\n",
            "          2861,    11,   756,    21,    44, 12042, 25427,  1092,   257,    16,\n",
            "          2329,   124,    16,  2789,     5,    37,  1087,    11,  3053,    13,\n",
            "             8, 19647,   372,  9859,    12,   359,  1112,    16,     8,   408,\n",
            "             6,  3498,    11,   239,    18,   235,    18,  1135,  1180,    13,\n",
            "             8,  4646, 20805, 28297,   810,     6,    11,     8,  8697,   711,\n",
            "          3689,     6,    16, 10454,  2399,  3055,  6238,  3689,  7192,     6,\n",
            "          3689,  1929,     6,  9398,    11,   738,    13,  3629,    11,     8,\n",
            "           251,   787,    12,  7448,  1221,    11,  2869,     5,   506,  1285,\n",
            "          3558,  2869,    12,   428,  7468,   772,    12,    66,  3008,    11,\n",
            "            59,   131,    12,   458,  8527,  1465,    22,  3008,     6,    11,\n",
            "          2123,  5786,    13,     8,  6275,    13,  1032,  6839,   871,    12,\n",
            "          3689,  1929,     5,   506,  1112,   130,     3, 27997,    57,     3,\n",
            "             9,   458,   782,   585,   372,    22,  1295,    24,   365, 29320,\n",
            "            66,  4727,    11, 15347,   464,  2842,    45,     8,    91,  2244,\n",
            "            11, 25124,    26,     8,   701,    13,   321, 19647,    11,  3689,\n",
            "         13954,  2980,     5,    37,  4421,   982,  5008,   533,   364,  1457,\n",
            "             3,     9,  2711,    13,   585,  2254,    11,   331,  1308,     5,\n",
            "           421,   351,    11,     8,  6678,   504,    24,     8,  1393,    13,\n",
            "         25078,    26,    53, 19647,   585,    16, 10570,    33,    72,   952,\n",
            "            12,    36,     3, 19007,     3,    99,  1388,    19,   787,    12,\n",
            "           321,  8649,  2580,    11,  3079,    45,     8,    91,  2244,     5,\n",
            "           506,   560, 14399,    11,  6684,  3135,    21, 19647,   585,     6,\n",
            "         25078,    26,    53, 19647,   585,  1540,   441,     8,  3689,  2486,\n",
            "             6,  1260,  2471,  3620,    11,  1438,    11,     3, 25345,    12,\n",
            "          3079,     3,   390,    30,  8543,  5786,    13,    11,  1445,    21,\n",
            "             8,   701,    13,   315,  2254,    11, 14013,     5,   101, 11052,\n",
            "           843,  1036,    21,     8,  1459,    13,   647, 10570,     5, 20660,\n",
            "          3816,    10,  9937,    53,    21,    44, 12042, 25427,  1092,   257,\n",
            "            28,   262, 12150,    12,  1428,  9529,  6827,  4902, 11053,  2938,\n",
            "          4271,  4240,  3747,    41,    89,    15,     9,     7, 11102,   810,\n",
            "          3670,  9937,    53,    21,    44, 12042, 25427,  1092,   257,    28,\n",
            "           262, 12150,    12,  1428,  9529,     3,   104,     3,     9,  6504,\n",
            "          3375,  6478,  3689,  6827,  4902, 11053,  5865, 15442,  3420,  8797,\n",
            "             1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  571,    12, 25078, 19647,   585,    16, 10570,    10,  7639,    45,\n",
            "             8, 28297,   810,    13,     8,  4646, 20805,  3689,  2486,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 2847,  7765,   308,  4481,    19,     3,     9,  5274, 24261,  1994,\n",
            "            24,    65,  7760,  2490,   536,  9286,  1342,    11,    16,    89,\n",
            "          7633,  4040,    16,     8,   907,  1323,  2932,   623,     6,   902,\n",
            "             8, 12766,  2074,     5, 25579,    53,  2084,    65,  2008,     8,\n",
            "          6722,    12,  1137, 24731,    52,    52,   107,  6623,    75,    11,\n",
            "         17133, 20113,  7216,     6,    84,  1113,    66,  3640,     7,     6,\n",
            "           379,     3, 17454,     6, 11546,     7,     6,    11,     8,  2241,\n",
            "             6,    38,   168,    38,  5273,  2197,     5,   180, 25210,    18,\n",
            "          3881,   553,  4949,    92,  2603,     7,  1221,    22,     6,  1791,\n",
            "            22,     6,    11,  2710,    22,     7,  2550,   533,    44,   508,\n",
            "             5,   290,    19,  1710,  2084,    13,     3,    60,    18,    77,\n",
            "         17856,    16,   128,  1221,     5,    37,  1288,    13,    48,  1040,\n",
            "            19,    12,   370,     3,     9,  3452,  1132,    13,   180, 25210,\n",
            "            18,  3881,   553,  4949,    18, 14515,  1994,     6,   165,  8557,\n",
            "            13,  7952,     6,  7028,     7,     6, 12206,     7,     6,    11,\n",
            "          1058,  3266,     6,   298,    92,     3,  7388,    30,   705,  5526,\n",
            "          3149,    57,  1767,  2116,     6,   379, 15027,   380,     6, 11041,\n",
            "             6,    11, 15602,    13,     8,  2131,   221,  3113,    11,   165,\n",
            "           758,     5,   101,  3032,     3,     9, 20036,  1132,    13,  2490,\n",
            "         19215,  2984,    11,  1285,   314,  1828,  9811,    45,   367, 16961,\n",
            "             6,   379,     6, 22057, 20123,     6,  1163, 23229,     6,    11,\n",
            "          1826, 14849,   636,    22,     7,  3595,     5,  2847,  7765,   308,\n",
            "          4481,  1221,   281,   190, 12498, 19944, 19285, 12398,     6,     3,\n",
            "         14578,  2917,    15,  5536,     6, 12498,  6676, 28286,   179,   538,\n",
            "             6,    11,  1510,  3114,   447, 22330,     6,    84,   398,    36,\n",
            "          3030,    57,     3,     9,  1249, 15471,   372,   379,  8205,     6,\n",
            "          7470,     6,    11, 15602,     5,    37, 12766,  2074,    11,   273,\n",
            "           113,    33,  5706,    45, 16434,    22,     7,  1994,    11, 19398,\n",
            "          1341, 21154,  1727,    12,    36,    44,     8,  1146,  1020,     5,\n",
            "           290,    33,  2059, 12956,     7,   365,   606,     6,    11,   126,\n",
            "          1058,  3266,    87,  1409,   235,  3297,     7,    33,   271, 18277,\n",
            "             5,    37,   647,   758,    21,  2847,  7765,   308,  4481,   225,\n",
            "           560,   272,    18,  8725,    11,   332,    18,  8725, 17133, 10896,\n",
            "            16,  2711,    28,  7821,   813,  6941,    40,  8606,     7,     5,\n",
            "            37,  2550,   533,    11,  7095,  2663,    13,  2847,  7765,   308,\n",
            "          4481,    33,   859,     8,   167,   359,   596,  1951,    13,    48,\n",
            "          2131,   221,  3113,    84,  2311,     3,     9,  1157,   515,    21,\n",
            "          9793,     6,  8209,    11,  1058,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 2847,  7765,   308,  4481,    10,  4543,    13,     3,     9,  1401,\n",
            "             7,    17, 12336,  4266,   221,  3113,    45,  1754,    23,  1863,\n",
            "            12, 11574,    18,  8118,    23,     9,  3929,  1318, 13555,     7,\n",
            "             1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   86,  1797,  7887,     3,     9, 16686, 24261,  1994,  4283,    16,\n",
            "             8,   690,    13, 17792,  2618,    16,  1473,     5,    71,   126,\n",
            "         12637,  5715,   106,     9, 18095,     6,   180, 25210,    18,  3881,\n",
            "           553,  4949,     6,    65,   118,  4771,    38,     8,  1966,  2071,\n",
            "          5255,    16,    48,  7952,     5,  1875,  4301,   106,     9, 18095,\n",
            "          1994,    19,  3218,   120,  7103,    38,     3,     9,     3, 26836,\n",
            "          7952,     6,  2404,   180, 25210,    18,  3881,   553,  4949,  7952,\n",
            "            19,  4344,  6446,    28,     3, 28286, 23599,     6,    11,     3,\n",
            "          8514,  6310,    15,  6310,  2176,   984,    33,     3, 28766,    16,\n",
            "           633,  1221,     5,   374, 10656,   257,     6, 12498,     3, 15329,\n",
            "          1706,     6,   813, 11674,   256, 10651,  1707,   383,  1994,     6,\n",
            "          6831,    13,  1317, 16712,  1020,  2580,   224,    38,  8363,     6,\n",
            "         18719,    42,  6676, 13177,     6,  1767, 27008,    63,     3, 27845,\n",
            "          1994,     6,     3,  2014,  3113,  9529,     6, 22586,     3, 27845,\n",
            "          1994,    33,  8325,     3,   287,   127,  9824,  2197,    16,   180,\n",
            "         25210,    18,  3881,   553,  4949,  2833,  1601,  7404,     6,    84,\n",
            "          3673, 15189,     3,  8514,  6310,    18,    15,  6310,  2176,  1020,\n",
            "             5,   611,     6,   119, 31161,  2580,    54,   341,    36,  4313,\n",
            "           224,    38,    73,    60, 20066,    15,    26,    46, 10253,   324,\n",
            "             7,    77,  2466,  1041,     6,     8,   169,    13, 17133, 14063,\n",
            "            83,    77,     7,     6,    46,  1936,   999,    13, 21186,    15,\n",
            "          1938, 19166,     3,   179,    12, 21151,     3, 15100, 13386,    11,\n",
            "           414,    32,    17, 17801,   138,  5817,   257,     6, 10090, 22935,\n",
            "             6, 10981,   999,    13, 22883, 21144,   996, 10791,  9684,     7,\n",
            "            41,  9978,     7,   201,    11,  1936,  3829,  1655,  3476,     5,\n",
            "          5586,    18,  4641,    15,  4866,    18,  9378,     3,    88,  1893,\n",
            "            77,   225,    36,  3934,    38,   778,  1058,   250,    13,   165,\n",
            "          1181,    18, 15329,  1041,    11,   165,  1418,    12,    46,  2408,\n",
            "           106,  1737,   112,  6948,     7,    11,    78, 11220,     8,   414,\n",
            "            32,   532,    40,  2552,     5,   611,     6,   633, 12206,  7839,\n",
            "            43,    92,   118,  4382,   224,    38, 25427,    77,    32, 14991,\n",
            "          1058,     6,  4845,    24,  2387,     3,  9978,     7,     6,    11,\n",
            "         10090, 29418,     5,     3, 13099,     6,  2199,     8,  4756,    13,\n",
            "             8,  2131,   221,  3113,   164,  3130,     8,   169,    13, 29917,\n",
            "          5872,    12,  1428,     8, 28830, 20544,    24,     3, 21007,  1167,\n",
            "             9, 14347,   180, 25210,    18,  3881,   553,  4949,  7952,     6,\n",
            "            62,   857,    24, 11082,  5872,   225,   163,    36,   261,   441,\n",
            "          3754,    11,  6478, 18870,     6,     8,   163,  2102,    24,    54,\n",
            "           370,  1934,    11, 11610,   251,    30,     8, 21264,    13,     8,\n",
            "          5872,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  638,     9,  6106, 23599,    11,     3,  8514,  6310,    15,  6310,\n",
            "          2176,   984,    16,  1221,    28,   180, 25210,    18,  3881,   553,\n",
            "          4949,  7952,    10,  2071,    32, 21715,    11,   758,  3266,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   71,   603,   304,  5530,  2704,   383,     8,  2847,  7765,   308,\n",
            "          4481,  2131,   221,  3113,    13,   151,   840,    28,  6658,  6522,\n",
            "         15543,   406,     3,     9,  8209,  7717,     7,   282,   294,    13,\n",
            "             3,     9,  6281,  4838,  2254,   810,    41,   279,   864,   189,\n",
            "         15543,    18, 23770,  6715,     7,   427,  8840,    16, 14542,   124,\n",
            "            10,  3004,     9,   532,    18,   308, 28367,   201,  4772, 16180,\n",
            "            26,  8917,   130, 18046,    28,   151,     3,  4822,    21,  4962,\n",
            "            13,  6658,  6522, 15543,   640,     3,   324,     3,  8049,  2869,\n",
            "            37,  2772,  1539,  1285,   746,   300,  2704,    13,  6522, 15543,\n",
            "             6,  4640,  9944,    11,     8,  1113,    13,  2847,  7765,   308,\n",
            "          4481,  2131,   221,  3113, 28747,  8917,   130,  2931,    60,  7621,\n",
            "            15,    26,     6,     3, 11665, 22573,     6,  1081,    26,    11,\n",
            "          9112,    57,     8,   810,   372,   338,     8,  4992,  1693, 12772,\n",
            "          2035,  1296,  1274,   383,     8,  1270,  6081,  3035,    21,     8,\n",
            "          2847,  7765,   308,  4481,  2131,   221,  3113,     6,   460,  3008,\n",
            "           130, 19257, 16465,  3955,     6,  1243,  1246,  7123,     3,    63,\n",
            "            52,     7,    61,  9528,  3008,  4114,  2238,     6,   192,   130,\n",
            "           464,    11,   386,  1310,  1204,     3,     9,  5899,  8209,    21,\n",
            "            70,  6522, 15543, 14794,    13,     8,  3008,  1906,  2847,  7765,\n",
            "           308,  4481,  5245,   843,  8334,   130,  4313,   209,   597,    77,\n",
            "          9174,   138,    20,    18,  2246,   127,   155,  2121,    13,  8209,\n",
            "            57,  1221,    37,  2847,  7765,   308,  4481,  2131,   221,  3113,\n",
            "            65,  2237,    12,     3,     9,  4709,    16,  3945,  4640,    21,\n",
            "            48,   563,   886,  3028,    70,  6522, 15543,    38,     3,     9,\n",
            "             3,    31,    29,   106,    18,   450,  5560,    31,   682,     6,\n",
            "            11,   717,  1800,  9220,    81,  9054,    53,    70,     3,  8049,\n",
            "            11,     8,   868,  1685,  1387,    41, 15743,   134,    61,    44,\n",
            "            48,    97,   204,  6851,  1270,     3,    31,  4029,  3035,    31,\n",
            "          4864,    21,     8,   879,  2074,     6,    19,    48,   631,    58,\n",
            "           100,   563,    33,    59,  4313,    38,  9930,    68,    43,     3,\n",
            "             9,   964,  8136,    24,    79,    33,    44,  1936,  1020,     3,\n",
            "            99,    79,   130,    12,  1696,  2847,  7765,   308,  4481,   220,\n",
            "         14906,    13,  6081,  3035,    30,     3, 22375,  3266,    21,  5037,\n",
            "          6522, 15543,  2449,    43,  7103,  8473,  7916,    12,   199,   135,\n",
            "         14331,    28,  6081,  3035,   886,   151,    33, 19880,    26,    57,\n",
            "             8,  1405,    13,  6081,  3035,    12,   169,  1028, 16408,    26,\n",
            "             3, 22375,  3266,    84,    65,     3,     9,  2841,  1113,    30,\n",
            "          5037,    70,  6522, 15543,    11,  2550,   533, 29197,    37,  1895,\n",
            "         24810, 18013,    12,  8209,    21,   151,   840,    28,  6658,  6522,\n",
            "         15543,    65,   118,   856, 28357,   383,     8,  2847,  7765,   308,\n",
            "          4481,  2131,   221,  3113,  2449,  7103,  2410,    81,   163,   826,\n",
            "           879,  2074,  1867,     6,  1066,   145, 13128,    53,     6,   788,\n",
            "            12,    59,   578,     3,     9,  8209, 18027,    11, 21637,     7,\n",
            "           174,    12,     3,    60,    18, 16408,    28,     8, 18013,    12,\n",
            "          8209,    11,   758,    13,  6658,  6522, 15543,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  101,     6,   113,    43,    29,    31,    17,   118, 12223,     6,\n",
            "            33,  1843,    13,    91,    13,     8,  1554,  1439,    58,    31,\n",
            "          6522,   924,   406,     3,     9,  8209,    10,    37,  1270,   576,\n",
            "          6961,  4481,  6081,  3035,   351,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[21488,    52,  1497,    32,     7,   159,    41,  9041,   201,    38,\n",
            "             8,   779, 24261,  1994,    16,     8,   296,     6,    65, 18827,\n",
            "          7702,    21,    59,   163,  6917,     6,    68,    92, 17941,    11,\n",
            "           633,  9106,  3244,     5,   100,  1994,  6621,  1151,  2428,    12,\n",
            "           936,    11,     3, 22987,   533,  5779,   787,     8,     3,   172,\n",
            "            32,   106,  9798,  1405,    13,     8,  2071,  5255,     7,  1966,\n",
            "            21,     8,  1994,   640,  3244,     5,   555,    13,     8,   711,\n",
            "           452,   533,  2428,  1918,     3,   172,    32,   106,  9798,     3,\n",
            "          9041,    41,   956,  9041,    61,  2953,    57,   499,   509, 19628,\n",
            "          2552,  3005,  3466,    19,    24,     8,  1176, 20588,    13,    48,\n",
            "           686,    13,     3,  9041,    16,  6917,    19,    59,   801,    11,\n",
            "            19,   952,    12,    36, 26199,    26,     5,   304,  3762,  1115,\n",
            "          2428,     3, 12151,    57,  1027,  9041,     6,    46,  4580,   555,\n",
            "          1685,  1295,    19,   906,     5,    86,    48, 14496,     6,    62,\n",
            "          5530,     8, 12226,    15,     6,   779,  2245,     6, 13618,     6,\n",
            "         10588,     6,    11,   359,   984,    24,  2237,    12,     8,     3,\n",
            "         30221,    13,     3,     9,  1176,  4580,  1249,    18, 17521,  6318,\n",
            "            11,     3,    23, 25503,   372,    24, 10380,     8, 17091,  1288,\n",
            "            13,  2421,     3,     9,  1027,  9041, 28871,     6,  1790,    16,\n",
            "          1797,     6,  3846,    94,     3, 28896,   843,  1087,    12,  1115,\n",
            "             8,  1252,  2428,  1918,     8,  9793,     6, 12305,     6,  8209,\n",
            "             6,    11,  1058,    13,  1027,  9041,     5,   101,  2497,    11,\n",
            "         15523,     8,  3172,    13,  4580,  6315,    12,    36,     3,   179,\n",
            "            12,  8582,     8,   710,    41,  1201,  6503,    61,    11,  2768,\n",
            "          1657,    41,  1201,   460,  1828,    61,  1766,     3, 17403,    16,\n",
            "             8,  1027,  9041, 28871,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 5450,     3,     9,  4908,    18,  9496,  6318,    11,    27, 25503,\n",
            "          2271,    12, 24305,     3,     9, 16550,    29,  9798, 21488,    52,\n",
            "          1497,    32,     7,   159,  2409, 11576,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 4511, 20856,   155, 28045, 18095,    18,  8584,    44,   402,  2847,\n",
            "          7765,   308,  4481,     3,  1625,     9,   107,  1076,  1191,    26,\n",
            "            23,  2131,  1778,    23,  1252,     3,  3768,  1076,  1191,    26,\n",
            "            23,  9358,   521,   107,     3,    76, 22713,     3,    63,  1468,\n",
            "             3,  3272,   302,   142,  1304,     9,     3, 23692,   989,  4288,\n",
            "          3304,     5,  8930,   107,     3,     7,   144,    76,   443,     9,\n",
            "             3,    63,  1468,   836,  4665,     3,    26,   173, 16296,  3304,\n",
            "             3,     9,    26,   138,     9,   107,   140,  4246,   302,     3,\n",
            "          3569,     9,    23,  4550,    63,    15,  1047,   152,  6722,     3,\n",
            "          4849,    15,  2780,   177,  2565,     3,  2341, 16296,  3304,    20,\n",
            "         15150,     7,    23,     3,  3768,     3,  2341,   138,    76,  3304,\n",
            "             3,  4031,   288,    77,     9,     5,  4511,    75,    23,  1313,\n",
            "           152,     3,     4,    18, 25619,   836,  4665,  1227,  1191, 23692,\n",
            "           152, 21934,   144,    99,     3,    26,   138,   265,     3,    51,\n",
            "         29605,     9,  5670,    23,  2847,  7765,   308,  4481,     5,     3,\n",
            "             4,    18, 25619,     3,  8603,  4102,     9,   102,   954,  1167,\n",
            "            76,  1076,   122,  8758,  1047,  3304, 10447,    26,   159,    23,\n",
            "           260,    76,    18,  1893,    76,  8950,     9,   330,    23,    35,\n",
            "          2847,  7765,   308,  4481,     3,  3768,   836,  4665,  1076,  1191,\n",
            "            26,    23,   491,   144,  4514,    17,    76, 28252,     9,     3,\n",
            "           157,  6129,     7,     5, 10683,     9,  4550,    15,    40,    23,\n",
            "         12572,    16,    23,     6,  6511,    23,  1076,  1744,     7,    83,\n",
            "          3304,  4550,   221,  8682,   152,  1659,  1036,     3,  1152,  4883,\n",
            "           159, 27687,  1659,  1229,    73,    17,  1598,    20, 15150,     7,\n",
            "            23,  2847,  7765,   308,  4481,     3,  2341,     9,  2878,  6895,\n",
            "            52,     9,  5738,     3,     4,    18, 25619,     5,   262,  7480,\n",
            "             9,     7,    23,     3,    63,  1468,     3,    26,   173, 16296,\n",
            "          3304,    73,    17,  1598,  1076,  2782,     9,  3464,  1912,     9,\n",
            "         20308,     3,    63,  1468,  1227,   302,    83,  3304,     3,  1152,\n",
            "           413,     9, 11723,     6,  7881,     6,   377,  4347,     3,  3768,\n",
            "          7452,     5,  4498,   173,     3, 16789,  4267,   904,  2285,    29,\n",
            "          2047,   157,  3304,     3, 17670,   210,     9,   178,    83,   152,\n",
            "         20308,    16,    23,  1144,    23,  3304, 11723,     6,  7881,     6,\n",
            "           377,   536,     3,  3768,  7452,     3,  2754,    53,    18,  2754,\n",
            "            53,  8014,  3916,     6,  8014,  3301,     6,  8014,  4327,     3,\n",
            "          3768,     3, 21962,     5, 10683,     9,  9358,  1076,  6757,  1725,\n",
            "             6, 16962,    16,    23,  1227, 14888,   102,  3304,   836,  4665,\n",
            "          1227, 27769,     9,     7,    23,     3,  3768,     3,  1050,    51,\n",
            "            76,  8603,  9799,   202,     9,  3304,    73,    17,  1598, 12442,\n",
            "          1725, 18852,    23, 28252,     9,     3,   157,  6129,     7,     3,\n",
            "            32,   109,   107,   103,   157,   449,     5,   439,   144,     9,\n",
            "             3,   157, 15254,    10, 28045, 18095,    18,  8584,     6,  2847,\n",
            "          7765,   308,  4481,     6,  5738,     3,     4,    18, 25619,     6,\n",
            "          1659,  1036,     6, 27687,  1229, 20798, 11359,  6227, 13026,   106,\n",
            "             9, 18095,    18,  8584,    42,  2847,  7765,   308,  4481,  1994,\n",
            "            65,   582,     3,     9,  1252,  2131,   221,  3113,    11,    19,\n",
            "             3,     9,   779,   682,    24,   398,    36,  4910,  2017,     5,\n",
            "           555,    13,     8,  1155,    24,    54,    36,   612,    12,  1190,\n",
            "           165, 16436,    19,    12,  1733,     8, 16436,  3741,    13,     8,\n",
            "          6722,    57,     3, 29782,    11,   692, 29359,   630,     5,     3,\n",
            "             4,    18, 25619, 12586,    54,    36,   261,    38,    46,  2433,\n",
            "            16,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  374, 15150,     7,    23,  4511, 20856,   155,  2847,  7765,   308,\n",
            "          4481,  5653,  7664,   291,  3304,  4385,  1313,     3,     4,    18,\n",
            "         25619,  3137,  4102,   202,     9,  3304,  9509,  7127,    23,    26,\n",
            "          3471,  3426,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[18726,  5190,    53,     9,   109,  9323,  1755,  4481, 16968,     6,\n",
            "          1215,   235,    40,  1361,    38,     8,  7174,    13,   941,  8205,\n",
            "             6,  9859,  6891,    12,     8, 14500,    13,   941,   452,   533,\n",
            "         22812,  4261,   203,   977,     6,  5190,    53,     9,   109,    31,\n",
            "             7,  1867,    30,  7952,   610,     6,     3, 14198,     8,  3172,\n",
            "            13,   609,  9834,     6,  3262, 30525,     6, 18426,     6, 18275,\n",
            "             6, 11775,   331,     6,    11,   533, 18298,     6,  3048,  1385,\n",
            "          2193,    16,   469,    31,     7,  1252,  2870,   581,     8,  4301,\n",
            "           106,     9, 18095,    86,  3610,    13, 18726,  5190,    53,     9,\n",
            "           109,    31,     7,  2382,   189,  3591,     6,  1150,  1685,  9139,\n",
            "         10126,  6503,     8,  1331,  2929,    13,     8, 20252,    11,  6650,\n",
            "         22106,    37,     3,  1498,    13,    96,   567,   450,  2260,    10,\n",
            "            71, 12347,    12, 12208,     3,    18, 17069,     8,  1150,    12,\n",
            "          1685,   121,    19,  5364,  1084,   100,  1108,  7181,     8, 13343,\n",
            "          1113,    13,  5190,    53,     9,   109,    31,     7,  7952,   610,\n",
            "            11,   452,   533, 14013,    30,  3629,  1083,   271,  1026,    12,\n",
            "          3480,  4301,   106,     9, 18095,  1994,  1360,    41,  5911,  7765,\n",
            "           308,  4481,    61,  7053,     6,    62,   580,    30, 10524,  1019,\n",
            "             8,   296,    12,  4032,     3, 31256,    16,  8205,    12,  7992,\n",
            "             8,  1455,    13,  1221,    11,  2519,   452,   533,    16,   455,\n",
            "            12,  1984,     8, 15387,    13,     8,   907,  9638,    31,  5086,\n",
            "           606,  1766,    12,  1175,   150,    80,  1187,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  784,   567,   450,  2260,    10,    71, 12347,    12, 12208,     6,\n",
            "         17069,     8,  1150,    12,  1685,    18, 15270,    53,  2847,  7765,\n",
            "           308,  4481, 12741,   221,  3113, 19715,     3, 29421,   127,    17,\n",
            "             7,    16,  2892,    13,  5190,    53,     9,   109,    31,     7,\n",
            "         27631,    30,    86, 17856,  4330,   908,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[    3, 10539,   683, 14196,  8087,   134,    10,    12,   810,     8,\n",
            "         25965, 20588,     6,     8, 14798,     7,    11,   533,  1124,    13,\n",
            "             8,  2074,  5285,    21,  2847,  7765,   308,  4481,     6,    11,\n",
            "            12,  2828,     8, 16556,  3438,    13,   928,  1488,    16,     8,\n",
            "          2074,    13,     8,  8561,    83,    23, 27889,    23,     9,  3156,\n",
            "            83,    23,     9,  6163,    41, 22969,    18,   427,     9, 13072,\n",
            "          5308,   137, 31864,    10,  2074,    18,   390, 12556,   138,   810,\n",
            "             3,   390,    30,     3,     9,  1368,  1309,   545,  3979,    13,\n",
            "         16961,  1285,    16,     8,  3031,   533,   251,   358,    13,     8,\n",
            "          8561,    83,    23, 27889,    23,     9,  3156,    83,    23,     9,\n",
            "          6163,     5,     3, 20788, 21089,  3430,     3, 19846, 18316,   345,\n",
            "          9156,   134,    10,     8,   810,   563, 14280,    26,    13,  1742,\n",
            "           113, 14989,    26,    16,     8,  8561,    83,    23, 27889,    23,\n",
            "             9,  3156,    83,    23,     9,  6163,    11,   113,   365, 16103,\n",
            "          2847,  7765,   308,  4481,  2505,    45,     3, 10068,  4928,    12,\n",
            "           997,     5, 14161, 22224,     5,    37,   810,   563,    47,  4313,\n",
            "            45,     8, 10343,  3501,     6,    84,  2579,    66,     8,  2179,\n",
            "          6420,  6207,  2505,  3032,    16,  3518,  2465,     5,  2300,    15,\n",
            "            26,   151,   130,     3, 28295,   139,  1465,    42,  2841,  1488,\n",
            "             6,     3,   390,    30,   794,   772,     5,   283, 13570,     3,\n",
            "          9744,  6657,   427,  7934,  3291, 18290,   134,    10, 15834,    13,\n",
            "           271,  5285,    21,    11, 25965, 20588,    13,  2847,  7765,   308,\n",
            "          4481,     5,     3, 12200,  4254,  4578,    10,     8, 25965, 15834,\n",
            "            13,   271,  5285,    21,  2847,  7765,   308,  4481,    47,   204,\n",
            "          3940,    87, 29573, 21155,     6,   298,     8, 25965, 20588,    47,\n",
            "          1630,  1488,    87, 29573,     5,  3387,    13,  5400,     6,  4433,\n",
            "           519,  5285,   151,     6,  3547,  4581,   591,    41, 20677,  6210,\n",
            "          2120,    91,    12,    36,  1465,    21,  2847,  7765,   308,  4481,\n",
            "             5,  4047,   130,  5285,    72,   557,   145,  1076,  6918,  4118,\n",
            "             3,   208,     7,     3, 27184,    87, 29573,   201,    11,    79,\n",
            "          3217,     3,     9,  1146, 20588,    13,  7952,   145,  1076,    41,\n",
            "          1828,    11,   957,    16,    89,  7633,  1488,    87, 29573,  2797,\n",
            "             6,  6898,   137,  2867, 25965, 20588,    11, 25965, 15834,    13,\n",
            "           271,  5285,   130,  1146,    16,     8, 12766,  2074,     5,  4504,\n",
            "         12238,    13,    16,    89,  7633,   151,    47,  6523,    16,  6576,\n",
            "          2503,    11,     3,  7561,    47,  7283,    57,  4640,  2765,     5,\n",
            "         21564,    17,    63,  2391,  1093,    13,  1465,  1488,   141,  6676,\n",
            "         13177,     6, 13914, 16216, 20113,  6716,     6,   298,  8363,    11,\n",
            "          1874,     3, 16730,  7806,  6170,    11,  6389,    13,     8,    16,\n",
            "            89,  7633,  2074,     6,  6898,     5,    37, 20929,  3438,    13,\n",
            "          1465,  1488,  3217,     3,     9,  3627,  3060,    13,     8,  7952,\n",
            "            16,     8,   690,    13,  2702,  2613,     6,    46,  4150,   616,\n",
            "            28,     8,  2030,  3518,  2074, 11048,     5,  8472,  8440,  3063,\n",
            "         22164,    10,     8,  2847,  7765,   308,  4481,  2131,   221,  3113,\n",
            "           410,    59,  1560,     8,  8561,    83,    23, 27889,    23,     9,\n",
            "          3156,    83,    23,     9,  6163,    38,   614,    38,   119,  5961,\n",
            "          4338,  6163,     7,     5,    86,     8,   778,  3944,     6,    38,\n",
            "         15552,    16,    48,   810,     6,     8,  2847,  7765,   308,  4481,\n",
            "          2131,   221,  3113,  1989,  4161,   887,    11, 12766,   151,     6,\n",
            "           902,   273,   840,    16,  6576,  2503,    16,  2702,  2613,     5,\n",
            "             1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 2847,  7765,   308,  4481, 13315,    16,     8,  8561,    83,    23,\n",
            "         27889,    23,     9,  3156,    83,    23,     9,  6163,    41, 22969,\n",
            "            49,    29,  5308,    61,    10,     3,     9,  2074,    18,   390,\n",
            "         29825,  1693,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[18921,    10,    37,  2847,  7765,   308,  4481,  2131,   221,  3113,\n",
            "            65,   990,    46, 19534,  1419,   213, 12914,    11, 22914, 18787,\n",
            "             7,    13, 19302,     3,  1092,  1221,    43, 23773,    15,    26,\n",
            "          4640,  1002,  4388,    71,   779,  2410,    21,  9612,  4388,    19,\n",
            "           149,    12,   200,  1865,   508,  2302,    13,  2847,  7765,   308,\n",
            "          4481,    16,    89,  7633,    11,   529,    18,    77,    89,  7633,\n",
            "          1221,     6,   298,   341,  6011,   306,    18,  4497,  3739,   124,\n",
            "             5,    71,   603,    10,   100, 14496,  8788,     8,   358,   606,\n",
            "             6,  9642,  2231,    11,     8,  2428, 15110,    16,  2421,    46,\n",
            "            16,    18,  1840,  3739,  6123, 16740,     5,  7717,     7,    10,\n",
            "          4582,     3,     9, 29308,     6,  1413,   221,  2274, 13974,  3561,\n",
            "             6,     3,     9,  2847,  7765,   308,  4481,  3739,  6123, 16740,\n",
            "            47,   990,   338,  2803,  2621,     3,  5972,    11,  7112,   687,\n",
            "          5491, 10509,    41,  2823,   434,    61,    12,  5970,  3739, 20363,\n",
            "            13,  1221,    11,  1868,  1128,    16,     3,     9,   712,  1641,\n",
            "             5,    71,   945,    18,  9886, 26622,    47,  2930,    12,  1759,\n",
            "             3,     9,  1131,  6481,    21,  1221,     3,  2544,  1706,    19,\n",
            "             3, 18687,    53,     6,   823,   788,    12,  3094, 11035,  2173,\n",
            "            42,  4131,    29,    53, 10343,  2620,     5,   389,  1151,  1681,\n",
            "          9367,  1105,    12,  9722,   323,   139,     8,  1868,    31,     7,\n",
            "          3739,    11, 10343,  8755,    21,     8,   657,   305,   477,     6,\n",
            "            11,  5510,    12,     8,  6477,  1868,  5059,    21,   856,  4193,\n",
            "             5, 12772,    10,    37,   606,    13,    46,    16,    18,  1840,\n",
            "          3739,  6123, 16740,    19,     3,     9, 20218,     6,  1231,  1464,\n",
            "            12,   995,   851,   747, 21637,     7,    12,  3393,  1868,  2637,\n",
            "            16,  1317,     3,  2239,     7,    11,     3, 31256,  7770,    15,\n",
            "            38,  3739,   120,  1316,    11,  2025,  1221,    12,     8,  2016,\n",
            "           593,    13,   124,     5, 20959,    53,     8,   604,   477,   274,\n",
            "            11,   604,   477,   227,     8,  4432,    13,     8, 16740,     6,\n",
            "             8,  5294,    13,  1221,   113,   831, 10839,    16, 14535,   257,\n",
            "            42, 16643,     3,    60,     7,   302, 13903,    30,     8,   879,\n",
            "          1035,     3,  2239,     6,  1066,   145,     3,     9,  2404,   124,\n",
            "          1898,     6, 14833,    57,   147,  5743, 13642,    91,    13,  6154,\n",
            "             6,   220,  5170,     3,   208,     7,     5,   489,    91,    13,\n",
            "          6897,     6,   209,  5170,   117,   192,    18,    17, 10990,     3,\n",
            "           102,     3,     2,     3, 25079,    57, 14639,    31,     7,  2883,\n",
            "           794,   117,  4674,  1877,  4906,   117,     3,  3597,  1300,  4560,\n",
            "            12,  5477,  3301,   137, 29197,    10,    37, 16740,    65,  9367,\n",
            "         13768,    12,  8877,  6570,  1868, 13548,    11,   495, 20363,    12,\n",
            "         25370,  3739,   124,    11, 18056, 28974, 25976,  1438,     5,    37,\n",
            "         16740,    54,    36, 18526,    26,    57,  2421,  4640,  1002,    24,\n",
            "            33,  6168,    12, 31031,    15,    28,     8,  2131,   221,  3113,\n",
            "             5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[13836,  2958,    11, 20156,   257,    13,     3,     9, 14067,  5869,\n",
            "          2825,  1433, 30424,    21,  7383,   747, 12657,  7137,    12, 30543,\n",
            "            15, 23208, 10179,     3,  2092,   638,  6961,  4481,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[    3, 10539,   683, 14196,  8087,   134,    10,    41,    23,    61,\n",
            "            12,  5530,     8,  7763,  3266,  6960,    12, 25420,  9281,  1018,\n",
            "         12388,     7,   757,  3918,    41, 14196,    61,  7794,     6,    11,\n",
            "            41,    23,    23,    61,    12,  2075,     8,  1504,    13,     8,\n",
            "          6081,  3035,    11,  7763,  3266,    30,     8,  6803,    13,  1221,\n",
            "           113,  1204,     3, 14196,   383,     8,  2332,   431,   767,    13,\n",
            "             8,  2847,  7765,   308,  4481,  6081,  3035,     5,     3, 24506,\n",
            "          6299,  3592,    10,   486,   166,     6,     8,  7763,  3266,    24,\n",
            "           130,  6960,    44,     8, 13017,   526,     9, 15198,     7,     3,\n",
            "         14196,  3132,   130,  4505,  1635,  3375,     5,  3325,     7,    15,\n",
            "         19404,   120,     6,     8,  6803,    13,  1221,   113,  1204,     3,\n",
            "         14196,    16,     8,  6081,  3035,  1059, 19198,  1332, 10892,  1600,\n",
            "          6503,    61,    11,    16,     8,  4993,  1059, 19198,  1332, 10892,\n",
            "          1600,  1360,    61,   130,     3,  2172,     5,     3, 12200,  4254,\n",
            "          4578,    10,  1404,  1455,  3629,   130,  6960,     6,    11,   132,\n",
            "            47,   150,  2847,  7765,   308,  4481,  7952,   859,  2550,   533,\n",
            "           871,    11,  1221,     5,    86,     8,  6081,  3035,  1059,     6,\n",
            "             8,   381,    13,  1221,  4743, 28640,  6210,    11,     8,   792,\n",
            "           381,    13,     3, 14196,     7,    41,  3166,     5,  5988,    61,\n",
            "           130,   705,     5,   100,  3275,    47,    72,  8304,   859,     8,\n",
            "          9742,  1221,     5,  8472,  8440,  3063,  9215,    10, 12165,  2869,\n",
            "            33,  1832,    12,   370,     3, 14196,   383,  6081,  3035,     7,\n",
            "           237,   116,     8,   573,  5790,    13,  2847,  7765,   308,  4481,\n",
            "            19,   306,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 2847,  7765,   308,  4481,    11,     3, 14196,     3,    18,     3,\n",
            "             9, 16071,  3503,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[    3, 10539,   683, 14196,  8087,    10,   304,   934,     8,     3,\n",
            "          4267, 11480,  6353,    13,  2382,  1221,    28,     3,   122,    63,\n",
            "            29,    15,    75,  7925,  1874,   113,   365, 16103,  3730,   383,\n",
            "             8, 24388, 28045, 18095, 14326,    41,  5911,  7765,   308,  4481,\n",
            "            61,  2131,   221,  3113,    11,     8,  1455,    13, 11685,  1295,\n",
            "             5,     3, 24506,  6299,  3592,    10,  2747,    13,  1221,  7747,\n",
            "           344,  1332,   335,    11,   932, 16047,  6503,     6,   130,  4759,\n",
            "         29825,   120,     5,  2747,   130, 11775,   120,     3, 16466,   338,\n",
            "         11045,     3, 30578, 14815,    21,     8,  2730,  9226,    41,  4274,\n",
            "          4256,    61, 19258,    21,  1758,     3,   208,     5,  6760,   357,\n",
            "         12734,     5,     3, 12200,  4254,  4578,    10,  2747,    13,  2382,\n",
            "          1221,   130,  1285,     5,  2940,  1243,  1246,    47, 11526,   203,\n",
            "             5,  1129,     8,  1221,     6,   305,  5988,    41,    29,  2423,\n",
            "         16169,   201,  2307,     5,  2712,    41,    29,  2423,  3769,   201,\n",
            "          8013,  2712,    41,    29,  2423,  1828,   201,    11,     3,  5406,\n",
            "            41,    29,  2423,  7256,   130, 12223,    38,   578,   414,    32,\n",
            "          8180,   138,     6,     3,  6194,  5288,     6, 28312,     6,    11,\n",
            "             3, 12388,  4331,  1874,     6,  6898,     5,  1129,   135,     6,\n",
            "           668,  5953,   365, 16103,   529,    18,    15,   935,  5560,  3730,\n",
            "             5,    71,  6211,   120,     3, 15267, 11685,  1295,    47,   261,\n",
            "            16,   507,  1454,     5, 13578,   209,  1874,    47,   435,    16,\n",
            "           431,  5953,    13,  1221,     5,   180, 19623,     7,  2196,  2847,\n",
            "          7765,   308,    18,  3897,  1112,    16,  6389,    13,     8,  1488,\n",
            "             5,    37,  1080,    13,   442, 11480, 14497,    47,     3, 26821,\n",
            "             5,  3462,   192,  1221,   141, 19222,    11, 18024, 18919,    51,\n",
            "          4554,   110,  2865,    30,     3,    17, 21783, 13241, 29216,    26,\n",
            "            12,    51,  5984,   442, 11480,   120,     6,    68,  7598,    47,\n",
            "          1465,    21,  2847,  7765,   308,  4481,    30,  4251,   526, 15447,\n",
            "          3741,  6363,  2505,     5,  8472,  8440,  3063,  9215,    10,  6719,\n",
            "            30,     8,   915,  7469,     6,    34,    19,   816,    24,     3,\n",
            "           122,    63,    29,    15,    75,  7925,  1874,  3730,   225,   916,\n",
            "           383,     8,  2847,  7765,   308,  4481,  2131,   221,  3113,   298,\n",
            "         21186,    49,    53,    12,     8,  3629,     5,  1844,  5041,  1194,\n",
            "            42,   529,    18, 31058,   758,   225,   163,    36,  1702,    16,\n",
            "          1221,    28, 15552,  7952,     5, 12109,    29,    15,    75,  7925,\n",
            "          1874,  3730,   225,   916,   383,     8,  2847,  7765,   308,  4481,\n",
            "          2131,   221,  3113,   298, 21186,    49,    53,    12,  3629,     5,\n",
            "          3462,     3,  4704,    13,  1221,  1597,  2847,  7765,   308,  4481,\n",
            "            18,  3897,  3976,   383,     8,   442, 11480,  1130,    18,   413,\n",
            "          1059,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[    3, 26656,     3,   122,    63,    29,    15,    75,  7925,  1874,\n",
            "          3730,   383,     8,  2847,  7765,   308,  4481,  2131,   221,  3113,\n",
            "            16,  9299,    10,    71,  1249, 13866, 29825, 12556,   138,   810,\n",
            "             1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 1972,  2700, 20197,     7,    41,  4184,   196,     7,    61,    11,\n",
            "           158,   122,  8027,  3484,     7,  2998,     6,     3,     9,   307,\n",
            "            18,  2708,    53,  1170,  2945,  3102,     6,    33,  3362,  3379,\n",
            "            13,   750,  1874,  5872,     5, 18502,    15,    18,  3897, 11233,\n",
            "           984,    41,    23,    52, 14611,     7,    61,   224,    38,   576,\n",
            "         24101,    11, 18919,  8823,    17,   159,    33,   168,    18, 24109,\n",
            "         12068,  2197,  1968,    28,   205,  4111,  3918,     5,   611,     6,\n",
            "           508,    18,   162,  9816,   409,     7,  1071, 24101,  6980,    12,\n",
            "           205,  4111, 21961,    19,  2196,   163,    16,  3400,   495,  2279,\n",
            "            11,   495,   939,     5,     3, 23500,     6,   508,    18,   162,\n",
            "          9816,   409,     7,  1071, 24101,    65,    92,   118,  2196,    38,\n",
            "             3,     9,  3400,     3,   287, 13555,    13,   158,   122,  8027,\n",
            "          3484,     7,  2998,   169,     5,   101,   915,     3,     9,     3,\n",
            "          3390,    18,  1201,    18,  1490,  3955,    28,   646,  1726,  2466,\n",
            "           188,    41,    75,   382,   357,   567,   632,   329,   632,    61,\n",
            "         12063,    18, 31600,  6748,  1874,  4281,     3,    29,    15,    32,\n",
            "             9,    26,  2047,  6451,    20, 26466, 12712,    11,   158, 12634,\n",
            "          4172, 19001,     9,   115,  1884,    12,     3,    29,    15,    32,\n",
            "             9,    26,  2047,  6451, 26324,    41,  5999,   254,   137,   445,\n",
            "          5173,  1285,  1068,    18,   858,    18,  2864,  6742, 13809,     3,\n",
            "         11990,   127,  8371,    75,    77,    11,     3,  7132,    32,  9553,\n",
            "             7,   102,  1483,  1599,    41,    26,    26,  5173,    61,  3510,\n",
            "            28,   158,   122,  8027,  3484,     7,  2998,   169,  2348,    57,\n",
            "          5547,  9566,    32,   102, 14098,    11,     3,  5379,  4250, 11579,\n",
            "            40,     5,   621,  4281,   160,   511,  4005,    13,     3,    26,\n",
            "            26,  5173,    28,   158,   122,  8027,  3484,     7,  2998,     6,\n",
            "             8,  1868,  2196,   874,   477,    13,   646,  8173,    11,  2939,\n",
            "          1406,     5,  3325,     7,    15, 19404,  8668, 12586,  9028,  1481,\n",
            "          4126,    35,    53,    11,     3, 15329,  1112,  3825,     8,   646,\n",
            "           769, 18780,    23,   152,     3, 27845,     6,     3,     9,   127,\n",
            "          1225, 11508,     6,   646,   212,  2719,    23,    26,     3, 27845,\n",
            "             6,     3, 20042,    23,  1982,    16,  3114,  8660,     3, 31159,\n",
            "             6,    11,     8,  2076,  3224,   212,  2719,    23,    26,     3,\n",
            "         31159,    11,   165,  6421,    53, 12979,     5,   506,  7469,   130,\n",
            "          2033,  6238,    21,   508,    18,   162,  9816,   409,     7,  1071,\n",
            "         24101,     5,  1881, 10562,    26,    53,   205,  4111,  3918,    11,\n",
            "           158,   122,  8027,  3484,     7,  2998,   169,     6,   150,  1151,\n",
            "            16, 17994,   605,    42,  7757,    24,     8,  1868,    47,  6666,\n",
            "            12,    47,  4466,    12,    36,  1968,    28,   508,    18,   162,\n",
            "          9816,   409,     7,  1071, 24101,     5,   101,   915,    48,   495,\n",
            "            12,   934,    30,    48,  3400,    68,  5274,     3,   287, 13555,\n",
            "            45,  5871, 11411,  4373,    16,  1874,  1058,     5,   101,    92,\n",
            "          4285,     8,  5113,    13,   508,    18,   162,  9816,   409,     7,\n",
            "          1071, 24101,   606,    16,  4689,    12,     8,  2847,  7765,   308,\n",
            "          4481, 12956,   788,    12,  2471,  3018,   435,    16,   321,     8,\n",
            "         12956,    11,   158,   122,  8027,  3484,     7,  2998,     5,    94,\n",
            "            19,   359,    12, 11052,     8,  1058,   261,    21,   224,     3,\n",
            "             9,     3,   287, 13555,    38,   150,     3, 23579,  1058,    65,\n",
            "           118,  2127,    21,   508,    18,   162,  9816,   409,     7,  1071,\n",
            "         24101,  2953,    57,   205,  4111,  3918,    42,   158,   122,  8027,\n",
            "          3484,     7,  2998,   169,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   71, 23043,  6320,    13,  7199,    18,   553, 19132, 12379,  1071,\n",
            "         24101,   826,  1972,  2700,    86, 13506,    17,   127, 13587,    11,\n",
            "          1276,   122,  8027,  3484,     7,  2998,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[14892,  2670,  2992,    46,  5299,  5888,    12,    69,  2710,    28,\n",
            "           664,    18,    77,  5045,     9,     7,    53,  2841, 11737,    30,\n",
            "            69,  1164,    11,   533,    57,  7084,    69,   542,  3741,     5,\n",
            "          3068,  2242,    19,   801,    12,    36,     8,   793,   827,  1391,\n",
            "            24,    20,  6801,     7,  2343,  2670,    44,     3,     9,   182,\n",
            "          2684,  1080,     5,  2133,  3113,  1765,     8,  1075,    13, 16285,\n",
            "             6,     8,  1202,  2138,     9, 14991, 26644,   433,   228,  4019,\n",
            "         16845,     8, 26644,  1080,  2049,    12,     8,  1202,  2138,     9,\n",
            "           120,     7,    17,    24, 24173,  6758,     7,     8,  1202, 14676,\n",
            "         14081,  1381,    16,     8, 26644,   433,     5,   100,  3016,  1132,\n",
            "          4396,    28,    46,  5302,    12,     8,  5368,  5761,     7,    13,\n",
            "             8,  1017,  2343,  2670,     5,    37, 12009,    13,  1202,   221,\n",
            "          3987,   257,    13,  4251,  5567,    16,   879,   130,   258, 20442,\n",
            "            15,    26,     5,     3, 28653,     7,     6,     3,     9,   360,\n",
            "          1202,  2138,     9,   120,     7,    17,     7,   130,  3665,    28,\n",
            "            46,  8053,    30, 28663, 22122,    41,   382,    23,   667, 16426,\n",
            "           201,    84,    19,     8,   167,  4344,   261,  1202,  2138,     9,\n",
            "           120,     7,    17,     5,    37,  6270,    13,  2262,   667, 16426,\n",
            "          1202,  2138,     9,   120,     7,    17,    16,     8,  1202,   221,\n",
            "          3987,   257,   433,   130,   258, 16224,    26,     6,  2348,    57,\n",
            "             8,  1100, 15895,    13,  1202,  2138,     9, 14991, 26644,    13,\n",
            "           796,  2343,  2670,     5,     3, 19807,     6,    69, 14013,    30,\n",
            "             8,   647,   585,  7943,    13,  1202,  2138,     9, 14991,  2343,\n",
            "         26644,    33,   915,     5,   947,    77,     6,     8,  3172,    13,\n",
            "          1712,     9, 14991,  1202,   221,  3987,   257,    19,     3, 25472,\n",
            "            12,  6512,   585,    30,  2421,   126,  1202,  2138,     9,   120,\n",
            "             7,    17,     7,    11,   126,  2842,    21,    20,   287,  4718,\n",
            "            13,  2343,  2670,     6,    11,   258,    12,   993,   165, 11667,\n",
            "          1080,  1989,    16,     8,   750,  2131,   221,  3113,    28,     8,\n",
            "           664,    18,    77,  5045,     9,     7,    53,  3381,    13,  2343,\n",
            "          2670,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 5810,  2138,     9, 14991,   374,  3987,   257,    13, 14892, 17305,\n",
            "            10,    71,  4533,  4543,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   37,  4301,   106,     9, 18095,  1994,  1360,    41,  5911,  7765,\n",
            "           308,  4481,    61,  2131,   221,  3113,    65, 19598,  6117,  3834,\n",
            "          2130,   334,  2663,    13,   569,     6,  1035,    11,  1456,   280,\n",
            "         13448,     5,  1875,    69,  1435,  3782,  4587,    13,     8,     3,\n",
            "         10067,  4110,    43,  2237,    12,  3805,  5765,  9361,    16,  9793,\n",
            "            11,   610,    13,  3060,     6,     3,     9,  6281,    72, 13066,\n",
            "          1295,     6,   379,  5559,    13,  3850,    11,   529,    18,  1326,\n",
            "         13072, 31161,   485,   164,  6758,    69,  1418,    12,  1709,   647,\n",
            "         22494,     7,     5,   374,  8135,    29,  4890,    69,  1435,  3376,\n",
            "            30,  1035, 31161,   485,   164, 12064,     8,  1032,    13,  4404,\n",
            "            11, 12812,    69,  1705,    13,   533,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  374,  8135,    29,  4890,  1035, 31161,   485,    16,     8,  2847,\n",
            "          7765,   308,  4481,  2131,   221,  3113,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[    3, 26953, 18256,  4630, 13110,    10,    37,  4301,   106,     9,\n",
            "         18095,  1994,  1360,    41,  5911,  7765,   308,  4481,    61,  2131,\n",
            "           221,  3113,    11,  1968,  6081,  3035,  3629,    43, 23773,    15,\n",
            "            26,  3472,    11,  7470,   364, 13448,     5, 17725,     8,  1879,\n",
            "            11, 21701, 11737,    13, 17879,    13, 15027,    41,  6646, 10795,\n",
            "            61,   364,    19,  2404,    21,  8296,  1231,   442,    18,  5911,\n",
            "          7765,   308,  4481,  3938,  3101,     5,     3, 10539,   683, 14196,\n",
            "          8087,   134,    10,    37,  2674,    13,    48,   810,    47,    12,\n",
            "          5443,     8,  1113,    13,  2847,  7765,   308,  4481,    18, 14515,\n",
            "         17879,    13,   496, 10795,   364,    30,  5699,   542,  1034,    16,\n",
            "          7904,     5,     3, 24506,  6299,  3592,    10,   101,  3334,  5699,\n",
            "            18,  4563,     6,   554,    18,  5911,  7765,   308,  4481,    16,\n",
            "            18,  6075,  3719,   331,    28,   442,  2837,   221,  3113,   951,\n",
            "          3719,   331,     6,   590,    28,   415,   789,   616,    41,   434,\n",
            "          6302,    61,    18,  4563,   251,    30,   592,    12,   496, 10795,\n",
            "           364,     5,   101,   261,     3,     9,  1750,    18,    77,    18,\n",
            "            26,    99, 11788,  1295,    11, 14650, 10301,  8563,  5001,    16,\n",
            "             8,   542,  1034,    13, 15802,    28,    11,   406,   592,    12,\n",
            "           496, 10795,   364,     5,  1129,     8,  3106,    26, 15802,     6,\n",
            "           505,  5170,   619,    16,   301,  6302,     7,    28,   496, 10795,\n",
            "           364,     5,     3, 12200,  4254,  4578,    10,  1384,  6134,     7,\n",
            "          1906,    46,   993,    16,   542,    16, 19361,    16,     8,   442,\n",
            "            18,  5911,  7765,   308,  4481,  3719,  1751,     5,    37,   698,\n",
            "            13, 15802,  5210,  5341,     3,     9,  3506,  1936,    57, 10635,\n",
            "          5294,   979, 14156,  2712,     3,  3597,    10,  8537, 19431,  5294,\n",
            "           979,   137,  2847,  7765,   308,  4481,    18, 14515, 17879,     7,\n",
            "            13,   496, 10795,   364,  1936, 15802,    31,  2704,    13,   542,\n",
            "            16, 19361,     6,  3094,     8, 15834,    13,  5210,  5341,     3,\n",
            "             9,  3506,    57,   668,  5294,   979, 14156,  2712,     3,  3597,\n",
            "            10,   220, 10794,  5294,   979,    61,    11,     8, 17902,    13,\n",
            "           352,   406,  3182,    21,     3,     9,   829,   239,    57,   220,\n",
            "          5294,   979, 14156,  2712,     3,  3597,    10,   204,  9169,  5294,\n",
            "           979,   137,  2678,  9433,    23,   106,    13,   496, 10795,   364,\n",
            "            19,  1968,    28,     3,     9,     3, 18189,  9579, 14156,  2712,\n",
            "             3,  3597,    10,     3, 11739, 26814,     5,  4853,  9579,    61,\n",
            "           993,    16,     8,   542,    16, 19361,  5538,     5,  1384,  6134,\n",
            "             7,     3, 19801,    16,  2315,  8154,  6926,  6081,  3035,  3629,\n",
            "          2196,   856,     3, 18687,    23,   106,    16,   542,    16, 19361,\n",
            "             5,  7871, 16449,    11,  2714,    49, 15802,  1906,  4352,  2186,\n",
            "             3, 18687,  2865,    16,   542,  1034,   788,    12, 17879,    13,\n",
            "           496, 10795,   364,     5,  8472,  8440,  3063, 22164,    10,   421,\n",
            "          7469,   504,    24,  2847,  7765,   308,  4481,    18, 14515, 17879,\n",
            "             7,    16,  3472,    11, 15027,   364,    43,     3, 31488,    26,\n",
            "         15802,    31,   542,    16, 19361,    16,  7904,     5,   506,  7469,\n",
            "            54,  3261,     8,  2888,    13,  5299,    11,  2768,    18,  1987,\n",
            "          1291,  7216,     6,   379,     8,  2888,    13,   569,  1711,  3101,\n",
            "            11,  2433,  1356,    12, 11608, 15027,   364,  4161,    57,     8,\n",
            "          2131,   221,  3113,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 2847,  7765,   308,  4481,    18,  1570, 12160,    26,  2678,  9433,\n",
            "          2865,    13,  1121,  8495,    26,    53,  1799,  1881,     9,  2110,\n",
            "          3697,    15,  3139,    86, 19361,    16,  7904,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   37, 19192,   381,    19,    46, 11169,    13,     8,  9009,    13,\n",
            "            46, 24878,     5, 21900,     6,  4034, 12182,  6230,    21,    48,\n",
            "           381,    33,  1832,    21,  1357,   492,    16,  6525,     5,  1404,\n",
            "         12182,  6230,   169,     3, 23161,   331,    38,  3785,    12, 17077,\n",
            "            21, 29469,    13,  2196,  1488,     5,   611,     6,    21,  1444,\n",
            "            18,   390, 22781,     7,     6,    48,  4191,    53,  3433,    12,\n",
            "         16735,     5,   886,  6315,   169,   422,  2034,  4342,    21,  4191,\n",
            "            53,    12,  8269,    48,   962,     5,   100,     6,    16,   919,\n",
            "             6,  3433,    12,    46,  1936, 16855,  3889,    13, 12182,  6230,\n",
            "             5,   304,  8269,   175,   807,     6,    16,     8,   915,  1040,\n",
            "             6,    62,  4277,    46, 12182,  1016,    21,     8, 19192,   381,\n",
            "            24,  2284,    46,     3,     9,    75,  2064,  1427,     3, 23161,\n",
            "           381,    13,  1488,    38,  3785,     6, 10321,     3, 16217,   321,\n",
            "             8, 16855,  3889,    11,     8,  7230,     5,   242,     8,  4191,\n",
            "           812,     6,    62,  3130,   338,     3,     9,  1317,    13,    80,\n",
            "           471,   437,  2196,  1488,   557,  6981,     3,     9,  5547,  3275,\n",
            "             5,   101,   504,    24,    48,  1295,    19,    72,  6268,   581,\n",
            "         16855,  2197,     6,    11,    24,    34,   405,    59,  6981,   136,\n",
            "         16735,    16,     8, 22781,     3,  2172,    12, 12182,  6230,    28,\n",
            "          2755,  4191,  4342,     5,     3,  7371,     6,   557,    34,    19,\n",
            "           614,    12,  5443, 12182,  6230,    16,  2736,   250,     3,     9,\n",
            "          1591,  2827,    19,  3586,     5,   242,     3, 19175,   315,  2605,\n",
            "            13,     8, 12182,  6230,     6,    62,  4230,     3,     9,  1573,\n",
            "            12,  3806, 13699, 17953,     7,    24,    54,    36,  1026,    38,\n",
            "          1591,  2827,     7,     5, 16516,   120,     6,     8, 13699,   331,\n",
            "          2579,    66,  2193,   490,    18,  7276,  3889,     5,  4213,     6,\n",
            "            62,  1581,     8,  4382, 12182,  1016,    12,     8, 11652,   347,\n",
            "          2847,  7765,   308,  4481,   331,    21,  3434,     5,   101,  4048,\n",
            "             8,  4382, 12182,  1016,    12,   192, 12182,  6230,   261,    57,\n",
            "             8,  2822,  2968,  2715, 16608,  2548,    41,   448, 14108,   137,\n",
            "           101,  7743,    24,    69, 12182,  1016,    19,    72,  5711,   145,\n",
            "             8, 15705,     7,   902,     3,    99,     8, 19192,   381,    19,\n",
            "           885,    12,  1300,  6719,    30,     8, 12556,    24,     8,  4382,\n",
            "         12182,  1016,  3475,    72,  6268,     6,    34,   164,    36,     3,\n",
            "             9,  1934,  7000,   116,  4014,     3, 18984, 14418,     5,    37,\n",
            "         12235,    53,  1391,  1081,    19,  1790,   365,     8, 24263,    18,\n",
            "         24273,  3344,    41,  5948,     7,  1303, 12651, 16420,     5,   287,\n",
            "            87,  2998,    76,    15,   107,    87,  5911,  7765,   308,  4481,\n",
            "           137,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[  374,  5595,    18,  5840,   302,    17, 23621,    23,   106,    13,\n",
            "             8,   419, 20762,  7720,    11, 20959,  1528, 22714,    30,  6939,\n",
            "          4094,  8951, 17194,  2747,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 5879,  6630,    41,  6858,    61,    65,   118,     3,     9,  1934,\n",
            "          1464,    21,  4290, 14500,   383,     8,  2847,  7765,   308,  4481,\n",
            "          2131,   221,  3113,     5,  3235,     3,  6471,    53,  4050,    33,\n",
            "           131,    80,   616, 22993,    53,     8,  1393,     6,    38,     3,\n",
            "          6858,    54,   169,  1128,    11,   533,   331,    45,   175,  4050,\n",
            "            12,  7555,  6722,  3060,     6,  9689,   105, 10718,     7,  3013,\n",
            "             7,   642,    11,  2862,  9930,  1637,     5,   611,     6,    12,\n",
            "           103,    78,     6,    34,    19,   166,   359,    12,   766,    24,\n",
            "             8, 17953,   175,  4050,  6339,    19,  4034,     6,   339,    13,\n",
            "         14387,    15,     7,     6,    11,  3468,     6,    38,   136,  5731,\n",
            "           210,    54,  1461,  2860,     3,  6858, 20099,     5,  9246,     8,\n",
            "          2136,    13,  6683,    12,   199,   766,    48,     6,    62,   915,\n",
            "           192,  1502,    21,   273,  6990,   338,     3,  6858,    12,  1130,\n",
            "             5,    37,  1502,    62,  2569,   161,    12,    95,  6134,  1038,\n",
            "           331,   463,  2443,   474,  7444,    21,     3,  6858,     5,   101,\n",
            "           258,  2862,   213,    69,  1502,    54,    36,  1736,     6,    38,\n",
            "          1440,    43,     3, 14177,   574,     3,  6471,    53,  4050,    11,\n",
            "          5626,  4742,     7,     5,     3, 19807,     6,     8,  7648,     6,\n",
            "         10005,     6,    11, 11398,  4587,     7,    13,    69,  1295,    33,\n",
            "          5172,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 2747,  6495,    11,  3426,  9151,  1628,    21,  4873,  3235,  3083,\n",
            "            75,    53,    11,  1685, 23740,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   71,   215,    65,  2804,   437,     8,  4551,  1932, 19944, 12398,\n",
            "            41, 13098,   134,    61, 22494,    16,     8,  5750,    13,  7054,\n",
            "             5,   100,  1230, 22494,  2237,    12,     3,     9,   394,  1705,\n",
            "            13,  4640,  7952,   610,     5,    37,   166,  9677,  1868,    16,\n",
            "            89,  7633,    57,  4551,  1932,  7127,  2388,  6546, 27956, 28045,\n",
            "         18095,    41, 13098,   134,    18,  3881,   553,    61,    47, 12223,\n",
            "            30,   932, 16047,  1230,     6,   227,     3,    88,  3666,    45,\n",
            "         21936,    11, 29656,     5,   290, 10245,     6,     3, 25398,  9677,\n",
            "           151,   130,    16,    89,  7633,    28,     8,   283,  9984,    18,\n",
            "          3881,   553,    16,     3,     9,   710,    97,   190,   936,    18,\n",
            "           235,    18, 12450,  5790,     5,   432,   175,  1488,   130,  5229,\n",
            "            12,  4640,  3803,     6,    11,   944,  4077,  9285,     3,  6210,\n",
            "            16,    89,  7633,  1221,   130,  4640,  2765,     5,     3, 16977,\n",
            "          2152,    35,  7578,  1693,  5259,    24,     8,   283,  9984,    18,\n",
            "          3881,   553, 25034,   435,    16,     8,  9677,  1868,    47,  4799,\n",
            "          1341,    12,     8, 21936,  6035,     6,    11,   410,    59, 22006,\n",
            "          5790,  3949,    18,   603, 18949, 17324,     7,     5,     3, 13099,\n",
            "             6,    28,     8,   337,    16,  4075,    53,  6722,  6035,     6,\n",
            "          7054,  1906,     8,  2015,   283,  9984,    18,  3881,   553, 22494,\n",
            "          1067,     8, 13849,    29, 20936,     6,     3,  5325,   788,    12,\n",
            "             8,   315,  6803,    13,  2074, 11048,    11,     8,  4640,   358,\n",
            "             5,   101,     3,  8287,    12,  1132,     8, 29969,  4478,   753,\n",
            "            11,  1895,  1103,    30,     8,  9677,   283,  9984, 22494,     6,\n",
            "            11,  3130,  2254,    12,  1709,   647, 24878,     7,     5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[14932,   138, 16386,    26,   655,    12,  1266,  2169,  9130,  4551,\n",
            "          1932,  7127,  2388,  6546, 27956, 28045, 18095,    18,   434,  5208,\n",
            "          3387, 14577,     7,    16,  5750,    13,  7054,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the input example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[   37,   576,  6961,  4481, 22494,    65,  4283,    12,    36,     3,\n",
            "             9,  5888,    12, 25575,    21,    66,     8,  1440,     6,   902,\n",
            "          1547,     5,    37,   166,  6772,    13,    48,  6722,  4363,    16,\n",
            "             8,   684,    16,  6503,     6,    11,   788,    12,   796,   610,\n",
            "          3629,  1026,    57,     8,   789,     6,     8,  1419,    47,  6309,\n",
            "           610,    40,   179,     5,  4877,     6,     8,   511,  6772,    65,\n",
            "          1940, 10933,  3169,    12,     8,  5169,     6,    11,   237,     8,\n",
            "          3629,  2654,    31,    17,  3673,  1190,     8,  8090,     5,   100,\n",
            "           810,  6621,     3,     9,  3452,  1693,    13,     8,   511,  6772,\n",
            "            13,  4301,   106,     9,  6722,  3060,    16,  1547,     6,   590,\n",
            "            28, 25086,    26,   251,    81, 24639, 18046,    57,     8,  5169,\n",
            "             5,    37, 17953,     7,   147,    84,     8,   810,    65,   118,\n",
            "          3032,    33,  1026,    45,   898,  1762,   460,  2658,    12,   204,\n",
            "           727,   932,   460,  2658,     5,     3,     2,   460,  2658, 23570,\n",
            "             5,     1]])\n",
            "A key of the input example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 1542,  7650,   757, 10582,    13,   638,  6961,  4481,  1994,    11,\n",
            "             3, 31334,   257,    16,  1547,     1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "A key of the output example: \"input_ids\"\n",
            "The value corresponding to the key-\"input_ids\"\n",
            "tensor([[ 863, 1248, 1737,    8,  787, 9838,   12,    3,    9, 2233,    1]])\n",
            "A key of the output example: \"attention_mask\"\n",
            "The value corresponding to the key-\"attention_mask\"\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    # Tokenize the input text\n",
        "    tokenized_inputs = tokenizer(examples[\"input\"], padding=\"max_length\", truncation=True, max_length=512)\n",
        "    # Tokenize the output text\n",
        "    tokenized_outputs = tokenizer(examples[\"output\"], padding=\"max_length\", truncation=True, max_length=512)\n",
        "    return {\n",
        "        \"input_ids\": tokenized_inputs[\"input_ids\"],\n",
        "        \"attention_mask\": tokenized_inputs[\"attention_mask\"],\n",
        "        \"labels\": tokenized_outputs[\"input_ids\"]\n",
        "    }"
      ],
      "metadata": {
        "id": "f2RkIgnFxVfW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the whole dataset\n",
        "tokenized_med_ds = med_ds.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "d3ddc5e96c82494586bb9f9b09c63d4f",
            "89fc16b702c24e41a8f59abaf2d7a103",
            "e4df57152cf24e76816111582b62f5ef",
            "cd9c675f6cf747479329eb08627e22e6",
            "15c2390a48cb45c38bb58a300a19dce0",
            "0202fb2dc800464daaa6df723bcc5479",
            "acec00a370ea47e58b134cb1da1f0d1e",
            "8c06d9807de5421cad715cb74f400022",
            "addd835b00954ab8b47815bf7c794115",
            "e675b07c0224468f800dce536f21deb8",
            "36be6c3dd1374b36895e678a14381240",
            "735e9631d29e4791be84e1d145b396a3",
            "c87cae25d57041468a46eea12a5969d4",
            "1324679d2ea941248085071dbd3d1079",
            "f721e1ace3c54f3699d78fa1125392ff",
            "a836efb195434b36af1262af990e30ac",
            "484a475cbc4f4cdd9ff1f02c538975c7",
            "c85cbecd98004c53b8e742b5e3377a93",
            "4d379f79289d4cdc920178ccf7c0ac15",
            "aa3a82573bc04aac82c4aa41a4c03c14",
            "4f2dcc0e649f4e81baa5f0ce9f50317f",
            "97ded8d6e9cd40139dd10177ef1fcc73"
          ]
        },
        "id": "RzeWPWfyxVjN",
        "outputId": "918d6c7f-f053-4596-eaa6-ec14f59e2a71"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3ddc5e96c82494586bb9f9b09c63d4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "735e9631d29e4791be84e1d145b396a3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_med_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOl6MnxmHybE",
        "outputId": "b5b70df0-ce0a-4325-9cae-c80e1de99674"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['output', 'input', 'instruction', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 1600\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['output', 'input', 'instruction', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 400\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Fine-tuning and Summarization**"
      ],
      "metadata": {
        "id": "YcAMUSTT1iOG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine-tuning - Iteration 1**"
      ],
      "metadata": {
        "id": "RR8sTNYObD9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "# Ensure tokenizer and datasets are correctly initialized\n",
        "# Example: tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "# Example: tokenized_med_ds = ... # Ensure this dataset is prepared and tokenized as needed\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    rouge = evaluate.load('rouge')\n",
        "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "\n",
        "    final_scores = {}\n",
        "    for key, value in result.items():\n",
        "        if isinstance(value, dict) and 'fmeasure' in value:\n",
        "            final_scores[key] = value['fmeasure']  # Scores in [0,1] range\n",
        "        elif isinstance(value, float):\n",
        "            final_scores[key] = value  # Direct assignment for floats\n",
        "\n",
        "    return final_scores\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"my_fine_tuned_t5_small_model\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=1e-5,  # Adjusted learning rate\n",
        "    per_device_train_batch_size=16,  # Adjusted batch size for better generalization\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=4,\n",
        "    predict_with_generate=True,\n",
        "    fp16=False,\n",
        "    fp16_full_eval=False,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_med_ds[\"train\"],\n",
        "    eval_dataset=tokenized_med_ds[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "fUa99TJT-UE_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "c6bb6a1a-995d-4a8e-db78-0877be23151e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [400/400 06:03, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>15.090100</td>\n",
              "      <td>6.512728</td>\n",
              "      <td>0.187299</td>\n",
              "      <td>0.064354</td>\n",
              "      <td>0.156969</td>\n",
              "      <td>0.157003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.433800</td>\n",
              "      <td>0.457806</td>\n",
              "      <td>0.026231</td>\n",
              "      <td>0.010566</td>\n",
              "      <td>0.022597</td>\n",
              "      <td>0.022658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.319800</td>\n",
              "      <td>0.223250</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.000370</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.000690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.965000</td>\n",
              "      <td>0.215247</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.000370</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.000690</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=400, training_loss=5.20218183517456, metrics={'train_runtime': 363.804, 'train_samples_per_second': 17.592, 'train_steps_per_second': 1.099, 'total_flos': 866187529420800.0, 'train_loss': 5.20218183517456, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine-tuning Iteration 2(to improve ROUGUE score)**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-I3mPG6VNb6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "# Initialize the tokenizer and datasets\n",
        "# Ensure tokenizer and datasets are correctly initialized\n",
        "# Example: tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "# Example: tokenized_med_ds = ... # Ensure this dataset is prepared and tokenized as needed\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    rouge = evaluate.load('rouge')\n",
        "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "\n",
        "    final_scores = {}\n",
        "    for key, value in result.items():\n",
        "        if isinstance(value, dict) and 'fmeasure' in value:\n",
        "            final_scores[key] = value['fmeasure']  # Scores in [0,1] range\n",
        "        elif isinstance(value, float):\n",
        "            final_scores[key] = value  # Direct assignment for floats\n",
        "\n",
        "    return final_scores\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"my_fine_tuned_t5_small_model\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=12,  # Reduced batch size for better generalization\n",
        "    per_device_eval_batch_size=12,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=4,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,  # Enable mixed precision\n",
        "    fp16_full_eval=False,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_med_ds[\"train\"],\n",
        "    eval_dataset=tokenized_med_ds[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# Ensure the generated summaries aren't prematurely truncated\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load the fine-tuned model into a summarization pipeline\n",
        "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "def generate_summary(text, max_length=150):\n",
        "    return summarizer(text, max_length=max_length, num_beams=4, early_stopping=True)\n",
        "\n",
        "# Example usage of the summarization function\n",
        "example_text = tokenized_med_ds['train'][0]['input']\n",
        "summary = generate_summary(example_text)\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "dliNh9UeNaVf",
        "outputId": "b5ef8002-5466-482d-d3f4-e4ae032ca8ca"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='536' max='536' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [536/536 06:35, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>12.373700</td>\n",
              "      <td>2.734553</td>\n",
              "      <td>0.152355</td>\n",
              "      <td>0.053573</td>\n",
              "      <td>0.127172</td>\n",
              "      <td>0.127027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.737400</td>\n",
              "      <td>0.217914</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.000370</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.000690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.693800</td>\n",
              "      <td>0.220235</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.428000</td>\n",
              "      <td>0.222647</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'summary_text': \"study aimed to investigate the stress experienced by emergency medicine physicians during the pandemic . participants included marital status, after-shift accommodation, working in a shift, smoking behavior, having children, and spouse's job as a healthcare professional .\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine-tuning Iteration 3(to improve ROUGUE score)**"
      ],
      "metadata": {
        "id": "m-lxcMsTTggj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, EarlyStoppingCallback\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "# Ensure tokenizer and datasets are correctly initialized\n",
        "# Example: tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "# Example: tokenized_med_ds = ... # Ensure this dataset is prepared and tokenized as needed\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    rouge = evaluate.load('rouge')\n",
        "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "\n",
        "    final_scores = {}\n",
        "    for key, value in result.items():\n",
        "        if isinstance(value, dict) and 'fmeasure' in value:\n",
        "            final_scores[key] = value['fmeasure']  # Scores in [0,1] range\n",
        "        elif isinstance(value, float):\n",
        "            final_scores[key] = value  # Direct assignment for floats\n",
        "\n",
        "    return final_scores\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"my_fine_tuned_t5_small_model\",\n",
        "    evaluation_strategy=\"epoch\",  # Evaluation is done at the end of each epoch\n",
        "    save_strategy=\"epoch\",        # Ensure the model is saved at the end of each epoch\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.02,  # Increased weight decay for additional regularization\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=4,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,  # Enable mixed precision\n",
        "    fp16_full_eval=False,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,  # Load the best model at the end of training\n",
        "    metric_for_best_model=\"loss\"  # Use validation loss to determine the best model\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_med_ds[\"train\"],\n",
        "    eval_dataset=tokenized_med_ds[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]  # Stop if validation loss does not improve\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "--lwackNTrgU",
        "outputId": "6fe408cc-ca78-46cc-a93a-b21bbcfef03b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [400/400 06:57, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>14.951600</td>\n",
              "      <td>6.253641</td>\n",
              "      <td>0.186804</td>\n",
              "      <td>0.063988</td>\n",
              "      <td>0.156271</td>\n",
              "      <td>0.156306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.318500</td>\n",
              "      <td>0.442376</td>\n",
              "      <td>0.022994</td>\n",
              "      <td>0.008870</td>\n",
              "      <td>0.019645</td>\n",
              "      <td>0.019982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.309000</td>\n",
              "      <td>0.224327</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.000370</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.000690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.950800</td>\n",
              "      <td>0.216112</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.000370</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.000690</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=400, training_loss=5.132495365142822, metrics={'train_runtime': 417.7654, 'train_samples_per_second': 15.32, 'train_steps_per_second': 0.957, 'total_flos': 866187529420800.0, 'train_loss': 5.132495365142822, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the generated summaries aren't prematurely truncated\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load the fine-tuned model into a summarization pipeline\n",
        "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "def generate_summary(text, max_length=150):\n",
        "    return summarizer(text, max_length=max_length, num_beams=4, early_stopping=True)\n",
        "\n",
        "# Example usage of the summarization function\n",
        "example_text = tokenized_med_ds['train'][0]['input']\n",
        "summary = generate_summary(example_text)\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLxRd_YSITJg",
        "outputId": "018325e8-3204-4a52-8add-2c16e6b57102"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'summary_text': 'study aimed to investigate the stress experienced by emergency medicine physicians during the pandemic, the factors they found to be effective against stress, and their coping approaches to stressful situations .'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine-tuning Iteration 4*(to improve ROUGUE score)**"
      ],
      "metadata": {
        "id": "L4XBNpwO923U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, EarlyStoppingCallback\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    rouge = evaluate.load('rouge')\n",
        "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "\n",
        "    final_scores = {}\n",
        "    for key, value in result.items():\n",
        "        if isinstance(value, dict) and 'fmeasure' in value:\n",
        "            final_scores[key] = value['fmeasure']\n",
        "        elif isinstance(value, float):\n",
        "            final_scores[key] = value\n",
        "    return final_scores\n",
        "\n",
        "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, EarlyStoppingCallback\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    rouge = evaluate.load('rouge')\n",
        "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "\n",
        "    final_scores = {}\n",
        "    for key, value in result.items():\n",
        "        if isinstance(value, dict) and 'fmeasure' in value:\n",
        "            final_scores[key] = value['fmeasure']\n",
        "        elif isinstance(value, float):\n",
        "            final_scores[key] = value\n",
        "\n",
        "    return final_scores"
      ],
      "metadata": {
        "id": "9QcEFqw-9--j"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"my_fine_tuned_t5_small_model\",\n",
        "    evaluation_strategy=\"epoch\",  # Evaluation is done at the end of each epoch\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=1e-4,           # Adjusted learning rate\n",
        "    per_device_train_batch_size=8,  # Adjusted batch size\n",
        "    per_device_eval_batch_size=8,  # Adjusted batch size\n",
        "    weight_decay=0.01,             # Adjusted weight decay\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=10,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,  # Enable mixed precision\n",
        "    fp16_full_eval=False,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,  # Load the best model at the end of training\n",
        "    metric_for_best_model=\"rougeL\"  # Use ROUGE-L to determine the best model\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_med_ds[\"train\"],\n",
        "    eval_dataset=tokenized_med_ds[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]  # Stop if validation loss does not improve\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "id": "H4ICjIwa-Hhc",
        "outputId": "942058af-0532-4e68-c1eb-302398846118"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 18:55, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.743400</td>\n",
              "      <td>0.133715</td>\n",
              "      <td>0.103495</td>\n",
              "      <td>0.047119</td>\n",
              "      <td>0.084862</td>\n",
              "      <td>0.084675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.139400</td>\n",
              "      <td>0.125833</td>\n",
              "      <td>0.322122</td>\n",
              "      <td>0.158128</td>\n",
              "      <td>0.272129</td>\n",
              "      <td>0.271954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.129500</td>\n",
              "      <td>0.123266</td>\n",
              "      <td>0.360597</td>\n",
              "      <td>0.181562</td>\n",
              "      <td>0.304444</td>\n",
              "      <td>0.304131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.123200</td>\n",
              "      <td>0.121817</td>\n",
              "      <td>0.372513</td>\n",
              "      <td>0.190136</td>\n",
              "      <td>0.318405</td>\n",
              "      <td>0.318553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.119300</td>\n",
              "      <td>0.120831</td>\n",
              "      <td>0.379637</td>\n",
              "      <td>0.192239</td>\n",
              "      <td>0.322761</td>\n",
              "      <td>0.322900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.115900</td>\n",
              "      <td>0.120883</td>\n",
              "      <td>0.386657</td>\n",
              "      <td>0.197814</td>\n",
              "      <td>0.327159</td>\n",
              "      <td>0.327344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.113300</td>\n",
              "      <td>0.120550</td>\n",
              "      <td>0.385787</td>\n",
              "      <td>0.193672</td>\n",
              "      <td>0.323960</td>\n",
              "      <td>0.324384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.111100</td>\n",
              "      <td>0.120307</td>\n",
              "      <td>0.387219</td>\n",
              "      <td>0.196580</td>\n",
              "      <td>0.330424</td>\n",
              "      <td>0.330394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.110200</td>\n",
              "      <td>0.120216</td>\n",
              "      <td>0.390101</td>\n",
              "      <td>0.197268</td>\n",
              "      <td>0.331623</td>\n",
              "      <td>0.331798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.109200</td>\n",
              "      <td>0.120308</td>\n",
              "      <td>0.388869</td>\n",
              "      <td>0.197690</td>\n",
              "      <td>0.332199</td>\n",
              "      <td>0.332120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2000, training_loss=0.2814541969299316, metrics={'train_runtime': 1135.5165, 'train_samples_per_second': 14.091, 'train_steps_per_second': 1.761, 'total_flos': 2165468823552000.0, 'train_loss': 0.2814541969299316, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save Model**"
      ],
      "metadata": {
        "id": "QcwtfjzI1ybv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"my_fine_tuned_t5_small_model\")"
      ],
      "metadata": {
        "id": "Qh-YaSw7zWPF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load and Use Model**"
      ],
      "metadata": {
        "id": "4lnXHaKdX-Qj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from transformers import pipeline\n",
        "from datasets import load_metric\n",
        "\n",
        "# Load the fine-tuned model for summarization\n",
        "summarizer = pipeline(\"summarization\", model=\"my_fine_tuned_t5_small_model\", tokenizer=tokenizer)\n",
        "\n",
        "# Select a random index from the test set\n",
        "random.seed(42)  # Optional: for reproducibility\n",
        "index = random.randint(0, len(tokenized_med_ds['test']) - 1)\n",
        "\n",
        "# Generate and evaluate a summary\n",
        "text = tokenized_med_ds['train'][index]['input']\n",
        "text = \"summarize: \" + text  # Add prefix if necessary\n",
        "pred = summarizer(text, max_length=150, num_beams=5, early_stopping=True)\n",
        "generated_summary = pred[0]['summary_text']\n",
        "print(f\"Generated Summary: {generated_summary}\")\n",
        "\n",
        "# Evaluate the generated summary\n",
        "reference_summary = tokenized_med_ds['train'][index].get('output')\n",
        "rouge_metric = load_metric(\"rouge\")\n",
        "results = rouge_metric.compute(predictions=[generated_summary], references=[reference_summary])\n",
        "\n",
        "# Extract and print the scores in a readable format\n",
        "rouge1 = results['rouge1'].mid.fmeasure\n",
        "rouge2 = results['rouge2'].mid.fmeasure\n",
        "rougeL = results['rougeL'].mid.fmeasure\n",
        "rougeLsum = results['rougeLsum'].mid.fmeasure\n",
        "\n",
        "print(f\"ROUGE-1: {rouge1:.4f}\")\n",
        "print(f\"ROUGE-2: {rouge2:.4f}\")\n",
        "print(f\"ROUGE-L: {rougeL:.4f}\")\n",
        "print(f\"ROUGE-Lsum: {rougeLsum:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjwcfzMbDjQK",
        "outputId": "d0dd6361-1c65-4ec3-85a8-8ad41529d860"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Summary: intersectionality theory: African American women are vulnerable to COVID-19 due to the twin legacies of racism and sexism\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/rouge/rouge.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE-1: 0.4848\n",
            "ROUGE-2: 0.1935\n",
            "ROUGE-L: 0.3030\n",
            "ROUGE-Lsum: 0.3030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, EarlyStoppingCallback, pipeline\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "# Set up the summarization pipeline with the fine-tuned model\n",
        "summarizer = pipeline(\"summarization\", model=\"my_fine_tuned_t5_small_model\", tokenizer=tokenizer)\n",
        "\n",
        "# Select a specific example from your dataset for summarization\n",
        "index = 3  # Adjust the index as needed\n",
        "text = tokenized_med_ds['train'][index]['input']  # Ensure 'input' is the correct field for your data\n",
        "\n",
        "# Prefix with \"summarize: \" if needed (based on your model's training format)\n",
        "text = \"summarize: \" + text\n",
        "\n",
        "# Generate and print the summary for the selected text\n",
        "pred = summarizer(text, max_length=150, num_beams=4, early_stopping=True)\n",
        "print(pred[0]['summary_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMtby7kT1lxV",
        "outputId": "0e2cb7a5-7e88-4c9b-9e6b-c64dbccb44eb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sex differences and the role of estradiol in modulating the lung and systemic inflammatory response in COVID-19 patients\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sample text summarization**"
      ],
      "metadata": {
        "id": "gz6Kw1LJBQkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import textwrap\n",
        "\n",
        "# Load the fine-tuned model into a summarization pipeline\n",
        "summarizer = pipeline(\"summarization\", model=\"my_fine_tuned_t5_small_model\", tokenizer=tokenizer)\n",
        "\n",
        "def generate_summary(text, max_length=150):\n",
        "    return summarizer(text, max_length=max_length, num_beams=4, early_stopping=True)\n",
        "\n",
        "def print_sentences(text, label, width=150, bold=False):\n",
        "    # Bold using ANSI escape codes\n",
        "    bold_start = \"\\033[1m\"\n",
        "    bold_end = \"\\033[0m\"\n",
        "\n",
        "    # Print the label in bold\n",
        "    print(bold_start + label + \":\" + bold_end)\n",
        "\n",
        "    # Wrap the entire block of text to fit the specified width\n",
        "    wrapped_text = textwrap.fill(text, width=width)\n",
        "\n",
        "    # Apply bold formatting to text if needed\n",
        "    if bold:\n",
        "        print(bold_start + wrapped_text + bold_end)\n",
        "    else:\n",
        "        print(wrapped_text)\n",
        "\n",
        "# Example usage of the summarization function\n",
        "example_text = \"BACKGROUND: In this study, the ability of antimicrobial photodynamic therapy (aPDT) as a treatment approach and adjuvant therapy using curcumin-poly (lactic-co-glycolic acid) nanoparticles (Cur@PLGA-NPs) to inactivate Coronavirus disease 2019 (COVID-19) in plasma was investigated. Furthermore, to verify whether the quality requirement of aPDT-treated plasma is acceptable, the differences of the levels of clotting factors, total plasma proteins, and anti-A and/or anti-B antibodies titrations in plasma of patient before and after aPDT treatment were investigated. MATERIALS AND METHODS: Cur@PLGA-NPs was synthesized using Electrospinning process and characterized by different analysis including Scanning Electron Microscope (SEM), Transmission Electron Microscope (TEM), and Fourier Transform Infrared (FTIR) spectroscopy assays. The presence of the SARS-CoV-2 in the plasma samples of patients suspected of having COVID-19 was confirmed by real-time reverse transcription-polymerase chain reaction (RT-PCR) assay. Then, the treated plasma samples with Cur@PLGA-NPs plus blue laser were exposed to Vero cells. Eventually, cell cytotoxicity and apoptotic effects of treated Vero cells were evaluated. Levels of clotting factors including prothrombin time (PT) and activated partial thromboplastin time (APTT), total plasma proteins, and anti-A and/or anti-B antibodies measurements were performed using the coagulometer, method of Bradford, and titration procedure, respectively. RESULTS: The presence of SARS-CoV-2 was positive in 84.3 % of samples. Different concentrations of Cur@PLGA-NPs (3, 5, 7, and 10 % wt.), the irradiation times of blue laser (1, 3, and 5 min), and aPDT with the maximum dosed of blue laser light (522.8 J/cm2) plus 10 % wt. Cur@PLGA-NPs had no cytotoxicity. Although there were significant cell degradation and apoptotic effects in treated Vero cells with treated plasma using 10 % wt. Cur@PLGA-NPs, and a blue laser at an energy density of 522.8 J/cm2, no visible changes in cells and apoptosis were observed following aPDT. Total plasma protein content, PT, APTT, and anti-A and/or anti-B antibodies titers showed no significant changes (P > 0.05 for all comparisons) in treated plasma as compared to untreated plasma. CONCLUSION: aPDT exhibited in vitro anti-COVID-19 activities in the treated plasma containing SARS-COV-2 without Vero cell apoptosis and any adverse effects on plasma quality in aPDT-exposed plasma.\"  # Replace with your actual input text\n",
        "summary = generate_summary(example_text)\n",
        "\n",
        "# Print input with each sentence on a new line, wrapping lines at 80 characters, heading in bold\n",
        "print_sentences(example_text, \"\\nInput\", bold=False)\n",
        "\n",
        "# Print output with each sentence on a new line, wrapping lines at 80 characters, heading and text in bold\n",
        "print_sentences(summary[0]['summary_text'], \"\\nOutput\", bold=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP2pI5BVLy-3",
        "outputId": "67a5c1bf-7cf2-494d-c4e0-c6de54278dbd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "Input:\u001b[0m\n",
            "BACKGROUND: In this study, the ability of antimicrobial photodynamic therapy (aPDT) as a treatment approach and adjuvant therapy using curcumin-poly\n",
            "(lactic-co-glycolic acid) nanoparticles (Cur@PLGA-NPs) to inactivate Coronavirus disease 2019 (COVID-19) in plasma was investigated. Furthermore, to\n",
            "verify whether the quality requirement of aPDT-treated plasma is acceptable, the differences of the levels of clotting factors, total plasma proteins,\n",
            "and anti-A and/or anti-B antibodies titrations in plasma of patient before and after aPDT treatment were investigated. MATERIALS AND METHODS:\n",
            "Cur@PLGA-NPs was synthesized using Electrospinning process and characterized by different analysis including Scanning Electron Microscope (SEM),\n",
            "Transmission Electron Microscope (TEM), and Fourier Transform Infrared (FTIR) spectroscopy assays. The presence of the SARS-CoV-2 in the plasma\n",
            "samples of patients suspected of having COVID-19 was confirmed by real-time reverse transcription-polymerase chain reaction (RT-PCR) assay. Then, the\n",
            "treated plasma samples with Cur@PLGA-NPs plus blue laser were exposed to Vero cells. Eventually, cell cytotoxicity and apoptotic effects of treated\n",
            "Vero cells were evaluated. Levels of clotting factors including prothrombin time (PT) and activated partial thromboplastin time (APTT), total plasma\n",
            "proteins, and anti-A and/or anti-B antibodies measurements were performed using the coagulometer, method of Bradford, and titration procedure,\n",
            "respectively. RESULTS: The presence of SARS-CoV-2 was positive in 84.3 % of samples. Different concentrations of Cur@PLGA-NPs (3, 5, 7, and 10 % wt.),\n",
            "the irradiation times of blue laser (1, 3, and 5 min), and aPDT with the maximum dosed of blue laser light (522.8 J/cm2) plus 10 % wt. Cur@PLGA-NPs\n",
            "had no cytotoxicity. Although there were significant cell degradation and apoptotic effects in treated Vero cells with treated plasma using 10 % wt.\n",
            "Cur@PLGA-NPs, and a blue laser at an energy density of 522.8 J/cm2, no visible changes in cells and apoptosis were observed following aPDT. Total\n",
            "plasma protein content, PT, APTT, and anti-A and/or anti-B antibodies titers showed no significant changes (P > 0.05 for all comparisons) in treated\n",
            "plasma as compared to untreated plasma. CONCLUSION: aPDT exhibited in vitro anti-COVID-19 activities in the treated plasma containing SARS-COV-2\n",
            "without Vero cell apoptosis and any adverse effects on plasma quality in aPDT-exposed plasma.\n",
            "\u001b[1m\n",
            "Output:\u001b[0m\n",
            "\u001b[1mantimicrobial photodynamic therapy with curcumin-poly (lactic-co-glycolic acid) nanoparticles inactivate Coronavirus disease 2019 (COVID-19)\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Deployment with Gradio**"
      ],
      "metadata": {
        "id": "UfZ7DhTubOPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install the required libraries\n",
        "!pip install transformers gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRcidkvJ5imw",
        "outputId": "37b0bcd7-c7c8-4bd3-f6de-f27a44ba137d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Collecting gradio\n",
            "  Downloading gradio-4.32.1-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.17.0 (from gradio)\n",
            "  Downloading gradio_client-0.17.0-py3-none-any.whl (316 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.3/316.3 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.1)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.4.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Collecting typer<1.0,>=0.12 (from gradio)\n",
            "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.17.0->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.17.0->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->gradio)\n",
            "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=62b00ca09cf7e359914d7749364815cd909b7fa4d7de1108c1a3baa6a1165605\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uvloop, ujson, tomlkit, shellingham, semantic-version, ruff, python-multipart, python-dotenv, orjson, httptools, h11, dnspython, aiofiles, watchfiles, uvicorn, starlette, httpcore, email_validator, typer, httpx, gradio-client, fastapi-cli, fastapi, gradio\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 gradio-4.32.1 gradio-client-0.17.0 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 orjson-3.10.3 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.4.7 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tomlkit-0.12.0 typer-0.12.3 ujson-5.10.0 uvicorn-0.30.0 uvloop-0.19.0 watchfiles-0.22.0 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Import necessary libraries\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "sM0GJf057GV2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers gradio\n",
        "\n",
        "# Import necessary libraries\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import gradio as gr\n",
        "\n",
        "# Step 3: Load the fine-tuned model and tokenizer\n",
        "model_name = \"my_fine_tuned_t5_small_model\"  # Use the directory where your fine-tuned model is saved\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# Step 4: Define the summarization function\n",
        "def summarize(text):\n",
        "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "# Step 5: Create the Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=summarize,\n",
        "    inputs=gr.components.Textbox(lines=10, label=\"Input Text\"),\n",
        "    outputs=gr.components.Textbox(label=\"Summary\"),\n",
        "    title=\"Medical Text Summarization\",\n",
        "    description=\"Enter a medical text to get a summarized version using a fine-tuned T5-small model.\"\n",
        ")\n",
        "\n",
        "# Step 6: Launch the interface\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y1P9t9wy65_y",
        "outputId": "3b88f403-1338-4ade-a6ca-b7c42c9b40f3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.32.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.111.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.2)\n",
            "Requirement already satisfied: gradio-client==0.17.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.17.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.3)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.30.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.17.0->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.17.0->gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.37.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.0.4)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (5.10.0)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (2.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi->gradio) (2.6.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.22.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://5f41015f29b32b290b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5f41015f29b32b290b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}